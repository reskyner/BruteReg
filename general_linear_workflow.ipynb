{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%reset\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "sys.path.append('./modules')\n",
    "\n",
    "import warnings\n",
    "#import re\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "## import modules to build pipelines\n",
    "import pipemodules as pm\n",
    "import projecthandle as proj\n",
    "import run_grid as rg\n",
    "\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read csv file containing descriptors\n",
    "descriptors_raw = pd.read_csv('./rdkit_descriptors.csv')\n",
    "labels = descriptors_raw.iloc[:,0]\n",
    "X = descriptors_raw.iloc[:,2:]\n",
    "y = descriptors_raw.iloc[:,1]\n",
    "\n",
    "del descriptors_raw\n",
    "\n",
    "#range(10,100,10),\n",
    "#,2,3,4,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.094e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.470e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.718e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=1.660e-03, previous alpha=1.599e-03, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.086e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.429e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.522e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.441e-03, previous alpha=1.111e-03, with an active set of 22 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.470e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.718e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=2.026e-03, previous alpha=1.933e-03, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.091e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.456e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.455e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.641e-04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=6.948e-04, previous alpha=6.913e-04, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.116e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.580e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.139e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.009e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.712e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.712e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.527e-03, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.294e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=1.350e-03, previous alpha=1.203e-03, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.089e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.444e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.163e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=3.446e-04, previous alpha=3.432e-04, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 95 iterations, alpha=3.059e-03, previous alpha=2.318e-04, with an active set of 60 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.674e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.654e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.189e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.731e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.324e-03, previous alpha=1.323e-03, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=7.644e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=7.487e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.814e-04, previous alpha=6.677e-04, with an active set of 53 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.445e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.636e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.068e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.676e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.330e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 55 iterations, alpha=3.836e-04, previous alpha=3.584e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.092e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.546e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.593e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=4.784e-04, previous alpha=4.752e-04, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.841e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.410e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.459e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.452e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=1.829e-03, previous alpha=1.636e-03, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=1.220e-03, previous alpha=1.459e-04, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=3.693e-03, previous alpha=7.821e-05, with an active set of 58 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=4.510e-03, previous alpha=8.756e-05, with an active set of 60 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:43: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.415e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.493e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=2.003e-03, previous alpha=1.985e-03, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.949e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.465e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=2.458e-03, previous alpha=2.317e-03, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.712e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=9.045e-03, previous alpha=3.818e-03, with an active set of 54 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.415e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.493e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=2.000e-03, previous alpha=1.928e-03, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.465e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=2.325e-03, previous alpha=2.188e-03, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.712e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=6.037e-03, previous alpha=2.879e-03, with an active set of 51 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.179e-02, previous alpha=8.339e-05, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=3.121e-03, previous alpha=6.087e-05, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=5.762e-05, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.130e-02, previous alpha=5.266e-05, with an active set of 58 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.343e-05, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=3.843e-03, previous alpha=5.981e-05, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.042e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.281e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=3.831e-04, previous alpha=3.564e-04, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=7.743e-03, previous alpha=1.106e-04, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.505e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.461e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=9.918e-04, previous alpha=9.693e-04, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.311e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.150e-03, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=1.070e-03, previous alpha=1.021e-03, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.305e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.116e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.066e-03, previous alpha=6.008e-03, with an active set of 14 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=9.261e-04, previous alpha=1.206e-04, with an active set of 61 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.338e-03, previous alpha=1.425e-04, with an active set of 49 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.475e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.421e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.816e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.698e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=1.707e-04, previous alpha=1.566e-04, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=5.404e+00, previous alpha=1.082e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.443e+00, previous alpha=4.276e-03, with an active set of 44 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.631e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.411e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.411e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=2.031e-03, previous alpha=2.003e-03, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=7.333e+01, previous alpha=2.137e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.577e+00, previous alpha=1.990e-02, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=2.591e+00, previous alpha=5.016e-03, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.166e-02, with an active set of 25 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.449e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.380e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=2.223e-02, previous alpha=2.200e-02, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=4.657e-02, previous alpha=4.296e-02, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=3.226e-02, previous alpha=1.807e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.493e-02, previous alpha=1.318e-02, with an active set of 44 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.596e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.974e-02, previous alpha=1.757e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.826e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 50 iterations, alpha=9.492e-02, previous alpha=8.713e-02, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.374e-02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=6.401e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=3.253e+01, previous alpha=6.401e-03, with an active set of 50 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.219e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 93 iterations, alpha=3.506e-01, previous alpha=8.354e-03, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.505e-02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=2.431e-02, previous alpha=2.160e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=2.341e+01, previous alpha=1.340e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=7.198e+00, previous alpha=7.814e-03, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=6.344e-01, previous alpha=6.344e-01, with an active set of 16 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.517e+00, previous alpha=1.049e-02, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.384e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.192e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.261e-01, previous alpha=1.113e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pipemodules as pm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## filter results and eliminate poor models\n",
    "for i in range(0,len(results)):\n",
    "    if results.mean_train_score[i] > 0.75 and abs(results.mean_test_score[i] - results.mean_train_score[i]) < 0.15:\n",
    "        continue\n",
    "    else: \n",
    "        results.drop(i, axis=0, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## create analysis set\n",
    "# set arrays for results\n",
    "dev_set_score = []\n",
    "eval_set_score = []\n",
    "dev_evs = []\n",
    "eval_evs = []\n",
    "dev_mae = []\n",
    "eval_mae = []\n",
    "dev_mse = []\n",
    "eval_mse = []\n",
    "dev_medae = []\n",
    "eval_medae = []\n",
    "method_ids = []\n",
    "parameters = []\n",
    "\n",
    "\n",
    "for i in range(0,len(results)):\n",
    "    ## take method_ids and build estimator for current method\n",
    "    string = results.method_ids[i] # retrive method id\n",
    "    setup = eval(string) # convert to iterable array\n",
    "\n",
    "    temp = pm.search_random_forest() #initiate class\n",
    "\n",
    "    # set the estimator type and initiate estimator class\n",
    "    _,clf,_ = temp.set_method(setup[2]) \n",
    "    \n",
    "    # get the development set features\n",
    "    X_dev_temp, _ = pm.get_X(dev_set.matrix_raw, \\\n",
    "                             meth.indvals[setup[0]][setup[1]]) \n",
    "    # get the evaluation set features\n",
    "    X_eval_temp, _ = pm.get_X(eval_set.matrix_raw, \\\n",
    "                              meth.indvals[setup[0]][setup[1]]) \n",
    "\n",
    "    del temp\n",
    "\n",
    "    # retreive hyper-parameters\n",
    "    params = results['params'][i]\n",
    "    # set estimator hyper-parameters\n",
    "    clf.set_params(**params)\n",
    "    \n",
    "    # fit the estimator to the development set\n",
    "    clf.fit(X_dev_temp, dev_set.y_raw)\n",
    "    # predict the evaluation set\n",
    "    eval_predict = clf.predict(X_eval_temp)\n",
    "    # predict the development set - for metrics\n",
    "    dev_predict = clf.predict(X_dev_temp)\n",
    "    \n",
    "    # add calculated metrics, methods, and parameters to lists for results\n",
    "    dev_set_score.append(clf.score(X_dev_temp, dev_set.y_raw))\n",
    "    eval_set_score.append(clf.score(X_eval_temp, eval_set.y_raw))\n",
    "    dev_evs.append(metrics.explained_variance_score(dev_predict, dev_set.y_raw))\n",
    "    eval_evs.append(metrics.explained_variance_score(eval_predict, eval_set.y_raw))\n",
    "    dev_mae.append(metrics.mean_absolute_error(dev_predict, dev_set.y_raw))\n",
    "    eval_mae.append(metrics.mean_absolute_error(eval_predict, eval_set.y_raw))\n",
    "    dev_mse.append(metrics.mean_squared_error(dev_predict, dev_set.y_raw))\n",
    "    eval_mse.append(metrics.mean_squared_error(eval_predict, eval_set.y_raw))\n",
    "    dev_medae.append(metrics.median_absolute_error(dev_predict, dev_set.y_raw))\n",
    "    eval_medae.append(metrics.median_absolute_error(eval_predict, eval_set.y_raw))\n",
    "    method_ids.append(string)\n",
    "    parameters.append(params)\n",
    "    \n",
    "# create dictionary object from results\n",
    "evaluation_results = {'dev_set_score':dev_set_score, 'eval_set_score':eval_set_score, \\\n",
    "                     'method_ids':method_ids, 'parameters':parameters, 'dev_evs':dev_evs, \\\n",
    "                     'eval_evs':eval_evs, 'dev_mae':dev_mae, 'eval_mae':eval_mae, \\\n",
    "                     'dev_mse': dev_mse, 'eval_mse':eval_mse, 'dev_median_ae':dev_medae, \\\n",
    "                     'eval_median_ae':eval_medae}\n",
    "\n",
    "# re-rank and sort filtered methods by test-score (r**2)\n",
    "analysis_set = pd.DataFrame(evaluation_results)\n",
    "array = np.array(analysis_set['eval_set_score'])\n",
    "temp = array.argsort()[::-1]\n",
    "ranks = np.empty(len(array), int)\n",
    "ranks[temp] = np.arange(len(array))\n",
    "analysis_set['rank_test_score'] = ranks\n",
    "analysis_set.sort_values(by='rank_test_score', inplace=True)\n",
    "analysis_set.reset_index(drop=True, inplace=True)\n",
    "analysis_set.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.424076            0.999974      0.000405   \n",
      "1             0.99803           0.406243            0.999974      0.002746   \n",
      "2             0.99803           0.397930            0.999974      0.001071   \n",
      "3             0.99803           0.420547            0.999974      0.000255   \n",
      "4             0.99803           0.345349            0.999974      0.001128   \n",
      "5             0.99803           0.405106            0.999974      0.004279   \n",
      "6             0.99803           0.407175            0.999974      0.022929   \n",
      "7             0.99803           0.376038            0.999974      0.028923   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.022064         0.005022         0.429469          0.999327   \n",
      "1       0.057824         0.011764         0.477087          0.999327   \n",
      "2       0.089325         0.019156         0.447721          0.999327   \n",
      "3       0.121582         0.025687         0.465677          0.999327   \n",
      "4       0.050461         0.005172         0.417820          0.999327   \n",
      "5       0.129415         0.011766         0.455314          0.999327   \n",
      "6       0.204490         0.018932         0.445757          0.999327   \n",
      "7       0.280706         0.025735         0.440078          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 1, 2]             mse                 10   \n",
      "1  [0, 1, 2]             mse                 25   \n",
      "2  [0, 1, 2]             mse                 40   \n",
      "3  [0, 1, 2]             mse                 55   \n",
      "4  [0, 1, 2]             mae                 10   \n",
      "5  [0, 1, 2]             mae                 25   \n",
      "6  [0, 1, 2]             mae                 40   \n",
      "7  [0, 1, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.531158            0.999978           0.408375   \n",
      "1           0.503439            0.999978           0.525550   \n",
      "2           0.495257            0.999978           0.473424   \n",
      "3           0.532163            0.999978           0.492380   \n",
      "4           0.479440            0.999978           0.423900   \n",
      "5           0.514665            0.999978           0.466658   \n",
      "6           0.511391            0.999978           0.470341   \n",
      "7           0.503981            0.999978           0.439359   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.347781            0.999974      0.000520   \n",
      "1             0.99803           0.401990            0.999974      0.005516   \n",
      "2             0.99803           0.373970            0.999974      0.002415   \n",
      "3             0.99803           0.371773            0.999974      0.002624   \n",
      "4             0.99803           0.349457            0.999974      0.001997   \n",
      "5             0.99803           0.383980            0.999974      0.000475   \n",
      "6             0.99803           0.354833            0.999974      0.004821   \n",
      "7             0.99803           0.376207            0.999974      0.005013   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000010        0.076391         0.000917  \n",
      "1        0.000275        0.053725         0.000917  \n",
      "2        0.000319        0.052769         0.000917  \n",
      "3        0.000374        0.068188         0.000917  \n",
      "4        0.000168        0.053285         0.000917  \n",
      "5        0.000100        0.053995         0.000917  \n",
      "6        0.000459        0.066278         0.000917  \n",
      "7        0.000165        0.052212         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "0       0.022064         0.005022         0.429469          0.999327   \n",
      "1       0.057824         0.011764         0.477087          0.999327   \n",
      "2       0.089325         0.019156         0.447721          0.999327   \n",
      "3       0.121582         0.025687         0.465677          0.999327   \n",
      "4       0.050461         0.005172         0.417820          0.999327   \n",
      "5       0.129415         0.011766         0.455314          0.999327   \n",
      "6       0.204490         0.018932         0.445757          0.999327   \n",
      "7       0.280706         0.025735         0.440078          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "0  [0, 1, 2]             mse                 10   \n",
      "1  [0, 1, 2]             mse                 25   \n",
      "2  [0, 1, 2]             mse                 40   \n",
      "3  [0, 1, 2]             mse                 55   \n",
      "4  [0, 1, 2]             mae                 10   \n",
      "5  [0, 1, 2]             mae                 25   \n",
      "6  [0, 1, 2]             mae                 40   \n",
      "7  [0, 1, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "0           0.531158            0.999978           0.408375   \n",
      "1           0.503439            0.999978           0.525550   \n",
      "2           0.495257            0.999978           0.473424   \n",
      "3           0.532163            0.999978           0.492380   \n",
      "4           0.479440            0.999978           0.423900   \n",
      "5           0.514665            0.999978           0.466658   \n",
      "6           0.511391            0.999978           0.470341   \n",
      "7           0.503981            0.999978           0.439359   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "0            0.998030           0.347781            0.999974      0.000520   \n",
      "1            0.998030           0.401990            0.999974      0.005516   \n",
      "2            0.998030           0.373970            0.999974      0.002415   \n",
      "3            0.998030           0.371773            0.999974      0.002624   \n",
      "4            0.998030           0.349457            0.999974      0.001997   \n",
      "5            0.998030           0.383980            0.999974      0.000475   \n",
      "6            0.998030           0.354833            0.999974      0.004821   \n",
      "7            0.998030           0.376207            0.999974      0.005013   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "0        0.000010        0.076391         0.000917  \n",
      "1        0.000275        0.053725         0.000917  \n",
      "2        0.000319        0.052769         0.000917  \n",
      "3        0.000374        0.068188         0.000917  \n",
      "4        0.000168        0.053285         0.000917  \n",
      "5        0.000100        0.053995         0.000917  \n",
      "6        0.000459        0.066278         0.000917  \n",
      "7        0.000165        0.052212         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.023749         0.004902         0.377227          0.894722   \n",
      "1       0.061383         0.011770         0.447905          0.912889   \n",
      "2       0.093766         0.018978         0.414147          0.920426   \n",
      "3       0.128777         0.026892         0.423102          0.918386   \n",
      "4       0.049568         0.005000         0.421511          0.883591   \n",
      "5       0.121377         0.012151         0.422526          0.904570   \n",
      "6       0.226937         0.019638         0.434604          0.919032   \n",
      "7       0.268454         0.025964         0.455829          0.913065   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 2, 1]             mse                 10   \n",
      "1  [0, 2, 1]             mse                 25   \n",
      "2  [0, 2, 1]             mse                 40   \n",
      "3  [0, 2, 1]             mse                 55   \n",
      "4  [0, 2, 1]             mae                 10   \n",
      "5  [0, 2, 1]             mae                 25   \n",
      "6  [0, 2, 1]             mae                 40   \n",
      "7  [0, 2, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                7   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                3   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.394553            0.908679           0.427265   \n",
      "1           0.506235            0.910769           0.419286   \n",
      "2           0.490336            0.915519           0.356600   \n",
      "3           0.499550            0.915338           0.405926   \n",
      "4           0.530776            0.859296           0.420564   \n",
      "5           0.493540            0.892617           0.427600   \n",
      "6           0.533535            0.910753           0.432182   \n",
      "7           0.520751            0.904628           0.438295   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.880529           0.309677            0.894957      0.000176   \n",
      "1            0.912013           0.417566            0.915883      0.003928   \n",
      "2            0.926442           0.394687            0.919317      0.000166   \n",
      "3            0.923868           0.363007            0.915952      0.000726   \n",
      "4            0.893825           0.312019            0.897651      0.001317   \n",
      "5            0.916280           0.345674            0.904813      0.002863   \n",
      "6            0.924144           0.337031            0.922201      0.030296   \n",
      "7            0.916972           0.407742            0.917597      0.005751   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000139        0.049477         0.011494  \n",
      "1        0.000171        0.041473         0.002178  \n",
      "2        0.000079        0.056342         0.004528  \n",
      "3        0.001883        0.057092         0.003885  \n",
      "4        0.000152        0.089388         0.017250  \n",
      "5        0.000346        0.060525         0.009662  \n",
      "6        0.001403        0.080311         0.005908  \n",
      "7        0.000644        0.047803         0.005972  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "0       0.022064         0.005022         0.429469          0.999327   \n",
      "1       0.057824         0.011764         0.477087          0.999327   \n",
      "2       0.089325         0.019156         0.447721          0.999327   \n",
      "3       0.121582         0.025687         0.465677          0.999327   \n",
      "4       0.050461         0.005172         0.417820          0.999327   \n",
      "5       0.129415         0.011766         0.455314          0.999327   \n",
      "6       0.204490         0.018932         0.445757          0.999327   \n",
      "7       0.280706         0.025735         0.440078          0.999327   \n",
      "0       0.023749         0.004902         0.377227          0.894722   \n",
      "1       0.061383         0.011770         0.447905          0.912889   \n",
      "2       0.093766         0.018978         0.414147          0.920426   \n",
      "3       0.128777         0.026892         0.423102          0.918386   \n",
      "4       0.049568         0.005000         0.421511          0.883591   \n",
      "5       0.121377         0.012151         0.422526          0.904570   \n",
      "6       0.226937         0.019638         0.434604          0.919032   \n",
      "7       0.268454         0.025964         0.455829          0.913065   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "0  [0, 1, 2]             mse                 10   \n",
      "1  [0, 1, 2]             mse                 25   \n",
      "2  [0, 1, 2]             mse                 40   \n",
      "3  [0, 1, 2]             mse                 55   \n",
      "4  [0, 1, 2]             mae                 10   \n",
      "5  [0, 1, 2]             mae                 25   \n",
      "6  [0, 1, 2]             mae                 40   \n",
      "7  [0, 1, 2]             mae                 55   \n",
      "0  [0, 2, 1]             mse                 10   \n",
      "1  [0, 2, 1]             mse                 25   \n",
      "2  [0, 2, 1]             mse                 40   \n",
      "3  [0, 2, 1]             mse                 55   \n",
      "4  [0, 2, 1]             mae                 10   \n",
      "5  [0, 2, 1]             mae                 25   \n",
      "6  [0, 2, 1]             mae                 40   \n",
      "7  [0, 2, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                7   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                3   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "0           0.531158            0.999978           0.408375   \n",
      "1           0.503439            0.999978           0.525550   \n",
      "2           0.495257            0.999978           0.473424   \n",
      "3           0.532163            0.999978           0.492380   \n",
      "4           0.479440            0.999978           0.423900   \n",
      "5           0.514665            0.999978           0.466658   \n",
      "6           0.511391            0.999978           0.470341   \n",
      "7           0.503981            0.999978           0.439359   \n",
      "0           0.394553            0.908679           0.427265   \n",
      "1           0.506235            0.910769           0.419286   \n",
      "2           0.490336            0.915519           0.356600   \n",
      "3           0.499550            0.915338           0.405926   \n",
      "4           0.530776            0.859296           0.420564   \n",
      "5           0.493540            0.892617           0.427600   \n",
      "6           0.533535            0.910753           0.432182   \n",
      "7           0.520751            0.904628           0.438295   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "0            0.998030           0.347781            0.999974      0.000520   \n",
      "1            0.998030           0.401990            0.999974      0.005516   \n",
      "2            0.998030           0.373970            0.999974      0.002415   \n",
      "3            0.998030           0.371773            0.999974      0.002624   \n",
      "4            0.998030           0.349457            0.999974      0.001997   \n",
      "5            0.998030           0.383980            0.999974      0.000475   \n",
      "6            0.998030           0.354833            0.999974      0.004821   \n",
      "7            0.998030           0.376207            0.999974      0.005013   \n",
      "0            0.880529           0.309677            0.894957      0.000176   \n",
      "1            0.912013           0.417566            0.915883      0.003928   \n",
      "2            0.926442           0.394687            0.919317      0.000166   \n",
      "3            0.923868           0.363007            0.915952      0.000726   \n",
      "4            0.893825           0.312019            0.897651      0.001317   \n",
      "5            0.916280           0.345674            0.904813      0.002863   \n",
      "6            0.924144           0.337031            0.922201      0.030296   \n",
      "7            0.916972           0.407742            0.917597      0.005751   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "0        0.000010        0.076391         0.000917  \n",
      "1        0.000275        0.053725         0.000917  \n",
      "2        0.000319        0.052769         0.000917  \n",
      "3        0.000374        0.068188         0.000917  \n",
      "4        0.000168        0.053285         0.000917  \n",
      "5        0.000100        0.053995         0.000917  \n",
      "6        0.000459        0.066278         0.000917  \n",
      "7        0.000165        0.052212         0.000917  \n",
      "0        0.000139        0.049477         0.011494  \n",
      "1        0.000171        0.041473         0.002178  \n",
      "2        0.000079        0.056342         0.004528  \n",
      "3        0.001883        0.057092         0.003885  \n",
      "4        0.000152        0.089388         0.017250  \n",
      "5        0.000346        0.060525         0.009662  \n",
      "6        0.001403        0.080311         0.005908  \n",
      "7        0.000644        0.047803         0.005972  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.021641         0.005110         0.397968          0.999327   \n",
      "1       0.057207         0.011799         0.452940          0.999327   \n",
      "2       0.086584         0.018918         0.472299          0.999327   \n",
      "3       0.127629         0.025684         0.464409          0.999327   \n",
      "4       0.056939         0.005046         0.447631          0.999327   \n",
      "5       0.135677         0.012172         0.453036          0.999327   \n",
      "6       0.201224         0.019013         0.460067          0.999327   \n",
      "7       0.272294         0.025723         0.461594          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 2, 2]             mse                 10   \n",
      "1  [0, 2, 2]             mse                 25   \n",
      "2  [0, 2, 2]             mse                 40   \n",
      "3  [0, 2, 2]             mse                 55   \n",
      "4  [0, 2, 2]             mae                 10   \n",
      "5  [0, 2, 2]             mae                 25   \n",
      "6  [0, 2, 2]             mae                 40   \n",
      "7  [0, 2, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                4   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.448027            0.999978           0.405060   \n",
      "1           0.511811            0.999978           0.463751   \n",
      "2           0.564754            0.999978           0.479838   \n",
      "3           0.523986            0.999978           0.492553   \n",
      "4           0.499696            0.999978           0.443762   \n",
      "5           0.505800            0.999978           0.469945   \n",
      "6           0.531864            0.999978           0.487001   \n",
      "7           0.515662            0.999978           0.474997   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.340278            0.999974      0.000178   \n",
      "1             0.99803           0.382624            0.999974      0.004856   \n",
      "2             0.99803           0.371312            0.999974      0.000149   \n",
      "3             0.99803           0.376048            0.999974      0.012641   \n",
      "4             0.99803           0.398875            0.999974      0.001311   \n",
      "5             0.99803           0.382795            0.999974      0.004922   \n",
      "6             0.99803           0.360563            0.999974      0.007703   \n",
      "7             0.99803           0.393541            0.999974      0.010708   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000249        0.044310         0.000917  \n",
      "1        0.000110        0.053334         0.000917  \n",
      "2        0.000085        0.079220         0.000917  \n",
      "3        0.000315        0.063623         0.000917  \n",
      "4        0.000078        0.041286         0.000917  \n",
      "5        0.000161        0.051656         0.000917  \n",
      "6        0.000131        0.072526         0.000917  \n",
      "7        0.000124        0.050787         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "0       0.022064         0.005022         0.429469          0.999327   \n",
      "1       0.057824         0.011764         0.477087          0.999327   \n",
      "2       0.089325         0.019156         0.447721          0.999327   \n",
      "3       0.121582         0.025687         0.465677          0.999327   \n",
      "4       0.050461         0.005172         0.417820          0.999327   \n",
      "5       0.129415         0.011766         0.455314          0.999327   \n",
      "6       0.204490         0.018932         0.445757          0.999327   \n",
      "7       0.280706         0.025735         0.440078          0.999327   \n",
      "0       0.023749         0.004902         0.377227          0.894722   \n",
      "1       0.061383         0.011770         0.447905          0.912889   \n",
      "2       0.093766         0.018978         0.414147          0.920426   \n",
      "3       0.128777         0.026892         0.423102          0.918386   \n",
      "4       0.049568         0.005000         0.421511          0.883591   \n",
      "5       0.121377         0.012151         0.422526          0.904570   \n",
      "6       0.226937         0.019638         0.434604          0.919032   \n",
      "7       0.268454         0.025964         0.455829          0.913065   \n",
      "0       0.021641         0.005110         0.397968          0.999327   \n",
      "1       0.057207         0.011799         0.452940          0.999327   \n",
      "2       0.086584         0.018918         0.472299          0.999327   \n",
      "3       0.127629         0.025684         0.464409          0.999327   \n",
      "4       0.056939         0.005046         0.447631          0.999327   \n",
      "5       0.135677         0.012172         0.453036          0.999327   \n",
      "6       0.201224         0.019013         0.460067          0.999327   \n",
      "7       0.272294         0.025723         0.461594          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "0  [0, 1, 2]             mse                 10   \n",
      "1  [0, 1, 2]             mse                 25   \n",
      "2  [0, 1, 2]             mse                 40   \n",
      "3  [0, 1, 2]             mse                 55   \n",
      "4  [0, 1, 2]             mae                 10   \n",
      "5  [0, 1, 2]             mae                 25   \n",
      "6  [0, 1, 2]             mae                 40   \n",
      "7  [0, 1, 2]             mae                 55   \n",
      "0  [0, 2, 1]             mse                 10   \n",
      "1  [0, 2, 1]             mse                 25   \n",
      "2  [0, 2, 1]             mse                 40   \n",
      "3  [0, 2, 1]             mse                 55   \n",
      "4  [0, 2, 1]             mae                 10   \n",
      "5  [0, 2, 1]             mae                 25   \n",
      "6  [0, 2, 1]             mae                 40   \n",
      "7  [0, 2, 1]             mae                 55   \n",
      "0  [0, 2, 2]             mse                 10   \n",
      "1  [0, 2, 2]             mse                 25   \n",
      "2  [0, 2, 2]             mse                 40   \n",
      "3  [0, 2, 2]             mse                 55   \n",
      "4  [0, 2, 2]             mae                 10   \n",
      "5  [0, 2, 2]             mae                 25   \n",
      "6  [0, 2, 2]             mae                 40   \n",
      "7  [0, 2, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                7   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                3   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                4   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "0           0.531158            0.999978           0.408375   \n",
      "1           0.503439            0.999978           0.525550   \n",
      "2           0.495257            0.999978           0.473424   \n",
      "3           0.532163            0.999978           0.492380   \n",
      "4           0.479440            0.999978           0.423900   \n",
      "5           0.514665            0.999978           0.466658   \n",
      "6           0.511391            0.999978           0.470341   \n",
      "7           0.503981            0.999978           0.439359   \n",
      "0           0.394553            0.908679           0.427265   \n",
      "1           0.506235            0.910769           0.419286   \n",
      "2           0.490336            0.915519           0.356600   \n",
      "3           0.499550            0.915338           0.405926   \n",
      "4           0.530776            0.859296           0.420564   \n",
      "5           0.493540            0.892617           0.427600   \n",
      "6           0.533535            0.910753           0.432182   \n",
      "7           0.520751            0.904628           0.438295   \n",
      "0           0.448027            0.999978           0.405060   \n",
      "1           0.511811            0.999978           0.463751   \n",
      "2           0.564754            0.999978           0.479838   \n",
      "3           0.523986            0.999978           0.492553   \n",
      "4           0.499696            0.999978           0.443762   \n",
      "5           0.505800            0.999978           0.469945   \n",
      "6           0.531864            0.999978           0.487001   \n",
      "7           0.515662            0.999978           0.474997   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "0            0.998030           0.347781            0.999974      0.000520   \n",
      "1            0.998030           0.401990            0.999974      0.005516   \n",
      "2            0.998030           0.373970            0.999974      0.002415   \n",
      "3            0.998030           0.371773            0.999974      0.002624   \n",
      "4            0.998030           0.349457            0.999974      0.001997   \n",
      "5            0.998030           0.383980            0.999974      0.000475   \n",
      "6            0.998030           0.354833            0.999974      0.004821   \n",
      "7            0.998030           0.376207            0.999974      0.005013   \n",
      "0            0.880529           0.309677            0.894957      0.000176   \n",
      "1            0.912013           0.417566            0.915883      0.003928   \n",
      "2            0.926442           0.394687            0.919317      0.000166   \n",
      "3            0.923868           0.363007            0.915952      0.000726   \n",
      "4            0.893825           0.312019            0.897651      0.001317   \n",
      "5            0.916280           0.345674            0.904813      0.002863   \n",
      "6            0.924144           0.337031            0.922201      0.030296   \n",
      "7            0.916972           0.407742            0.917597      0.005751   \n",
      "0            0.998030           0.340278            0.999974      0.000178   \n",
      "1            0.998030           0.382624            0.999974      0.004856   \n",
      "2            0.998030           0.371312            0.999974      0.000149   \n",
      "3            0.998030           0.376048            0.999974      0.012641   \n",
      "4            0.998030           0.398875            0.999974      0.001311   \n",
      "5            0.998030           0.382795            0.999974      0.004922   \n",
      "6            0.998030           0.360563            0.999974      0.007703   \n",
      "7            0.998030           0.393541            0.999974      0.010708   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "0        0.000010        0.076391         0.000917  \n",
      "1        0.000275        0.053725         0.000917  \n",
      "2        0.000319        0.052769         0.000917  \n",
      "3        0.000374        0.068188         0.000917  \n",
      "4        0.000168        0.053285         0.000917  \n",
      "5        0.000100        0.053995         0.000917  \n",
      "6        0.000459        0.066278         0.000917  \n",
      "7        0.000165        0.052212         0.000917  \n",
      "0        0.000139        0.049477         0.011494  \n",
      "1        0.000171        0.041473         0.002178  \n",
      "2        0.000079        0.056342         0.004528  \n",
      "3        0.001883        0.057092         0.003885  \n",
      "4        0.000152        0.089388         0.017250  \n",
      "5        0.000346        0.060525         0.009662  \n",
      "6        0.001403        0.080311         0.005908  \n",
      "7        0.000644        0.047803         0.005972  \n",
      "0        0.000249        0.044310         0.000917  \n",
      "1        0.000110        0.053334         0.000917  \n",
      "2        0.000085        0.079220         0.000917  \n",
      "3        0.000315        0.063623         0.000917  \n",
      "4        0.000078        0.041286         0.000917  \n",
      "5        0.000161        0.051656         0.000917  \n",
      "6        0.000131        0.072526         0.000917  \n",
      "7        0.000124        0.050787         0.000917  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.026928         0.004926         0.529766          0.914276   \n",
      "1       0.067621         0.012016         0.517010          0.919884   \n",
      "2       0.107500         0.018467         0.529725          0.928579   \n",
      "3       0.150285         0.025328         0.529085          0.929993   \n",
      "4       0.079906         0.005054         0.471788          0.908994   \n",
      "5       0.203138         0.012009         0.522322          0.924236   \n",
      "6       0.340299         0.020804         0.514097          0.925083   \n",
      "7       0.507108         0.029291         0.535624          0.929226   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 0, 1]             mse                 10   \n",
      "1  [1, 0, 1]             mse                 25   \n",
      "2  [1, 0, 1]             mse                 40   \n",
      "3  [1, 0, 1]             mse                 55   \n",
      "4  [1, 0, 1]             mae                 10   \n",
      "5  [1, 0, 1]             mae                 25   \n",
      "6  [1, 0, 1]             mae                 40   \n",
      "7  [1, 0, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.593655            0.899050           0.564145   \n",
      "1           0.576332            0.914199           0.574699   \n",
      "2           0.585921            0.932432           0.571995   \n",
      "3           0.569633            0.923452           0.572766   \n",
      "4           0.556942            0.919819           0.520084   \n",
      "5           0.522936            0.929253           0.575438   \n",
      "6           0.567707            0.919558           0.544228   \n",
      "7           0.562966            0.918211           0.582872   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.916170           0.430812            0.927607      0.000247   \n",
      "1            0.916065           0.399362            0.929387      0.000219   \n",
      "2            0.917596           0.430655            0.935709      0.000166   \n",
      "3            0.928583           0.444420            0.937943      0.003182   \n",
      "4            0.906917           0.337422            0.900244      0.001381   \n",
      "5            0.918809           0.468585            0.924647      0.008198   \n",
      "6            0.925269           0.429778            0.930421      0.034664   \n",
      "7            0.933235           0.460740            0.936233      0.016345   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000115        0.070818         0.011735  \n",
      "1        0.000420        0.082970         0.006763  \n",
      "2        0.000161        0.070097         0.007880  \n",
      "3        0.000340        0.059721         0.005999  \n",
      "4        0.000050        0.095946         0.008125  \n",
      "5        0.000034        0.043547         0.004273  \n",
      "6        0.001539        0.060231         0.004437  \n",
      "7        0.001807        0.053432         0.007885  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.024136         0.005008         0.473376          0.883712   \n",
      "1       0.060178         0.011970         0.492589          0.913149   \n",
      "2       0.095356         0.018556         0.501884          0.919258   \n",
      "3       0.131009         0.025559         0.495889          0.920909   \n",
      "4       0.050747         0.005121         0.485578          0.894911   \n",
      "5       0.135085         0.011601         0.484008          0.915978   \n",
      "6       0.215881         0.022047         0.491211          0.916460   \n",
      "7       0.287532         0.025424         0.499552          0.918961   \n",
      "0       0.021495         0.004955         0.455315          0.999327   \n",
      "1       0.055847         0.012153         0.482821          0.999327   \n",
      "2       0.085707         0.020287         0.480219          0.999327   \n",
      "3       0.116703         0.025506         0.482323          0.999327   \n",
      "4       0.051623         0.004975         0.441957          0.999327   \n",
      "5       0.130315         0.011985         0.475367          0.999327   \n",
      "6       0.228170         0.020735         0.485410          0.999327   \n",
      "7       0.326909         0.028547         0.480426          0.999327   \n",
      "0       0.024429         0.005034         0.438331          0.886438   \n",
      "1       0.068368         0.014011         0.417784          0.910506   \n",
      "2       0.120861         0.026287         0.452943          0.910942   \n",
      "3       0.146770         0.026211         0.435130          0.917921   \n",
      "4       0.053327         0.005148         0.424631          0.873036   \n",
      "5       0.132050         0.012251         0.447810          0.904868   \n",
      "6       0.217647         0.023733         0.464478          0.909622   \n",
      "7       0.292883         0.026061         0.443942          0.914943   \n",
      "0       0.022064         0.005022         0.429469          0.999327   \n",
      "1       0.057824         0.011764         0.477087          0.999327   \n",
      "2       0.089325         0.019156         0.447721          0.999327   \n",
      "3       0.121582         0.025687         0.465677          0.999327   \n",
      "4       0.050461         0.005172         0.417820          0.999327   \n",
      "5       0.129415         0.011766         0.455314          0.999327   \n",
      "6       0.204490         0.018932         0.445757          0.999327   \n",
      "7       0.280706         0.025735         0.440078          0.999327   \n",
      "0       0.023749         0.004902         0.377227          0.894722   \n",
      "1       0.061383         0.011770         0.447905          0.912889   \n",
      "2       0.093766         0.018978         0.414147          0.920426   \n",
      "3       0.128777         0.026892         0.423102          0.918386   \n",
      "4       0.049568         0.005000         0.421511          0.883591   \n",
      "5       0.121377         0.012151         0.422526          0.904570   \n",
      "6       0.226937         0.019638         0.434604          0.919032   \n",
      "7       0.268454         0.025964         0.455829          0.913065   \n",
      "0       0.021641         0.005110         0.397968          0.999327   \n",
      "1       0.057207         0.011799         0.452940          0.999327   \n",
      "2       0.086584         0.018918         0.472299          0.999327   \n",
      "3       0.127629         0.025684         0.464409          0.999327   \n",
      "4       0.056939         0.005046         0.447631          0.999327   \n",
      "5       0.135677         0.012172         0.453036          0.999327   \n",
      "6       0.201224         0.019013         0.460067          0.999327   \n",
      "7       0.272294         0.025723         0.461594          0.999327   \n",
      "0       0.026928         0.004926         0.529766          0.914276   \n",
      "1       0.067621         0.012016         0.517010          0.919884   \n",
      "2       0.107500         0.018467         0.529725          0.928579   \n",
      "3       0.150285         0.025328         0.529085          0.929993   \n",
      "4       0.079906         0.005054         0.471788          0.908994   \n",
      "5       0.203138         0.012009         0.522322          0.924236   \n",
      "6       0.340299         0.020804         0.514097          0.925083   \n",
      "7       0.507108         0.029291         0.535624          0.929226   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [0, 0, 1]             mse                 10   \n",
      "1  [0, 0, 1]             mse                 25   \n",
      "2  [0, 0, 1]             mse                 40   \n",
      "3  [0, 0, 1]             mse                 55   \n",
      "4  [0, 0, 1]             mae                 10   \n",
      "5  [0, 0, 1]             mae                 25   \n",
      "6  [0, 0, 1]             mae                 40   \n",
      "7  [0, 0, 1]             mae                 55   \n",
      "0  [0, 0, 2]             mse                 10   \n",
      "1  [0, 0, 2]             mse                 25   \n",
      "2  [0, 0, 2]             mse                 40   \n",
      "3  [0, 0, 2]             mse                 55   \n",
      "4  [0, 0, 2]             mae                 10   \n",
      "5  [0, 0, 2]             mae                 25   \n",
      "6  [0, 0, 2]             mae                 40   \n",
      "7  [0, 0, 2]             mae                 55   \n",
      "0  [0, 1, 1]             mse                 10   \n",
      "1  [0, 1, 1]             mse                 25   \n",
      "2  [0, 1, 1]             mse                 40   \n",
      "3  [0, 1, 1]             mse                 55   \n",
      "4  [0, 1, 1]             mae                 10   \n",
      "5  [0, 1, 1]             mae                 25   \n",
      "6  [0, 1, 1]             mae                 40   \n",
      "7  [0, 1, 1]             mae                 55   \n",
      "0  [0, 1, 2]             mse                 10   \n",
      "1  [0, 1, 2]             mse                 25   \n",
      "2  [0, 1, 2]             mse                 40   \n",
      "3  [0, 1, 2]             mse                 55   \n",
      "4  [0, 1, 2]             mae                 10   \n",
      "5  [0, 1, 2]             mae                 25   \n",
      "6  [0, 1, 2]             mae                 40   \n",
      "7  [0, 1, 2]             mae                 55   \n",
      "0  [0, 2, 1]             mse                 10   \n",
      "1  [0, 2, 1]             mse                 25   \n",
      "2  [0, 2, 1]             mse                 40   \n",
      "3  [0, 2, 1]             mse                 55   \n",
      "4  [0, 2, 1]             mae                 10   \n",
      "5  [0, 2, 1]             mae                 25   \n",
      "6  [0, 2, 1]             mae                 40   \n",
      "7  [0, 2, 1]             mae                 55   \n",
      "0  [0, 2, 2]             mse                 10   \n",
      "1  [0, 2, 2]             mse                 25   \n",
      "2  [0, 2, 2]             mse                 40   \n",
      "3  [0, 2, 2]             mse                 55   \n",
      "4  [0, 2, 2]             mae                 10   \n",
      "5  [0, 2, 2]             mae                 25   \n",
      "6  [0, 2, 2]             mae                 40   \n",
      "7  [0, 2, 2]             mae                 55   \n",
      "0  [1, 0, 1]             mse                 10   \n",
      "1  [1, 0, 1]             mse                 25   \n",
      "2  [1, 0, 1]             mse                 40   \n",
      "3  [1, 0, 1]             mse                 55   \n",
      "4  [1, 0, 1]             mae                 10   \n",
      "5  [1, 0, 1]             mae                 25   \n",
      "6  [1, 0, 1]             mae                 40   \n",
      "7  [1, 0, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                7   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                3   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                4   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.532909            0.875786           0.441208   \n",
      "1           0.539835            0.910320           0.514354   \n",
      "2           0.565894            0.912127           0.505728   \n",
      "3           0.544117            0.922500           0.478462   \n",
      "4           0.558931            0.882973           0.483207   \n",
      "5           0.564253            0.916684           0.445223   \n",
      "6           0.573519            0.910791           0.453887   \n",
      "7           0.585932            0.915393           0.504125   \n",
      "0           0.492315            0.999978           0.449155   \n",
      "1           0.542346            0.999978           0.499233   \n",
      "2           0.531688            0.999978           0.510485   \n",
      "3           0.525395            0.999978           0.500564   \n",
      "4           0.497328            0.999978           0.482597   \n",
      "5           0.553961            0.999978           0.466189   \n",
      "6           0.566515            0.999978           0.481667   \n",
      "7           0.552411            0.999978           0.512055   \n",
      "0           0.469139            0.880897           0.496814   \n",
      "1           0.502791            0.902003           0.424643   \n",
      "2           0.542659            0.903799           0.430453   \n",
      "3           0.495867            0.906287           0.422693   \n",
      "4           0.512529            0.869530           0.414054   \n",
      "5           0.493631            0.894170           0.448127   \n",
      "6           0.525079            0.904297           0.460221   \n",
      "7           0.508563            0.905416           0.466128   \n",
      "0           0.531158            0.999978           0.408375   \n",
      "1           0.503439            0.999978           0.525550   \n",
      "2           0.495257            0.999978           0.473424   \n",
      "3           0.532163            0.999978           0.492380   \n",
      "4           0.479440            0.999978           0.423900   \n",
      "5           0.514665            0.999978           0.466658   \n",
      "6           0.511391            0.999978           0.470341   \n",
      "7           0.503981            0.999978           0.439359   \n",
      "0           0.394553            0.908679           0.427265   \n",
      "1           0.506235            0.910769           0.419286   \n",
      "2           0.490336            0.915519           0.356600   \n",
      "3           0.499550            0.915338           0.405926   \n",
      "4           0.530776            0.859296           0.420564   \n",
      "5           0.493540            0.892617           0.427600   \n",
      "6           0.533535            0.910753           0.432182   \n",
      "7           0.520751            0.904628           0.438295   \n",
      "0           0.448027            0.999978           0.405060   \n",
      "1           0.511811            0.999978           0.463751   \n",
      "2           0.564754            0.999978           0.479838   \n",
      "3           0.523986            0.999978           0.492553   \n",
      "4           0.499696            0.999978           0.443762   \n",
      "5           0.505800            0.999978           0.469945   \n",
      "6           0.531864            0.999978           0.487001   \n",
      "7           0.515662            0.999978           0.474997   \n",
      "0           0.593655            0.899050           0.564145   \n",
      "1           0.576332            0.914199           0.574699   \n",
      "2           0.585921            0.932432           0.571995   \n",
      "3           0.569633            0.923452           0.572766   \n",
      "4           0.556942            0.919819           0.520084   \n",
      "5           0.522936            0.929253           0.575438   \n",
      "6           0.567707            0.919558           0.544228   \n",
      "7           0.562966            0.918211           0.582872   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.877617           0.445372            0.897734      0.000139   \n",
      "1            0.912061           0.423071            0.917066      0.000326   \n",
      "2            0.923810           0.433343            0.921837      0.000400   \n",
      "3            0.923717           0.464570            0.916511      0.000613   \n",
      "4            0.905834           0.413808            0.895927      0.001724   \n",
      "5            0.912121           0.441685            0.919130      0.001826   \n",
      "6            0.920353           0.445343            0.918235      0.007670   \n",
      "7            0.924390           0.407669            0.917102      0.005413   \n",
      "0            0.998030           0.424076            0.999974      0.000405   \n",
      "1            0.998030           0.406243            0.999974      0.002746   \n",
      "2            0.998030           0.397930            0.999974      0.001071   \n",
      "3            0.998030           0.420547            0.999974      0.000255   \n",
      "4            0.998030           0.345349            0.999974      0.001128   \n",
      "5            0.998030           0.405106            0.999974      0.004279   \n",
      "6            0.998030           0.407175            0.999974      0.022929   \n",
      "7            0.998030           0.376038            0.999974      0.028923   \n",
      "0            0.869641           0.348710            0.908778      0.000299   \n",
      "1            0.914159           0.325005            0.915357      0.004393   \n",
      "2            0.911402           0.384754            0.917626      0.004156   \n",
      "3            0.922294           0.386176            0.925181      0.015858   \n",
      "4            0.870999           0.346366            0.878579      0.001481   \n",
      "5            0.915648           0.401179            0.904786      0.002898   \n",
      "6            0.917081           0.407480            0.907487      0.010971   \n",
      "7            0.921047           0.356440            0.918367      0.006066   \n",
      "0            0.998030           0.347781            0.999974      0.000520   \n",
      "1            0.998030           0.401990            0.999974      0.005516   \n",
      "2            0.998030           0.373970            0.999974      0.002415   \n",
      "3            0.998030           0.371773            0.999974      0.002624   \n",
      "4            0.998030           0.349457            0.999974      0.001997   \n",
      "5            0.998030           0.383980            0.999974      0.000475   \n",
      "6            0.998030           0.354833            0.999974      0.004821   \n",
      "7            0.998030           0.376207            0.999974      0.005013   \n",
      "0            0.880529           0.309677            0.894957      0.000176   \n",
      "1            0.912013           0.417566            0.915883      0.003928   \n",
      "2            0.926442           0.394687            0.919317      0.000166   \n",
      "3            0.923868           0.363007            0.915952      0.000726   \n",
      "4            0.893825           0.312019            0.897651      0.001317   \n",
      "5            0.916280           0.345674            0.904813      0.002863   \n",
      "6            0.924144           0.337031            0.922201      0.030296   \n",
      "7            0.916972           0.407742            0.917597      0.005751   \n",
      "0            0.998030           0.340278            0.999974      0.000178   \n",
      "1            0.998030           0.382624            0.999974      0.004856   \n",
      "2            0.998030           0.371312            0.999974      0.000149   \n",
      "3            0.998030           0.376048            0.999974      0.012641   \n",
      "4            0.998030           0.398875            0.999974      0.001311   \n",
      "5            0.998030           0.382795            0.999974      0.004922   \n",
      "6            0.998030           0.360563            0.999974      0.007703   \n",
      "7            0.998030           0.393541            0.999974      0.010708   \n",
      "0            0.916170           0.430812            0.927607      0.000247   \n",
      "1            0.916065           0.399362            0.929387      0.000219   \n",
      "2            0.917596           0.430655            0.935709      0.000166   \n",
      "3            0.928583           0.444420            0.937943      0.003182   \n",
      "4            0.906917           0.337422            0.900244      0.001381   \n",
      "5            0.918809           0.468585            0.924647      0.008198   \n",
      "6            0.925269           0.429778            0.930421      0.034664   \n",
      "7            0.933235           0.460740            0.936233      0.016345   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000128        0.042355         0.009943  \n",
      "1        0.000056        0.050119         0.002860  \n",
      "2        0.000246        0.054229         0.005106  \n",
      "3        0.000061        0.034750         0.003149  \n",
      "4        0.000112        0.059322         0.009361  \n",
      "5        0.000085        0.057065         0.002905  \n",
      "6        0.004956        0.058616         0.004101  \n",
      "7        0.000275        0.072911         0.003901  \n",
      "0        0.000361        0.028219         0.000917  \n",
      "1        0.000495        0.056804         0.000917  \n",
      "2        0.001730        0.058674         0.000917  \n",
      "3        0.000464        0.044731         0.000917  \n",
      "4        0.000103        0.068394         0.000917  \n",
      "5        0.000121        0.061167         0.000917  \n",
      "6        0.001815        0.065161         0.000917  \n",
      "7        0.003829        0.075440         0.000917  \n",
      "0        0.000216        0.064206         0.016451  \n",
      "1        0.001236        0.072806         0.006032  \n",
      "2        0.002018        0.066442         0.005654  \n",
      "3        0.001032        0.045671         0.008310  \n",
      "4        0.000067        0.068304         0.003965  \n",
      "5        0.000056        0.037777         0.008769  \n",
      "6        0.000500        0.048145         0.005433  \n",
      "7        0.000540        0.064097         0.006825  \n",
      "0        0.000010        0.076391         0.000917  \n",
      "1        0.000275        0.053725         0.000917  \n",
      "2        0.000319        0.052769         0.000917  \n",
      "3        0.000374        0.068188         0.000917  \n",
      "4        0.000168        0.053285         0.000917  \n",
      "5        0.000100        0.053995         0.000917  \n",
      "6        0.000459        0.066278         0.000917  \n",
      "7        0.000165        0.052212         0.000917  \n",
      "0        0.000139        0.049477         0.011494  \n",
      "1        0.000171        0.041473         0.002178  \n",
      "2        0.000079        0.056342         0.004528  \n",
      "3        0.001883        0.057092         0.003885  \n",
      "4        0.000152        0.089388         0.017250  \n",
      "5        0.000346        0.060525         0.009662  \n",
      "6        0.001403        0.080311         0.005908  \n",
      "7        0.000644        0.047803         0.005972  \n",
      "0        0.000249        0.044310         0.000917  \n",
      "1        0.000110        0.053334         0.000917  \n",
      "2        0.000085        0.079220         0.000917  \n",
      "3        0.000315        0.063623         0.000917  \n",
      "4        0.000078        0.041286         0.000917  \n",
      "5        0.000161        0.051656         0.000917  \n",
      "6        0.000131        0.072526         0.000917  \n",
      "7        0.000124        0.050787         0.000917  \n",
      "0        0.000115        0.070818         0.011735  \n",
      "1        0.000420        0.082970         0.006763  \n",
      "2        0.000161        0.070097         0.007880  \n",
      "3        0.000340        0.059721         0.005999  \n",
      "4        0.000050        0.095946         0.008125  \n",
      "5        0.000034        0.043547         0.004273  \n",
      "6        0.001539        0.060231         0.004437  \n",
      "7        0.001807        0.053432         0.007885  \n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.030515         0.008088         0.510087          0.999327   \n",
      "1       0.074109         0.014175         0.532244          0.999327   \n",
      "2       0.108297         0.023410         0.566013          0.999327   \n",
      "3       0.152059         0.029719         0.567674          0.999327   \n",
      "4       0.087587         0.006201         0.524329          0.999327   \n",
      "5       0.234337         0.013297         0.553500          0.999327   \n",
      "6       0.364388         0.020911         0.520476          0.999327   \n",
      "7       0.492291         0.029228         0.546656          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 0, 2]             mse                 10   \n",
      "1  [1, 0, 2]             mse                 25   \n",
      "2  [1, 0, 2]             mse                 40   \n",
      "3  [1, 0, 2]             mse                 55   \n",
      "4  [1, 0, 2]             mae                 10   \n",
      "5  [1, 0, 2]             mae                 25   \n",
      "6  [1, 0, 2]             mae                 40   \n",
      "7  [1, 0, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                5   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.561333            0.999978           0.566889   \n",
      "1           0.613994            0.999978           0.606001   \n",
      "2           0.626742            0.999978           0.612241   \n",
      "3           0.643035            0.999978           0.606921   \n",
      "4           0.595589            0.999978           0.584735   \n",
      "5           0.599834            0.999978           0.619800   \n",
      "6           0.574362            0.999978           0.580725   \n",
      "7           0.610133            0.999978           0.592280   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.401487            0.999974      0.001222   \n",
      "1             0.99803           0.375858            0.999974      0.015076   \n",
      "2             0.99803           0.458402            0.999974      0.012188   \n",
      "3             0.99803           0.452257            0.999974      0.008633   \n",
      "4             0.99803           0.391896            0.999974      0.005510   \n",
      "5             0.99803           0.440368            0.999974      0.008436   \n",
      "6             0.99803           0.405761            0.999974      0.004622   \n",
      "7             0.99803           0.436871            0.999974      0.008887   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.001682        0.076619         0.000917  \n",
      "1        0.000813        0.110334         0.000917  \n",
      "2        0.005118        0.076120         0.000917  \n",
      "3        0.000766        0.082721         0.000917  \n",
      "4        0.001011        0.093499         0.000917  \n",
      "5        0.000826        0.080198         0.000917  \n",
      "6        0.001109        0.080940         0.000917  \n",
      "7        0.001584        0.077765         0.000917  \n",
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.024136         0.005008         0.473376          0.883712   \n",
      "1        0.060178         0.011970         0.492589          0.913149   \n",
      "2        0.095356         0.018556         0.501884          0.919258   \n",
      "3        0.131009         0.025559         0.495889          0.920909   \n",
      "4        0.050747         0.005121         0.485578          0.894911   \n",
      "5        0.135085         0.011601         0.484008          0.915978   \n",
      "6        0.215881         0.022047         0.491211          0.916460   \n",
      "7        0.287532         0.025424         0.499552          0.918961   \n",
      "0        0.021495         0.004955         0.455315          0.999327   \n",
      "1        0.055847         0.012153         0.482821          0.999327   \n",
      "2        0.085707         0.020287         0.480219          0.999327   \n",
      "3        0.116703         0.025506         0.482323          0.999327   \n",
      "4        0.051623         0.004975         0.441957          0.999327   \n",
      "5        0.130315         0.011985         0.475367          0.999327   \n",
      "6        0.228170         0.020735         0.485410          0.999327   \n",
      "7        0.326909         0.028547         0.480426          0.999327   \n",
      "0        0.024429         0.005034         0.438331          0.886438   \n",
      "1        0.068368         0.014011         0.417784          0.910506   \n",
      "2        0.120861         0.026287         0.452943          0.910942   \n",
      "3        0.146770         0.026211         0.435130          0.917921   \n",
      "4        0.053327         0.005148         0.424631          0.873036   \n",
      "5        0.132050         0.012251         0.447810          0.904868   \n",
      "6        0.217647         0.023733         0.464478          0.909622   \n",
      "7        0.292883         0.026061         0.443942          0.914943   \n",
      "0        0.022064         0.005022         0.429469          0.999327   \n",
      "1        0.057824         0.011764         0.477087          0.999327   \n",
      "2        0.089325         0.019156         0.447721          0.999327   \n",
      "3        0.121582         0.025687         0.465677          0.999327   \n",
      "4        0.050461         0.005172         0.417820          0.999327   \n",
      "5        0.129415         0.011766         0.455314          0.999327   \n",
      "..            ...              ...              ...               ...   \n",
      "2        0.093766         0.018978         0.414147          0.920426   \n",
      "3        0.128777         0.026892         0.423102          0.918386   \n",
      "4        0.049568         0.005000         0.421511          0.883591   \n",
      "5        0.121377         0.012151         0.422526          0.904570   \n",
      "6        0.226937         0.019638         0.434604          0.919032   \n",
      "7        0.268454         0.025964         0.455829          0.913065   \n",
      "0        0.021641         0.005110         0.397968          0.999327   \n",
      "1        0.057207         0.011799         0.452940          0.999327   \n",
      "2        0.086584         0.018918         0.472299          0.999327   \n",
      "3        0.127629         0.025684         0.464409          0.999327   \n",
      "4        0.056939         0.005046         0.447631          0.999327   \n",
      "5        0.135677         0.012172         0.453036          0.999327   \n",
      "6        0.201224         0.019013         0.460067          0.999327   \n",
      "7        0.272294         0.025723         0.461594          0.999327   \n",
      "0        0.026928         0.004926         0.529766          0.914276   \n",
      "1        0.067621         0.012016         0.517010          0.919884   \n",
      "2        0.107500         0.018467         0.529725          0.928579   \n",
      "3        0.150285         0.025328         0.529085          0.929993   \n",
      "4        0.079906         0.005054         0.471788          0.908994   \n",
      "5        0.203138         0.012009         0.522322          0.924236   \n",
      "6        0.340299         0.020804         0.514097          0.925083   \n",
      "7        0.507108         0.029291         0.535624          0.929226   \n",
      "0        0.030515         0.008088         0.510087          0.999327   \n",
      "1        0.074109         0.014175         0.532244          0.999327   \n",
      "2        0.108297         0.023410         0.566013          0.999327   \n",
      "3        0.152059         0.029719         0.567674          0.999327   \n",
      "4        0.087587         0.006201         0.524329          0.999327   \n",
      "5        0.234337         0.013297         0.553500          0.999327   \n",
      "6        0.364388         0.020911         0.520476          0.999327   \n",
      "7        0.492291         0.029228         0.546656          0.999327   \n",
      "\n",
      "   method_ids param_criterion param_n_estimators  \\\n",
      "0   [0, 0, 1]             mse                 10   \n",
      "1   [0, 0, 1]             mse                 25   \n",
      "2   [0, 0, 1]             mse                 40   \n",
      "3   [0, 0, 1]             mse                 55   \n",
      "4   [0, 0, 1]             mae                 10   \n",
      "5   [0, 0, 1]             mae                 25   \n",
      "6   [0, 0, 1]             mae                 40   \n",
      "7   [0, 0, 1]             mae                 55   \n",
      "0   [0, 0, 2]             mse                 10   \n",
      "1   [0, 0, 2]             mse                 25   \n",
      "2   [0, 0, 2]             mse                 40   \n",
      "3   [0, 0, 2]             mse                 55   \n",
      "4   [0, 0, 2]             mae                 10   \n",
      "5   [0, 0, 2]             mae                 25   \n",
      "6   [0, 0, 2]             mae                 40   \n",
      "7   [0, 0, 2]             mae                 55   \n",
      "0   [0, 1, 1]             mse                 10   \n",
      "1   [0, 1, 1]             mse                 25   \n",
      "2   [0, 1, 1]             mse                 40   \n",
      "3   [0, 1, 1]             mse                 55   \n",
      "4   [0, 1, 1]             mae                 10   \n",
      "5   [0, 1, 1]             mae                 25   \n",
      "6   [0, 1, 1]             mae                 40   \n",
      "7   [0, 1, 1]             mae                 55   \n",
      "0   [0, 1, 2]             mse                 10   \n",
      "1   [0, 1, 2]             mse                 25   \n",
      "2   [0, 1, 2]             mse                 40   \n",
      "3   [0, 1, 2]             mse                 55   \n",
      "4   [0, 1, 2]             mae                 10   \n",
      "5   [0, 1, 2]             mae                 25   \n",
      "..        ...             ...                ...   \n",
      "2   [0, 2, 1]             mse                 40   \n",
      "3   [0, 2, 1]             mse                 55   \n",
      "4   [0, 2, 1]             mae                 10   \n",
      "5   [0, 2, 1]             mae                 25   \n",
      "6   [0, 2, 1]             mae                 40   \n",
      "7   [0, 2, 1]             mae                 55   \n",
      "0   [0, 2, 2]             mse                 10   \n",
      "1   [0, 2, 2]             mse                 25   \n",
      "2   [0, 2, 2]             mse                 40   \n",
      "3   [0, 2, 2]             mse                 55   \n",
      "4   [0, 2, 2]             mae                 10   \n",
      "5   [0, 2, 2]             mae                 25   \n",
      "6   [0, 2, 2]             mae                 40   \n",
      "7   [0, 2, 2]             mae                 55   \n",
      "0   [1, 0, 1]             mse                 10   \n",
      "1   [1, 0, 1]             mse                 25   \n",
      "2   [1, 0, 1]             mse                 40   \n",
      "3   [1, 0, 1]             mse                 55   \n",
      "4   [1, 0, 1]             mae                 10   \n",
      "5   [1, 0, 1]             mae                 25   \n",
      "6   [1, 0, 1]             mae                 40   \n",
      "7   [1, 0, 1]             mae                 55   \n",
      "0   [1, 0, 2]             mse                 10   \n",
      "1   [1, 0, 2]             mse                 25   \n",
      "2   [1, 0, 2]             mse                 40   \n",
      "3   [1, 0, 2]             mse                 55   \n",
      "4   [1, 0, 2]             mae                 10   \n",
      "5   [1, 0, 2]             mae                 25   \n",
      "6   [1, 0, 2]             mae                 40   \n",
      "7   [1, 0, 2]             mae                 55   \n",
      "\n",
      "                                         params  rank_test_score  \\\n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "..                                          ...              ...   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                7   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                3   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                4   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                5   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.532909            0.875786           0.441208   \n",
      "1            0.539835            0.910320           0.514354   \n",
      "2            0.565894            0.912127           0.505728   \n",
      "3            0.544117            0.922500           0.478462   \n",
      "4            0.558931            0.882973           0.483207   \n",
      "5            0.564253            0.916684           0.445223   \n",
      "6            0.573519            0.910791           0.453887   \n",
      "7            0.585932            0.915393           0.504125   \n",
      "0            0.492315            0.999978           0.449155   \n",
      "1            0.542346            0.999978           0.499233   \n",
      "2            0.531688            0.999978           0.510485   \n",
      "3            0.525395            0.999978           0.500564   \n",
      "4            0.497328            0.999978           0.482597   \n",
      "5            0.553961            0.999978           0.466189   \n",
      "6            0.566515            0.999978           0.481667   \n",
      "7            0.552411            0.999978           0.512055   \n",
      "0            0.469139            0.880897           0.496814   \n",
      "1            0.502791            0.902003           0.424643   \n",
      "2            0.542659            0.903799           0.430453   \n",
      "3            0.495867            0.906287           0.422693   \n",
      "4            0.512529            0.869530           0.414054   \n",
      "5            0.493631            0.894170           0.448127   \n",
      "6            0.525079            0.904297           0.460221   \n",
      "7            0.508563            0.905416           0.466128   \n",
      "0            0.531158            0.999978           0.408375   \n",
      "1            0.503439            0.999978           0.525550   \n",
      "2            0.495257            0.999978           0.473424   \n",
      "3            0.532163            0.999978           0.492380   \n",
      "4            0.479440            0.999978           0.423900   \n",
      "5            0.514665            0.999978           0.466658   \n",
      "..                ...                 ...                ...   \n",
      "2            0.490336            0.915519           0.356600   \n",
      "3            0.499550            0.915338           0.405926   \n",
      "4            0.530776            0.859296           0.420564   \n",
      "5            0.493540            0.892617           0.427600   \n",
      "6            0.533535            0.910753           0.432182   \n",
      "7            0.520751            0.904628           0.438295   \n",
      "0            0.448027            0.999978           0.405060   \n",
      "1            0.511811            0.999978           0.463751   \n",
      "2            0.564754            0.999978           0.479838   \n",
      "3            0.523986            0.999978           0.492553   \n",
      "4            0.499696            0.999978           0.443762   \n",
      "5            0.505800            0.999978           0.469945   \n",
      "6            0.531864            0.999978           0.487001   \n",
      "7            0.515662            0.999978           0.474997   \n",
      "0            0.593655            0.899050           0.564145   \n",
      "1            0.576332            0.914199           0.574699   \n",
      "2            0.585921            0.932432           0.571995   \n",
      "3            0.569633            0.923452           0.572766   \n",
      "4            0.556942            0.919819           0.520084   \n",
      "5            0.522936            0.929253           0.575438   \n",
      "6            0.567707            0.919558           0.544228   \n",
      "7            0.562966            0.918211           0.582872   \n",
      "0            0.561333            0.999978           0.566889   \n",
      "1            0.613994            0.999978           0.606001   \n",
      "2            0.626742            0.999978           0.612241   \n",
      "3            0.643035            0.999978           0.606921   \n",
      "4            0.595589            0.999978           0.584735   \n",
      "5            0.599834            0.999978           0.619800   \n",
      "6            0.574362            0.999978           0.580725   \n",
      "7            0.610133            0.999978           0.592280   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.877617           0.445372            0.897734      0.000139   \n",
      "1             0.912061           0.423071            0.917066      0.000326   \n",
      "2             0.923810           0.433343            0.921837      0.000400   \n",
      "3             0.923717           0.464570            0.916511      0.000613   \n",
      "4             0.905834           0.413808            0.895927      0.001724   \n",
      "5             0.912121           0.441685            0.919130      0.001826   \n",
      "6             0.920353           0.445343            0.918235      0.007670   \n",
      "7             0.924390           0.407669            0.917102      0.005413   \n",
      "0             0.998030           0.424076            0.999974      0.000405   \n",
      "1             0.998030           0.406243            0.999974      0.002746   \n",
      "2             0.998030           0.397930            0.999974      0.001071   \n",
      "3             0.998030           0.420547            0.999974      0.000255   \n",
      "4             0.998030           0.345349            0.999974      0.001128   \n",
      "5             0.998030           0.405106            0.999974      0.004279   \n",
      "6             0.998030           0.407175            0.999974      0.022929   \n",
      "7             0.998030           0.376038            0.999974      0.028923   \n",
      "0             0.869641           0.348710            0.908778      0.000299   \n",
      "1             0.914159           0.325005            0.915357      0.004393   \n",
      "2             0.911402           0.384754            0.917626      0.004156   \n",
      "3             0.922294           0.386176            0.925181      0.015858   \n",
      "4             0.870999           0.346366            0.878579      0.001481   \n",
      "5             0.915648           0.401179            0.904786      0.002898   \n",
      "6             0.917081           0.407480            0.907487      0.010971   \n",
      "7             0.921047           0.356440            0.918367      0.006066   \n",
      "0             0.998030           0.347781            0.999974      0.000520   \n",
      "1             0.998030           0.401990            0.999974      0.005516   \n",
      "2             0.998030           0.373970            0.999974      0.002415   \n",
      "3             0.998030           0.371773            0.999974      0.002624   \n",
      "4             0.998030           0.349457            0.999974      0.001997   \n",
      "5             0.998030           0.383980            0.999974      0.000475   \n",
      "..                 ...                ...                 ...           ...   \n",
      "2             0.926442           0.394687            0.919317      0.000166   \n",
      "3             0.923868           0.363007            0.915952      0.000726   \n",
      "4             0.893825           0.312019            0.897651      0.001317   \n",
      "5             0.916280           0.345674            0.904813      0.002863   \n",
      "6             0.924144           0.337031            0.922201      0.030296   \n",
      "7             0.916972           0.407742            0.917597      0.005751   \n",
      "0             0.998030           0.340278            0.999974      0.000178   \n",
      "1             0.998030           0.382624            0.999974      0.004856   \n",
      "2             0.998030           0.371312            0.999974      0.000149   \n",
      "3             0.998030           0.376048            0.999974      0.012641   \n",
      "4             0.998030           0.398875            0.999974      0.001311   \n",
      "5             0.998030           0.382795            0.999974      0.004922   \n",
      "6             0.998030           0.360563            0.999974      0.007703   \n",
      "7             0.998030           0.393541            0.999974      0.010708   \n",
      "0             0.916170           0.430812            0.927607      0.000247   \n",
      "1             0.916065           0.399362            0.929387      0.000219   \n",
      "2             0.917596           0.430655            0.935709      0.000166   \n",
      "3             0.928583           0.444420            0.937943      0.003182   \n",
      "4             0.906917           0.337422            0.900244      0.001381   \n",
      "5             0.918809           0.468585            0.924647      0.008198   \n",
      "6             0.925269           0.429778            0.930421      0.034664   \n",
      "7             0.933235           0.460740            0.936233      0.016345   \n",
      "0             0.998030           0.401487            0.999974      0.001222   \n",
      "1             0.998030           0.375858            0.999974      0.015076   \n",
      "2             0.998030           0.458402            0.999974      0.012188   \n",
      "3             0.998030           0.452257            0.999974      0.008633   \n",
      "4             0.998030           0.391896            0.999974      0.005510   \n",
      "5             0.998030           0.440368            0.999974      0.008436   \n",
      "6             0.998030           0.405761            0.999974      0.004622   \n",
      "7             0.998030           0.436871            0.999974      0.008887   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000128        0.042355         0.009943  \n",
      "1         0.000056        0.050119         0.002860  \n",
      "2         0.000246        0.054229         0.005106  \n",
      "3         0.000061        0.034750         0.003149  \n",
      "4         0.000112        0.059322         0.009361  \n",
      "5         0.000085        0.057065         0.002905  \n",
      "6         0.004956        0.058616         0.004101  \n",
      "7         0.000275        0.072911         0.003901  \n",
      "0         0.000361        0.028219         0.000917  \n",
      "1         0.000495        0.056804         0.000917  \n",
      "2         0.001730        0.058674         0.000917  \n",
      "3         0.000464        0.044731         0.000917  \n",
      "4         0.000103        0.068394         0.000917  \n",
      "5         0.000121        0.061167         0.000917  \n",
      "6         0.001815        0.065161         0.000917  \n",
      "7         0.003829        0.075440         0.000917  \n",
      "0         0.000216        0.064206         0.016451  \n",
      "1         0.001236        0.072806         0.006032  \n",
      "2         0.002018        0.066442         0.005654  \n",
      "3         0.001032        0.045671         0.008310  \n",
      "4         0.000067        0.068304         0.003965  \n",
      "5         0.000056        0.037777         0.008769  \n",
      "6         0.000500        0.048145         0.005433  \n",
      "7         0.000540        0.064097         0.006825  \n",
      "0         0.000010        0.076391         0.000917  \n",
      "1         0.000275        0.053725         0.000917  \n",
      "2         0.000319        0.052769         0.000917  \n",
      "3         0.000374        0.068188         0.000917  \n",
      "4         0.000168        0.053285         0.000917  \n",
      "5         0.000100        0.053995         0.000917  \n",
      "..             ...             ...              ...  \n",
      "2         0.000079        0.056342         0.004528  \n",
      "3         0.001883        0.057092         0.003885  \n",
      "4         0.000152        0.089388         0.017250  \n",
      "5         0.000346        0.060525         0.009662  \n",
      "6         0.001403        0.080311         0.005908  \n",
      "7         0.000644        0.047803         0.005972  \n",
      "0         0.000249        0.044310         0.000917  \n",
      "1         0.000110        0.053334         0.000917  \n",
      "2         0.000085        0.079220         0.000917  \n",
      "3         0.000315        0.063623         0.000917  \n",
      "4         0.000078        0.041286         0.000917  \n",
      "5         0.000161        0.051656         0.000917  \n",
      "6         0.000131        0.072526         0.000917  \n",
      "7         0.000124        0.050787         0.000917  \n",
      "0         0.000115        0.070818         0.011735  \n",
      "1         0.000420        0.082970         0.006763  \n",
      "2         0.000161        0.070097         0.007880  \n",
      "3         0.000340        0.059721         0.005999  \n",
      "4         0.000050        0.095946         0.008125  \n",
      "5         0.000034        0.043547         0.004273  \n",
      "6         0.001539        0.060231         0.004437  \n",
      "7         0.001807        0.053432         0.007885  \n",
      "0         0.001682        0.076619         0.000917  \n",
      "1         0.000813        0.110334         0.000917  \n",
      "2         0.005118        0.076120         0.000917  \n",
      "3         0.000766        0.082721         0.000917  \n",
      "4         0.001011        0.093499         0.000917  \n",
      "5         0.000826        0.080198         0.000917  \n",
      "6         0.001109        0.080940         0.000917  \n",
      "7         0.001584        0.077765         0.000917  \n",
      "\n",
      "[64 rows x 19 columns]\n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.030743         0.005673         0.472661          0.904200   \n",
      "1       0.079181         0.014082         0.434305          0.923994   \n",
      "2       0.119693         0.022323         0.465765          0.922783   \n",
      "3       0.159249         0.027426         0.478616          0.925977   \n",
      "4       0.091102         0.005276         0.384041          0.904600   \n",
      "5       0.237513         0.013088         0.471034          0.918397   \n",
      "6       0.383138         0.022711         0.452645          0.926690   \n",
      "7       0.513650         0.028162         0.437374          0.923543   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 1, 1]             mse                 10   \n",
      "1  [1, 1, 1]             mse                 25   \n",
      "2  [1, 1, 1]             mse                 40   \n",
      "3  [1, 1, 1]             mse                 55   \n",
      "4  [1, 1, 1]             mae                 10   \n",
      "5  [1, 1, 1]             mae                 25   \n",
      "6  [1, 1, 1]             mae                 40   \n",
      "7  [1, 1, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                7   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.529877            0.913407           0.474296   \n",
      "1           0.495826            0.919807           0.436976   \n",
      "2           0.491664            0.918327           0.526921   \n",
      "3           0.521132            0.929118           0.535756   \n",
      "4           0.346534            0.896983           0.493151   \n",
      "5           0.518611            0.925493           0.514109   \n",
      "6           0.470176            0.928646           0.515855   \n",
      "7           0.435470            0.929999           0.527282   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.874649           0.413195            0.924545      0.000490   \n",
      "1            0.920527           0.369452            0.931648      0.002282   \n",
      "2            0.919070           0.378431            0.930952      0.002355   \n",
      "3            0.921036           0.378503            0.927776      0.007452   \n",
      "4            0.896086           0.312841            0.920732      0.000950   \n",
      "5            0.903653           0.379872            0.926045      0.013425   \n",
      "6            0.920022           0.371715            0.931401      0.034239   \n",
      "7            0.914613           0.349390            0.926017      0.011770   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000421        0.047691         0.021385  \n",
      "1        0.001913        0.051672         0.005420  \n",
      "2        0.001147        0.063251         0.005785  \n",
      "3        0.001678        0.070853         0.003536  \n",
      "4        0.000251        0.078168         0.011413  \n",
      "5        0.000608        0.064316         0.010428  \n",
      "6        0.001851        0.060047         0.004847  \n",
      "7        0.001139        0.072507         0.006520  \n",
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.024136         0.005008         0.473376          0.883712   \n",
      "1        0.060178         0.011970         0.492589          0.913149   \n",
      "2        0.095356         0.018556         0.501884          0.919258   \n",
      "3        0.131009         0.025559         0.495889          0.920909   \n",
      "4        0.050747         0.005121         0.485578          0.894911   \n",
      "5        0.135085         0.011601         0.484008          0.915978   \n",
      "6        0.215881         0.022047         0.491211          0.916460   \n",
      "7        0.287532         0.025424         0.499552          0.918961   \n",
      "0        0.021495         0.004955         0.455315          0.999327   \n",
      "1        0.055847         0.012153         0.482821          0.999327   \n",
      "2        0.085707         0.020287         0.480219          0.999327   \n",
      "3        0.116703         0.025506         0.482323          0.999327   \n",
      "4        0.051623         0.004975         0.441957          0.999327   \n",
      "5        0.130315         0.011985         0.475367          0.999327   \n",
      "6        0.228170         0.020735         0.485410          0.999327   \n",
      "7        0.326909         0.028547         0.480426          0.999327   \n",
      "0        0.024429         0.005034         0.438331          0.886438   \n",
      "1        0.068368         0.014011         0.417784          0.910506   \n",
      "2        0.120861         0.026287         0.452943          0.910942   \n",
      "3        0.146770         0.026211         0.435130          0.917921   \n",
      "4        0.053327         0.005148         0.424631          0.873036   \n",
      "5        0.132050         0.012251         0.447810          0.904868   \n",
      "6        0.217647         0.023733         0.464478          0.909622   \n",
      "7        0.292883         0.026061         0.443942          0.914943   \n",
      "0        0.022064         0.005022         0.429469          0.999327   \n",
      "1        0.057824         0.011764         0.477087          0.999327   \n",
      "2        0.089325         0.019156         0.447721          0.999327   \n",
      "3        0.121582         0.025687         0.465677          0.999327   \n",
      "4        0.050461         0.005172         0.417820          0.999327   \n",
      "5        0.129415         0.011766         0.455314          0.999327   \n",
      "..            ...              ...              ...               ...   \n",
      "2        0.086584         0.018918         0.472299          0.999327   \n",
      "3        0.127629         0.025684         0.464409          0.999327   \n",
      "4        0.056939         0.005046         0.447631          0.999327   \n",
      "5        0.135677         0.012172         0.453036          0.999327   \n",
      "6        0.201224         0.019013         0.460067          0.999327   \n",
      "7        0.272294         0.025723         0.461594          0.999327   \n",
      "0        0.026928         0.004926         0.529766          0.914276   \n",
      "1        0.067621         0.012016         0.517010          0.919884   \n",
      "2        0.107500         0.018467         0.529725          0.928579   \n",
      "3        0.150285         0.025328         0.529085          0.929993   \n",
      "4        0.079906         0.005054         0.471788          0.908994   \n",
      "5        0.203138         0.012009         0.522322          0.924236   \n",
      "6        0.340299         0.020804         0.514097          0.925083   \n",
      "7        0.507108         0.029291         0.535624          0.929226   \n",
      "0        0.030515         0.008088         0.510087          0.999327   \n",
      "1        0.074109         0.014175         0.532244          0.999327   \n",
      "2        0.108297         0.023410         0.566013          0.999327   \n",
      "3        0.152059         0.029719         0.567674          0.999327   \n",
      "4        0.087587         0.006201         0.524329          0.999327   \n",
      "5        0.234337         0.013297         0.553500          0.999327   \n",
      "6        0.364388         0.020911         0.520476          0.999327   \n",
      "7        0.492291         0.029228         0.546656          0.999327   \n",
      "0        0.030743         0.005673         0.472661          0.904200   \n",
      "1        0.079181         0.014082         0.434305          0.923994   \n",
      "2        0.119693         0.022323         0.465765          0.922783   \n",
      "3        0.159249         0.027426         0.478616          0.925977   \n",
      "4        0.091102         0.005276         0.384041          0.904600   \n",
      "5        0.237513         0.013088         0.471034          0.918397   \n",
      "6        0.383138         0.022711         0.452645          0.926690   \n",
      "7        0.513650         0.028162         0.437374          0.923543   \n",
      "\n",
      "   method_ids param_criterion param_n_estimators  \\\n",
      "0   [0, 0, 1]             mse                 10   \n",
      "1   [0, 0, 1]             mse                 25   \n",
      "2   [0, 0, 1]             mse                 40   \n",
      "3   [0, 0, 1]             mse                 55   \n",
      "4   [0, 0, 1]             mae                 10   \n",
      "5   [0, 0, 1]             mae                 25   \n",
      "6   [0, 0, 1]             mae                 40   \n",
      "7   [0, 0, 1]             mae                 55   \n",
      "0   [0, 0, 2]             mse                 10   \n",
      "1   [0, 0, 2]             mse                 25   \n",
      "2   [0, 0, 2]             mse                 40   \n",
      "3   [0, 0, 2]             mse                 55   \n",
      "4   [0, 0, 2]             mae                 10   \n",
      "5   [0, 0, 2]             mae                 25   \n",
      "6   [0, 0, 2]             mae                 40   \n",
      "7   [0, 0, 2]             mae                 55   \n",
      "0   [0, 1, 1]             mse                 10   \n",
      "1   [0, 1, 1]             mse                 25   \n",
      "2   [0, 1, 1]             mse                 40   \n",
      "3   [0, 1, 1]             mse                 55   \n",
      "4   [0, 1, 1]             mae                 10   \n",
      "5   [0, 1, 1]             mae                 25   \n",
      "6   [0, 1, 1]             mae                 40   \n",
      "7   [0, 1, 1]             mae                 55   \n",
      "0   [0, 1, 2]             mse                 10   \n",
      "1   [0, 1, 2]             mse                 25   \n",
      "2   [0, 1, 2]             mse                 40   \n",
      "3   [0, 1, 2]             mse                 55   \n",
      "4   [0, 1, 2]             mae                 10   \n",
      "5   [0, 1, 2]             mae                 25   \n",
      "..        ...             ...                ...   \n",
      "2   [0, 2, 2]             mse                 40   \n",
      "3   [0, 2, 2]             mse                 55   \n",
      "4   [0, 2, 2]             mae                 10   \n",
      "5   [0, 2, 2]             mae                 25   \n",
      "6   [0, 2, 2]             mae                 40   \n",
      "7   [0, 2, 2]             mae                 55   \n",
      "0   [1, 0, 1]             mse                 10   \n",
      "1   [1, 0, 1]             mse                 25   \n",
      "2   [1, 0, 1]             mse                 40   \n",
      "3   [1, 0, 1]             mse                 55   \n",
      "4   [1, 0, 1]             mae                 10   \n",
      "5   [1, 0, 1]             mae                 25   \n",
      "6   [1, 0, 1]             mae                 40   \n",
      "7   [1, 0, 1]             mae                 55   \n",
      "0   [1, 0, 2]             mse                 10   \n",
      "1   [1, 0, 2]             mse                 25   \n",
      "2   [1, 0, 2]             mse                 40   \n",
      "3   [1, 0, 2]             mse                 55   \n",
      "4   [1, 0, 2]             mae                 10   \n",
      "5   [1, 0, 2]             mae                 25   \n",
      "6   [1, 0, 2]             mae                 40   \n",
      "7   [1, 0, 2]             mae                 55   \n",
      "0   [1, 1, 1]             mse                 10   \n",
      "1   [1, 1, 1]             mse                 25   \n",
      "2   [1, 1, 1]             mse                 40   \n",
      "3   [1, 1, 1]             mse                 55   \n",
      "4   [1, 1, 1]             mae                 10   \n",
      "5   [1, 1, 1]             mae                 25   \n",
      "6   [1, 1, 1]             mae                 40   \n",
      "7   [1, 1, 1]             mae                 55   \n",
      "\n",
      "                                         params  rank_test_score  \\\n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "..                                          ...              ...   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                4   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                5   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                7   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.532909            0.875786           0.441208   \n",
      "1            0.539835            0.910320           0.514354   \n",
      "2            0.565894            0.912127           0.505728   \n",
      "3            0.544117            0.922500           0.478462   \n",
      "4            0.558931            0.882973           0.483207   \n",
      "5            0.564253            0.916684           0.445223   \n",
      "6            0.573519            0.910791           0.453887   \n",
      "7            0.585932            0.915393           0.504125   \n",
      "0            0.492315            0.999978           0.449155   \n",
      "1            0.542346            0.999978           0.499233   \n",
      "2            0.531688            0.999978           0.510485   \n",
      "3            0.525395            0.999978           0.500564   \n",
      "4            0.497328            0.999978           0.482597   \n",
      "5            0.553961            0.999978           0.466189   \n",
      "6            0.566515            0.999978           0.481667   \n",
      "7            0.552411            0.999978           0.512055   \n",
      "0            0.469139            0.880897           0.496814   \n",
      "1            0.502791            0.902003           0.424643   \n",
      "2            0.542659            0.903799           0.430453   \n",
      "3            0.495867            0.906287           0.422693   \n",
      "4            0.512529            0.869530           0.414054   \n",
      "5            0.493631            0.894170           0.448127   \n",
      "6            0.525079            0.904297           0.460221   \n",
      "7            0.508563            0.905416           0.466128   \n",
      "0            0.531158            0.999978           0.408375   \n",
      "1            0.503439            0.999978           0.525550   \n",
      "2            0.495257            0.999978           0.473424   \n",
      "3            0.532163            0.999978           0.492380   \n",
      "4            0.479440            0.999978           0.423900   \n",
      "5            0.514665            0.999978           0.466658   \n",
      "..                ...                 ...                ...   \n",
      "2            0.564754            0.999978           0.479838   \n",
      "3            0.523986            0.999978           0.492553   \n",
      "4            0.499696            0.999978           0.443762   \n",
      "5            0.505800            0.999978           0.469945   \n",
      "6            0.531864            0.999978           0.487001   \n",
      "7            0.515662            0.999978           0.474997   \n",
      "0            0.593655            0.899050           0.564145   \n",
      "1            0.576332            0.914199           0.574699   \n",
      "2            0.585921            0.932432           0.571995   \n",
      "3            0.569633            0.923452           0.572766   \n",
      "4            0.556942            0.919819           0.520084   \n",
      "5            0.522936            0.929253           0.575438   \n",
      "6            0.567707            0.919558           0.544228   \n",
      "7            0.562966            0.918211           0.582872   \n",
      "0            0.561333            0.999978           0.566889   \n",
      "1            0.613994            0.999978           0.606001   \n",
      "2            0.626742            0.999978           0.612241   \n",
      "3            0.643035            0.999978           0.606921   \n",
      "4            0.595589            0.999978           0.584735   \n",
      "5            0.599834            0.999978           0.619800   \n",
      "6            0.574362            0.999978           0.580725   \n",
      "7            0.610133            0.999978           0.592280   \n",
      "0            0.529877            0.913407           0.474296   \n",
      "1            0.495826            0.919807           0.436976   \n",
      "2            0.491664            0.918327           0.526921   \n",
      "3            0.521132            0.929118           0.535756   \n",
      "4            0.346534            0.896983           0.493151   \n",
      "5            0.518611            0.925493           0.514109   \n",
      "6            0.470176            0.928646           0.515855   \n",
      "7            0.435470            0.929999           0.527282   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.877617           0.445372            0.897734      0.000139   \n",
      "1             0.912061           0.423071            0.917066      0.000326   \n",
      "2             0.923810           0.433343            0.921837      0.000400   \n",
      "3             0.923717           0.464570            0.916511      0.000613   \n",
      "4             0.905834           0.413808            0.895927      0.001724   \n",
      "5             0.912121           0.441685            0.919130      0.001826   \n",
      "6             0.920353           0.445343            0.918235      0.007670   \n",
      "7             0.924390           0.407669            0.917102      0.005413   \n",
      "0             0.998030           0.424076            0.999974      0.000405   \n",
      "1             0.998030           0.406243            0.999974      0.002746   \n",
      "2             0.998030           0.397930            0.999974      0.001071   \n",
      "3             0.998030           0.420547            0.999974      0.000255   \n",
      "4             0.998030           0.345349            0.999974      0.001128   \n",
      "5             0.998030           0.405106            0.999974      0.004279   \n",
      "6             0.998030           0.407175            0.999974      0.022929   \n",
      "7             0.998030           0.376038            0.999974      0.028923   \n",
      "0             0.869641           0.348710            0.908778      0.000299   \n",
      "1             0.914159           0.325005            0.915357      0.004393   \n",
      "2             0.911402           0.384754            0.917626      0.004156   \n",
      "3             0.922294           0.386176            0.925181      0.015858   \n",
      "4             0.870999           0.346366            0.878579      0.001481   \n",
      "5             0.915648           0.401179            0.904786      0.002898   \n",
      "6             0.917081           0.407480            0.907487      0.010971   \n",
      "7             0.921047           0.356440            0.918367      0.006066   \n",
      "0             0.998030           0.347781            0.999974      0.000520   \n",
      "1             0.998030           0.401990            0.999974      0.005516   \n",
      "2             0.998030           0.373970            0.999974      0.002415   \n",
      "3             0.998030           0.371773            0.999974      0.002624   \n",
      "4             0.998030           0.349457            0.999974      0.001997   \n",
      "5             0.998030           0.383980            0.999974      0.000475   \n",
      "..                 ...                ...                 ...           ...   \n",
      "2             0.998030           0.371312            0.999974      0.000149   \n",
      "3             0.998030           0.376048            0.999974      0.012641   \n",
      "4             0.998030           0.398875            0.999974      0.001311   \n",
      "5             0.998030           0.382795            0.999974      0.004922   \n",
      "6             0.998030           0.360563            0.999974      0.007703   \n",
      "7             0.998030           0.393541            0.999974      0.010708   \n",
      "0             0.916170           0.430812            0.927607      0.000247   \n",
      "1             0.916065           0.399362            0.929387      0.000219   \n",
      "2             0.917596           0.430655            0.935709      0.000166   \n",
      "3             0.928583           0.444420            0.937943      0.003182   \n",
      "4             0.906917           0.337422            0.900244      0.001381   \n",
      "5             0.918809           0.468585            0.924647      0.008198   \n",
      "6             0.925269           0.429778            0.930421      0.034664   \n",
      "7             0.933235           0.460740            0.936233      0.016345   \n",
      "0             0.998030           0.401487            0.999974      0.001222   \n",
      "1             0.998030           0.375858            0.999974      0.015076   \n",
      "2             0.998030           0.458402            0.999974      0.012188   \n",
      "3             0.998030           0.452257            0.999974      0.008633   \n",
      "4             0.998030           0.391896            0.999974      0.005510   \n",
      "5             0.998030           0.440368            0.999974      0.008436   \n",
      "6             0.998030           0.405761            0.999974      0.004622   \n",
      "7             0.998030           0.436871            0.999974      0.008887   \n",
      "0             0.874649           0.413195            0.924545      0.000490   \n",
      "1             0.920527           0.369452            0.931648      0.002282   \n",
      "2             0.919070           0.378431            0.930952      0.002355   \n",
      "3             0.921036           0.378503            0.927776      0.007452   \n",
      "4             0.896086           0.312841            0.920732      0.000950   \n",
      "5             0.903653           0.379872            0.926045      0.013425   \n",
      "6             0.920022           0.371715            0.931401      0.034239   \n",
      "7             0.914613           0.349390            0.926017      0.011770   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000128        0.042355         0.009943  \n",
      "1         0.000056        0.050119         0.002860  \n",
      "2         0.000246        0.054229         0.005106  \n",
      "3         0.000061        0.034750         0.003149  \n",
      "4         0.000112        0.059322         0.009361  \n",
      "5         0.000085        0.057065         0.002905  \n",
      "6         0.004956        0.058616         0.004101  \n",
      "7         0.000275        0.072911         0.003901  \n",
      "0         0.000361        0.028219         0.000917  \n",
      "1         0.000495        0.056804         0.000917  \n",
      "2         0.001730        0.058674         0.000917  \n",
      "3         0.000464        0.044731         0.000917  \n",
      "4         0.000103        0.068394         0.000917  \n",
      "5         0.000121        0.061167         0.000917  \n",
      "6         0.001815        0.065161         0.000917  \n",
      "7         0.003829        0.075440         0.000917  \n",
      "0         0.000216        0.064206         0.016451  \n",
      "1         0.001236        0.072806         0.006032  \n",
      "2         0.002018        0.066442         0.005654  \n",
      "3         0.001032        0.045671         0.008310  \n",
      "4         0.000067        0.068304         0.003965  \n",
      "5         0.000056        0.037777         0.008769  \n",
      "6         0.000500        0.048145         0.005433  \n",
      "7         0.000540        0.064097         0.006825  \n",
      "0         0.000010        0.076391         0.000917  \n",
      "1         0.000275        0.053725         0.000917  \n",
      "2         0.000319        0.052769         0.000917  \n",
      "3         0.000374        0.068188         0.000917  \n",
      "4         0.000168        0.053285         0.000917  \n",
      "5         0.000100        0.053995         0.000917  \n",
      "..             ...             ...              ...  \n",
      "2         0.000085        0.079220         0.000917  \n",
      "3         0.000315        0.063623         0.000917  \n",
      "4         0.000078        0.041286         0.000917  \n",
      "5         0.000161        0.051656         0.000917  \n",
      "6         0.000131        0.072526         0.000917  \n",
      "7         0.000124        0.050787         0.000917  \n",
      "0         0.000115        0.070818         0.011735  \n",
      "1         0.000420        0.082970         0.006763  \n",
      "2         0.000161        0.070097         0.007880  \n",
      "3         0.000340        0.059721         0.005999  \n",
      "4         0.000050        0.095946         0.008125  \n",
      "5         0.000034        0.043547         0.004273  \n",
      "6         0.001539        0.060231         0.004437  \n",
      "7         0.001807        0.053432         0.007885  \n",
      "0         0.001682        0.076619         0.000917  \n",
      "1         0.000813        0.110334         0.000917  \n",
      "2         0.005118        0.076120         0.000917  \n",
      "3         0.000766        0.082721         0.000917  \n",
      "4         0.001011        0.093499         0.000917  \n",
      "5         0.000826        0.080198         0.000917  \n",
      "6         0.001109        0.080940         0.000917  \n",
      "7         0.001584        0.077765         0.000917  \n",
      "0         0.000421        0.047691         0.021385  \n",
      "1         0.001913        0.051672         0.005420  \n",
      "2         0.001147        0.063251         0.005785  \n",
      "3         0.001678        0.070853         0.003536  \n",
      "4         0.000251        0.078168         0.011413  \n",
      "5         0.000608        0.064316         0.010428  \n",
      "6         0.001851        0.060047         0.004847  \n",
      "7         0.001139        0.072507         0.006520  \n",
      "\n",
      "[72 rows x 19 columns]\n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.027020         0.005336         0.480873          0.999327   \n",
      "1       0.068788         0.012659         0.486692          0.999327   \n",
      "2       0.107790         0.023480         0.510219          0.999327   \n",
      "3       0.145789         0.027460         0.474844          0.999327   \n",
      "4       0.093866         0.006053         0.443603          0.999327   \n",
      "5       0.241093         0.014588         0.477887          0.999327   \n",
      "6       0.384652         0.022765         0.491559          0.999327   \n",
      "7       0.524458         0.037809         0.466708          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 1, 2]             mse                 10   \n",
      "1  [1, 1, 2]             mse                 25   \n",
      "2  [1, 1, 2]             mse                 40   \n",
      "3  [1, 1, 2]             mse                 55   \n",
      "4  [1, 1, 2]             mae                 10   \n",
      "5  [1, 1, 2]             mae                 25   \n",
      "6  [1, 1, 2]             mae                 40   \n",
      "7  [1, 1, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                4   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                3   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                7   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.551075            0.999978           0.558273   \n",
      "1           0.492013            0.999978           0.553150   \n",
      "2           0.538011            0.999978           0.576530   \n",
      "3           0.525228            0.999978           0.567881   \n",
      "4           0.459749            0.999978           0.535967   \n",
      "5           0.497923            0.999978           0.539135   \n",
      "6           0.499860            0.999978           0.603550   \n",
      "7           0.470177            0.999978           0.577105   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.332517            0.999974      0.001776   \n",
      "1             0.99803           0.414854            0.999974      0.003099   \n",
      "2             0.99803           0.415819            0.999974      0.000128   \n",
      "3             0.99803           0.330883            0.999974      0.002054   \n",
      "4             0.99803           0.334918            0.999974      0.003281   \n",
      "5             0.99803           0.396388            0.999974      0.009429   \n",
      "6             0.99803           0.371179            0.999974      0.015930   \n",
      "7             0.99803           0.352804            0.999974      0.025848   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000272        0.104664         0.000917  \n",
      "1        0.000308        0.056485         0.000917  \n",
      "2        0.001063        0.068408         0.000917  \n",
      "3        0.000370        0.103009         0.000917  \n",
      "4        0.000542        0.082731         0.000917  \n",
      "5        0.001277        0.059890         0.000917  \n",
      "6        0.001539        0.094879         0.000917  \n",
      "7        0.006585        0.091440         0.000917  \n",
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.024136         0.005008         0.473376          0.883712   \n",
      "1        0.060178         0.011970         0.492589          0.913149   \n",
      "2        0.095356         0.018556         0.501884          0.919258   \n",
      "3        0.131009         0.025559         0.495889          0.920909   \n",
      "4        0.050747         0.005121         0.485578          0.894911   \n",
      "5        0.135085         0.011601         0.484008          0.915978   \n",
      "6        0.215881         0.022047         0.491211          0.916460   \n",
      "7        0.287532         0.025424         0.499552          0.918961   \n",
      "0        0.021495         0.004955         0.455315          0.999327   \n",
      "1        0.055847         0.012153         0.482821          0.999327   \n",
      "2        0.085707         0.020287         0.480219          0.999327   \n",
      "3        0.116703         0.025506         0.482323          0.999327   \n",
      "4        0.051623         0.004975         0.441957          0.999327   \n",
      "5        0.130315         0.011985         0.475367          0.999327   \n",
      "6        0.228170         0.020735         0.485410          0.999327   \n",
      "7        0.326909         0.028547         0.480426          0.999327   \n",
      "0        0.024429         0.005034         0.438331          0.886438   \n",
      "1        0.068368         0.014011         0.417784          0.910506   \n",
      "2        0.120861         0.026287         0.452943          0.910942   \n",
      "3        0.146770         0.026211         0.435130          0.917921   \n",
      "4        0.053327         0.005148         0.424631          0.873036   \n",
      "5        0.132050         0.012251         0.447810          0.904868   \n",
      "6        0.217647         0.023733         0.464478          0.909622   \n",
      "7        0.292883         0.026061         0.443942          0.914943   \n",
      "0        0.022064         0.005022         0.429469          0.999327   \n",
      "1        0.057824         0.011764         0.477087          0.999327   \n",
      "2        0.089325         0.019156         0.447721          0.999327   \n",
      "3        0.121582         0.025687         0.465677          0.999327   \n",
      "4        0.050461         0.005172         0.417820          0.999327   \n",
      "5        0.129415         0.011766         0.455314          0.999327   \n",
      "..            ...              ...              ...               ...   \n",
      "2        0.107500         0.018467         0.529725          0.928579   \n",
      "3        0.150285         0.025328         0.529085          0.929993   \n",
      "4        0.079906         0.005054         0.471788          0.908994   \n",
      "5        0.203138         0.012009         0.522322          0.924236   \n",
      "6        0.340299         0.020804         0.514097          0.925083   \n",
      "7        0.507108         0.029291         0.535624          0.929226   \n",
      "0        0.030515         0.008088         0.510087          0.999327   \n",
      "1        0.074109         0.014175         0.532244          0.999327   \n",
      "2        0.108297         0.023410         0.566013          0.999327   \n",
      "3        0.152059         0.029719         0.567674          0.999327   \n",
      "4        0.087587         0.006201         0.524329          0.999327   \n",
      "5        0.234337         0.013297         0.553500          0.999327   \n",
      "6        0.364388         0.020911         0.520476          0.999327   \n",
      "7        0.492291         0.029228         0.546656          0.999327   \n",
      "0        0.030743         0.005673         0.472661          0.904200   \n",
      "1        0.079181         0.014082         0.434305          0.923994   \n",
      "2        0.119693         0.022323         0.465765          0.922783   \n",
      "3        0.159249         0.027426         0.478616          0.925977   \n",
      "4        0.091102         0.005276         0.384041          0.904600   \n",
      "5        0.237513         0.013088         0.471034          0.918397   \n",
      "6        0.383138         0.022711         0.452645          0.926690   \n",
      "7        0.513650         0.028162         0.437374          0.923543   \n",
      "0        0.027020         0.005336         0.480873          0.999327   \n",
      "1        0.068788         0.012659         0.486692          0.999327   \n",
      "2        0.107790         0.023480         0.510219          0.999327   \n",
      "3        0.145789         0.027460         0.474844          0.999327   \n",
      "4        0.093866         0.006053         0.443603          0.999327   \n",
      "5        0.241093         0.014588         0.477887          0.999327   \n",
      "6        0.384652         0.022765         0.491559          0.999327   \n",
      "7        0.524458         0.037809         0.466708          0.999327   \n",
      "\n",
      "   method_ids param_criterion param_n_estimators  \\\n",
      "0   [0, 0, 1]             mse                 10   \n",
      "1   [0, 0, 1]             mse                 25   \n",
      "2   [0, 0, 1]             mse                 40   \n",
      "3   [0, 0, 1]             mse                 55   \n",
      "4   [0, 0, 1]             mae                 10   \n",
      "5   [0, 0, 1]             mae                 25   \n",
      "6   [0, 0, 1]             mae                 40   \n",
      "7   [0, 0, 1]             mae                 55   \n",
      "0   [0, 0, 2]             mse                 10   \n",
      "1   [0, 0, 2]             mse                 25   \n",
      "2   [0, 0, 2]             mse                 40   \n",
      "3   [0, 0, 2]             mse                 55   \n",
      "4   [0, 0, 2]             mae                 10   \n",
      "5   [0, 0, 2]             mae                 25   \n",
      "6   [0, 0, 2]             mae                 40   \n",
      "7   [0, 0, 2]             mae                 55   \n",
      "0   [0, 1, 1]             mse                 10   \n",
      "1   [0, 1, 1]             mse                 25   \n",
      "2   [0, 1, 1]             mse                 40   \n",
      "3   [0, 1, 1]             mse                 55   \n",
      "4   [0, 1, 1]             mae                 10   \n",
      "5   [0, 1, 1]             mae                 25   \n",
      "6   [0, 1, 1]             mae                 40   \n",
      "7   [0, 1, 1]             mae                 55   \n",
      "0   [0, 1, 2]             mse                 10   \n",
      "1   [0, 1, 2]             mse                 25   \n",
      "2   [0, 1, 2]             mse                 40   \n",
      "3   [0, 1, 2]             mse                 55   \n",
      "4   [0, 1, 2]             mae                 10   \n",
      "5   [0, 1, 2]             mae                 25   \n",
      "..        ...             ...                ...   \n",
      "2   [1, 0, 1]             mse                 40   \n",
      "3   [1, 0, 1]             mse                 55   \n",
      "4   [1, 0, 1]             mae                 10   \n",
      "5   [1, 0, 1]             mae                 25   \n",
      "6   [1, 0, 1]             mae                 40   \n",
      "7   [1, 0, 1]             mae                 55   \n",
      "0   [1, 0, 2]             mse                 10   \n",
      "1   [1, 0, 2]             mse                 25   \n",
      "2   [1, 0, 2]             mse                 40   \n",
      "3   [1, 0, 2]             mse                 55   \n",
      "4   [1, 0, 2]             mae                 10   \n",
      "5   [1, 0, 2]             mae                 25   \n",
      "6   [1, 0, 2]             mae                 40   \n",
      "7   [1, 0, 2]             mae                 55   \n",
      "0   [1, 1, 1]             mse                 10   \n",
      "1   [1, 1, 1]             mse                 25   \n",
      "2   [1, 1, 1]             mse                 40   \n",
      "3   [1, 1, 1]             mse                 55   \n",
      "4   [1, 1, 1]             mae                 10   \n",
      "5   [1, 1, 1]             mae                 25   \n",
      "6   [1, 1, 1]             mae                 40   \n",
      "7   [1, 1, 1]             mae                 55   \n",
      "0   [1, 1, 2]             mse                 10   \n",
      "1   [1, 1, 2]             mse                 25   \n",
      "2   [1, 1, 2]             mse                 40   \n",
      "3   [1, 1, 2]             mse                 55   \n",
      "4   [1, 1, 2]             mae                 10   \n",
      "5   [1, 1, 2]             mae                 25   \n",
      "6   [1, 1, 2]             mae                 40   \n",
      "7   [1, 1, 2]             mae                 55   \n",
      "\n",
      "                                         params  rank_test_score  \\\n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "..                                          ...              ...   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                5   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                7   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                4   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                3   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                7   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.532909            0.875786           0.441208   \n",
      "1            0.539835            0.910320           0.514354   \n",
      "2            0.565894            0.912127           0.505728   \n",
      "3            0.544117            0.922500           0.478462   \n",
      "4            0.558931            0.882973           0.483207   \n",
      "5            0.564253            0.916684           0.445223   \n",
      "6            0.573519            0.910791           0.453887   \n",
      "7            0.585932            0.915393           0.504125   \n",
      "0            0.492315            0.999978           0.449155   \n",
      "1            0.542346            0.999978           0.499233   \n",
      "2            0.531688            0.999978           0.510485   \n",
      "3            0.525395            0.999978           0.500564   \n",
      "4            0.497328            0.999978           0.482597   \n",
      "5            0.553961            0.999978           0.466189   \n",
      "6            0.566515            0.999978           0.481667   \n",
      "7            0.552411            0.999978           0.512055   \n",
      "0            0.469139            0.880897           0.496814   \n",
      "1            0.502791            0.902003           0.424643   \n",
      "2            0.542659            0.903799           0.430453   \n",
      "3            0.495867            0.906287           0.422693   \n",
      "4            0.512529            0.869530           0.414054   \n",
      "5            0.493631            0.894170           0.448127   \n",
      "6            0.525079            0.904297           0.460221   \n",
      "7            0.508563            0.905416           0.466128   \n",
      "0            0.531158            0.999978           0.408375   \n",
      "1            0.503439            0.999978           0.525550   \n",
      "2            0.495257            0.999978           0.473424   \n",
      "3            0.532163            0.999978           0.492380   \n",
      "4            0.479440            0.999978           0.423900   \n",
      "5            0.514665            0.999978           0.466658   \n",
      "..                ...                 ...                ...   \n",
      "2            0.585921            0.932432           0.571995   \n",
      "3            0.569633            0.923452           0.572766   \n",
      "4            0.556942            0.919819           0.520084   \n",
      "5            0.522936            0.929253           0.575438   \n",
      "6            0.567707            0.919558           0.544228   \n",
      "7            0.562966            0.918211           0.582872   \n",
      "0            0.561333            0.999978           0.566889   \n",
      "1            0.613994            0.999978           0.606001   \n",
      "2            0.626742            0.999978           0.612241   \n",
      "3            0.643035            0.999978           0.606921   \n",
      "4            0.595589            0.999978           0.584735   \n",
      "5            0.599834            0.999978           0.619800   \n",
      "6            0.574362            0.999978           0.580725   \n",
      "7            0.610133            0.999978           0.592280   \n",
      "0            0.529877            0.913407           0.474296   \n",
      "1            0.495826            0.919807           0.436976   \n",
      "2            0.491664            0.918327           0.526921   \n",
      "3            0.521132            0.929118           0.535756   \n",
      "4            0.346534            0.896983           0.493151   \n",
      "5            0.518611            0.925493           0.514109   \n",
      "6            0.470176            0.928646           0.515855   \n",
      "7            0.435470            0.929999           0.527282   \n",
      "0            0.551075            0.999978           0.558273   \n",
      "1            0.492013            0.999978           0.553150   \n",
      "2            0.538011            0.999978           0.576530   \n",
      "3            0.525228            0.999978           0.567881   \n",
      "4            0.459749            0.999978           0.535967   \n",
      "5            0.497923            0.999978           0.539135   \n",
      "6            0.499860            0.999978           0.603550   \n",
      "7            0.470177            0.999978           0.577105   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.877617           0.445372            0.897734      0.000139   \n",
      "1             0.912061           0.423071            0.917066      0.000326   \n",
      "2             0.923810           0.433343            0.921837      0.000400   \n",
      "3             0.923717           0.464570            0.916511      0.000613   \n",
      "4             0.905834           0.413808            0.895927      0.001724   \n",
      "5             0.912121           0.441685            0.919130      0.001826   \n",
      "6             0.920353           0.445343            0.918235      0.007670   \n",
      "7             0.924390           0.407669            0.917102      0.005413   \n",
      "0             0.998030           0.424076            0.999974      0.000405   \n",
      "1             0.998030           0.406243            0.999974      0.002746   \n",
      "2             0.998030           0.397930            0.999974      0.001071   \n",
      "3             0.998030           0.420547            0.999974      0.000255   \n",
      "4             0.998030           0.345349            0.999974      0.001128   \n",
      "5             0.998030           0.405106            0.999974      0.004279   \n",
      "6             0.998030           0.407175            0.999974      0.022929   \n",
      "7             0.998030           0.376038            0.999974      0.028923   \n",
      "0             0.869641           0.348710            0.908778      0.000299   \n",
      "1             0.914159           0.325005            0.915357      0.004393   \n",
      "2             0.911402           0.384754            0.917626      0.004156   \n",
      "3             0.922294           0.386176            0.925181      0.015858   \n",
      "4             0.870999           0.346366            0.878579      0.001481   \n",
      "5             0.915648           0.401179            0.904786      0.002898   \n",
      "6             0.917081           0.407480            0.907487      0.010971   \n",
      "7             0.921047           0.356440            0.918367      0.006066   \n",
      "0             0.998030           0.347781            0.999974      0.000520   \n",
      "1             0.998030           0.401990            0.999974      0.005516   \n",
      "2             0.998030           0.373970            0.999974      0.002415   \n",
      "3             0.998030           0.371773            0.999974      0.002624   \n",
      "4             0.998030           0.349457            0.999974      0.001997   \n",
      "5             0.998030           0.383980            0.999974      0.000475   \n",
      "..                 ...                ...                 ...           ...   \n",
      "2             0.917596           0.430655            0.935709      0.000166   \n",
      "3             0.928583           0.444420            0.937943      0.003182   \n",
      "4             0.906917           0.337422            0.900244      0.001381   \n",
      "5             0.918809           0.468585            0.924647      0.008198   \n",
      "6             0.925269           0.429778            0.930421      0.034664   \n",
      "7             0.933235           0.460740            0.936233      0.016345   \n",
      "0             0.998030           0.401487            0.999974      0.001222   \n",
      "1             0.998030           0.375858            0.999974      0.015076   \n",
      "2             0.998030           0.458402            0.999974      0.012188   \n",
      "3             0.998030           0.452257            0.999974      0.008633   \n",
      "4             0.998030           0.391896            0.999974      0.005510   \n",
      "5             0.998030           0.440368            0.999974      0.008436   \n",
      "6             0.998030           0.405761            0.999974      0.004622   \n",
      "7             0.998030           0.436871            0.999974      0.008887   \n",
      "0             0.874649           0.413195            0.924545      0.000490   \n",
      "1             0.920527           0.369452            0.931648      0.002282   \n",
      "2             0.919070           0.378431            0.930952      0.002355   \n",
      "3             0.921036           0.378503            0.927776      0.007452   \n",
      "4             0.896086           0.312841            0.920732      0.000950   \n",
      "5             0.903653           0.379872            0.926045      0.013425   \n",
      "6             0.920022           0.371715            0.931401      0.034239   \n",
      "7             0.914613           0.349390            0.926017      0.011770   \n",
      "0             0.998030           0.332517            0.999974      0.001776   \n",
      "1             0.998030           0.414854            0.999974      0.003099   \n",
      "2             0.998030           0.415819            0.999974      0.000128   \n",
      "3             0.998030           0.330883            0.999974      0.002054   \n",
      "4             0.998030           0.334918            0.999974      0.003281   \n",
      "5             0.998030           0.396388            0.999974      0.009429   \n",
      "6             0.998030           0.371179            0.999974      0.015930   \n",
      "7             0.998030           0.352804            0.999974      0.025848   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000128        0.042355         0.009943  \n",
      "1         0.000056        0.050119         0.002860  \n",
      "2         0.000246        0.054229         0.005106  \n",
      "3         0.000061        0.034750         0.003149  \n",
      "4         0.000112        0.059322         0.009361  \n",
      "5         0.000085        0.057065         0.002905  \n",
      "6         0.004956        0.058616         0.004101  \n",
      "7         0.000275        0.072911         0.003901  \n",
      "0         0.000361        0.028219         0.000917  \n",
      "1         0.000495        0.056804         0.000917  \n",
      "2         0.001730        0.058674         0.000917  \n",
      "3         0.000464        0.044731         0.000917  \n",
      "4         0.000103        0.068394         0.000917  \n",
      "5         0.000121        0.061167         0.000917  \n",
      "6         0.001815        0.065161         0.000917  \n",
      "7         0.003829        0.075440         0.000917  \n",
      "0         0.000216        0.064206         0.016451  \n",
      "1         0.001236        0.072806         0.006032  \n",
      "2         0.002018        0.066442         0.005654  \n",
      "3         0.001032        0.045671         0.008310  \n",
      "4         0.000067        0.068304         0.003965  \n",
      "5         0.000056        0.037777         0.008769  \n",
      "6         0.000500        0.048145         0.005433  \n",
      "7         0.000540        0.064097         0.006825  \n",
      "0         0.000010        0.076391         0.000917  \n",
      "1         0.000275        0.053725         0.000917  \n",
      "2         0.000319        0.052769         0.000917  \n",
      "3         0.000374        0.068188         0.000917  \n",
      "4         0.000168        0.053285         0.000917  \n",
      "5         0.000100        0.053995         0.000917  \n",
      "..             ...             ...              ...  \n",
      "2         0.000161        0.070097         0.007880  \n",
      "3         0.000340        0.059721         0.005999  \n",
      "4         0.000050        0.095946         0.008125  \n",
      "5         0.000034        0.043547         0.004273  \n",
      "6         0.001539        0.060231         0.004437  \n",
      "7         0.001807        0.053432         0.007885  \n",
      "0         0.001682        0.076619         0.000917  \n",
      "1         0.000813        0.110334         0.000917  \n",
      "2         0.005118        0.076120         0.000917  \n",
      "3         0.000766        0.082721         0.000917  \n",
      "4         0.001011        0.093499         0.000917  \n",
      "5         0.000826        0.080198         0.000917  \n",
      "6         0.001109        0.080940         0.000917  \n",
      "7         0.001584        0.077765         0.000917  \n",
      "0         0.000421        0.047691         0.021385  \n",
      "1         0.001913        0.051672         0.005420  \n",
      "2         0.001147        0.063251         0.005785  \n",
      "3         0.001678        0.070853         0.003536  \n",
      "4         0.000251        0.078168         0.011413  \n",
      "5         0.000608        0.064316         0.010428  \n",
      "6         0.001851        0.060047         0.004847  \n",
      "7         0.001139        0.072507         0.006520  \n",
      "0         0.000272        0.104664         0.000917  \n",
      "1         0.000308        0.056485         0.000917  \n",
      "2         0.001063        0.068408         0.000917  \n",
      "3         0.000370        0.103009         0.000917  \n",
      "4         0.000542        0.082731         0.000917  \n",
      "5         0.001277        0.059890         0.000917  \n",
      "6         0.001539        0.094879         0.000917  \n",
      "7         0.006585        0.091440         0.000917  \n",
      "\n",
      "[80 rows x 19 columns]\n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.027670         0.005471         0.572118          0.930895   \n",
      "1       0.087699         0.014203         0.586321          0.934560   \n",
      "2       0.123745         0.021479         0.615974          0.941097   \n",
      "3       0.156221         0.028420         0.617331          0.942951   \n",
      "4       0.076248         0.005222         0.563950          0.923866   \n",
      "5       0.199907         0.014017         0.608719          0.934413   \n",
      "6       0.300280         0.020285         0.588369          0.936139   \n",
      "7       0.439856         0.027308         0.618587          0.940927   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 2, 1]             mse                 10   \n",
      "1  [1, 2, 1]             mse                 25   \n",
      "2  [1, 2, 1]             mse                 40   \n",
      "3  [1, 2, 1]             mse                 55   \n",
      "4  [1, 2, 1]             mae                 10   \n",
      "5  [1, 2, 1]             mae                 25   \n",
      "6  [1, 2, 1]             mae                 40   \n",
      "7  [1, 2, 1]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                4   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.641078            0.922661           0.549063   \n",
      "1           0.696969            0.929801           0.558220   \n",
      "2           0.693874            0.929307           0.626593   \n",
      "3           0.715424            0.934945           0.579221   \n",
      "4           0.582810            0.903686           0.594502   \n",
      "5           0.635584            0.933998           0.660207   \n",
      "6           0.655826            0.923715           0.571048   \n",
      "7           0.662526            0.932603           0.615139   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.937908           0.525471            0.932116      0.001447   \n",
      "1            0.924635           0.502585            0.949243      0.003171   \n",
      "2            0.941446           0.526619            0.952537      0.006429   \n",
      "3            0.947193           0.556294            0.946716      0.006242   \n",
      "4            0.928826           0.514336            0.939085      0.005195   \n",
      "5            0.920911           0.530077            0.948331      0.012959   \n",
      "6            0.933144           0.537507            0.951558      0.012898   \n",
      "7            0.945497           0.577623            0.944681      0.019597   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000494        0.049958         0.006284  \n",
      "1        0.000462        0.081862         0.010595  \n",
      "2        0.003365        0.068751         0.009487  \n",
      "3        0.001802        0.070357         0.005665  \n",
      "4        0.000098        0.035313         0.014871  \n",
      "5        0.000620        0.056365         0.011198  \n",
      "6        0.001610        0.049865         0.011562  \n",
      "7        0.000795        0.034777         0.005895  \n",
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.024136         0.005008         0.473376          0.883712   \n",
      "1        0.060178         0.011970         0.492589          0.913149   \n",
      "2        0.095356         0.018556         0.501884          0.919258   \n",
      "3        0.131009         0.025559         0.495889          0.920909   \n",
      "4        0.050747         0.005121         0.485578          0.894911   \n",
      "5        0.135085         0.011601         0.484008          0.915978   \n",
      "6        0.215881         0.022047         0.491211          0.916460   \n",
      "7        0.287532         0.025424         0.499552          0.918961   \n",
      "0        0.021495         0.004955         0.455315          0.999327   \n",
      "1        0.055847         0.012153         0.482821          0.999327   \n",
      "2        0.085707         0.020287         0.480219          0.999327   \n",
      "3        0.116703         0.025506         0.482323          0.999327   \n",
      "4        0.051623         0.004975         0.441957          0.999327   \n",
      "5        0.130315         0.011985         0.475367          0.999327   \n",
      "6        0.228170         0.020735         0.485410          0.999327   \n",
      "7        0.326909         0.028547         0.480426          0.999327   \n",
      "0        0.024429         0.005034         0.438331          0.886438   \n",
      "1        0.068368         0.014011         0.417784          0.910506   \n",
      "2        0.120861         0.026287         0.452943          0.910942   \n",
      "3        0.146770         0.026211         0.435130          0.917921   \n",
      "4        0.053327         0.005148         0.424631          0.873036   \n",
      "5        0.132050         0.012251         0.447810          0.904868   \n",
      "6        0.217647         0.023733         0.464478          0.909622   \n",
      "7        0.292883         0.026061         0.443942          0.914943   \n",
      "0        0.022064         0.005022         0.429469          0.999327   \n",
      "1        0.057824         0.011764         0.477087          0.999327   \n",
      "2        0.089325         0.019156         0.447721          0.999327   \n",
      "3        0.121582         0.025687         0.465677          0.999327   \n",
      "4        0.050461         0.005172         0.417820          0.999327   \n",
      "5        0.129415         0.011766         0.455314          0.999327   \n",
      "..            ...              ...              ...               ...   \n",
      "2        0.108297         0.023410         0.566013          0.999327   \n",
      "3        0.152059         0.029719         0.567674          0.999327   \n",
      "4        0.087587         0.006201         0.524329          0.999327   \n",
      "5        0.234337         0.013297         0.553500          0.999327   \n",
      "6        0.364388         0.020911         0.520476          0.999327   \n",
      "7        0.492291         0.029228         0.546656          0.999327   \n",
      "0        0.030743         0.005673         0.472661          0.904200   \n",
      "1        0.079181         0.014082         0.434305          0.923994   \n",
      "2        0.119693         0.022323         0.465765          0.922783   \n",
      "3        0.159249         0.027426         0.478616          0.925977   \n",
      "4        0.091102         0.005276         0.384041          0.904600   \n",
      "5        0.237513         0.013088         0.471034          0.918397   \n",
      "6        0.383138         0.022711         0.452645          0.926690   \n",
      "7        0.513650         0.028162         0.437374          0.923543   \n",
      "0        0.027020         0.005336         0.480873          0.999327   \n",
      "1        0.068788         0.012659         0.486692          0.999327   \n",
      "2        0.107790         0.023480         0.510219          0.999327   \n",
      "3        0.145789         0.027460         0.474844          0.999327   \n",
      "4        0.093866         0.006053         0.443603          0.999327   \n",
      "5        0.241093         0.014588         0.477887          0.999327   \n",
      "6        0.384652         0.022765         0.491559          0.999327   \n",
      "7        0.524458         0.037809         0.466708          0.999327   \n",
      "0        0.027670         0.005471         0.572118          0.930895   \n",
      "1        0.087699         0.014203         0.586321          0.934560   \n",
      "2        0.123745         0.021479         0.615974          0.941097   \n",
      "3        0.156221         0.028420         0.617331          0.942951   \n",
      "4        0.076248         0.005222         0.563950          0.923866   \n",
      "5        0.199907         0.014017         0.608719          0.934413   \n",
      "6        0.300280         0.020285         0.588369          0.936139   \n",
      "7        0.439856         0.027308         0.618587          0.940927   \n",
      "\n",
      "   method_ids param_criterion param_n_estimators  \\\n",
      "0   [0, 0, 1]             mse                 10   \n",
      "1   [0, 0, 1]             mse                 25   \n",
      "2   [0, 0, 1]             mse                 40   \n",
      "3   [0, 0, 1]             mse                 55   \n",
      "4   [0, 0, 1]             mae                 10   \n",
      "5   [0, 0, 1]             mae                 25   \n",
      "6   [0, 0, 1]             mae                 40   \n",
      "7   [0, 0, 1]             mae                 55   \n",
      "0   [0, 0, 2]             mse                 10   \n",
      "1   [0, 0, 2]             mse                 25   \n",
      "2   [0, 0, 2]             mse                 40   \n",
      "3   [0, 0, 2]             mse                 55   \n",
      "4   [0, 0, 2]             mae                 10   \n",
      "5   [0, 0, 2]             mae                 25   \n",
      "6   [0, 0, 2]             mae                 40   \n",
      "7   [0, 0, 2]             mae                 55   \n",
      "0   [0, 1, 1]             mse                 10   \n",
      "1   [0, 1, 1]             mse                 25   \n",
      "2   [0, 1, 1]             mse                 40   \n",
      "3   [0, 1, 1]             mse                 55   \n",
      "4   [0, 1, 1]             mae                 10   \n",
      "5   [0, 1, 1]             mae                 25   \n",
      "6   [0, 1, 1]             mae                 40   \n",
      "7   [0, 1, 1]             mae                 55   \n",
      "0   [0, 1, 2]             mse                 10   \n",
      "1   [0, 1, 2]             mse                 25   \n",
      "2   [0, 1, 2]             mse                 40   \n",
      "3   [0, 1, 2]             mse                 55   \n",
      "4   [0, 1, 2]             mae                 10   \n",
      "5   [0, 1, 2]             mae                 25   \n",
      "..        ...             ...                ...   \n",
      "2   [1, 0, 2]             mse                 40   \n",
      "3   [1, 0, 2]             mse                 55   \n",
      "4   [1, 0, 2]             mae                 10   \n",
      "5   [1, 0, 2]             mae                 25   \n",
      "6   [1, 0, 2]             mae                 40   \n",
      "7   [1, 0, 2]             mae                 55   \n",
      "0   [1, 1, 1]             mse                 10   \n",
      "1   [1, 1, 1]             mse                 25   \n",
      "2   [1, 1, 1]             mse                 40   \n",
      "3   [1, 1, 1]             mse                 55   \n",
      "4   [1, 1, 1]             mae                 10   \n",
      "5   [1, 1, 1]             mae                 25   \n",
      "6   [1, 1, 1]             mae                 40   \n",
      "7   [1, 1, 1]             mae                 55   \n",
      "0   [1, 1, 2]             mse                 10   \n",
      "1   [1, 1, 2]             mse                 25   \n",
      "2   [1, 1, 2]             mse                 40   \n",
      "3   [1, 1, 2]             mse                 55   \n",
      "4   [1, 1, 2]             mae                 10   \n",
      "5   [1, 1, 2]             mae                 25   \n",
      "6   [1, 1, 2]             mae                 40   \n",
      "7   [1, 1, 2]             mae                 55   \n",
      "0   [1, 2, 1]             mse                 10   \n",
      "1   [1, 2, 1]             mse                 25   \n",
      "2   [1, 2, 1]             mse                 40   \n",
      "3   [1, 2, 1]             mse                 55   \n",
      "4   [1, 2, 1]             mae                 10   \n",
      "5   [1, 2, 1]             mae                 25   \n",
      "6   [1, 2, 1]             mae                 40   \n",
      "7   [1, 2, 1]             mae                 55   \n",
      "\n",
      "                                         params  rank_test_score  \\\n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "..                                          ...              ...   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                7   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                2   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                7   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                4   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                3   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                7   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                4   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.532909            0.875786           0.441208   \n",
      "1            0.539835            0.910320           0.514354   \n",
      "2            0.565894            0.912127           0.505728   \n",
      "3            0.544117            0.922500           0.478462   \n",
      "4            0.558931            0.882973           0.483207   \n",
      "5            0.564253            0.916684           0.445223   \n",
      "6            0.573519            0.910791           0.453887   \n",
      "7            0.585932            0.915393           0.504125   \n",
      "0            0.492315            0.999978           0.449155   \n",
      "1            0.542346            0.999978           0.499233   \n",
      "2            0.531688            0.999978           0.510485   \n",
      "3            0.525395            0.999978           0.500564   \n",
      "4            0.497328            0.999978           0.482597   \n",
      "5            0.553961            0.999978           0.466189   \n",
      "6            0.566515            0.999978           0.481667   \n",
      "7            0.552411            0.999978           0.512055   \n",
      "0            0.469139            0.880897           0.496814   \n",
      "1            0.502791            0.902003           0.424643   \n",
      "2            0.542659            0.903799           0.430453   \n",
      "3            0.495867            0.906287           0.422693   \n",
      "4            0.512529            0.869530           0.414054   \n",
      "5            0.493631            0.894170           0.448127   \n",
      "6            0.525079            0.904297           0.460221   \n",
      "7            0.508563            0.905416           0.466128   \n",
      "0            0.531158            0.999978           0.408375   \n",
      "1            0.503439            0.999978           0.525550   \n",
      "2            0.495257            0.999978           0.473424   \n",
      "3            0.532163            0.999978           0.492380   \n",
      "4            0.479440            0.999978           0.423900   \n",
      "5            0.514665            0.999978           0.466658   \n",
      "..                ...                 ...                ...   \n",
      "2            0.626742            0.999978           0.612241   \n",
      "3            0.643035            0.999978           0.606921   \n",
      "4            0.595589            0.999978           0.584735   \n",
      "5            0.599834            0.999978           0.619800   \n",
      "6            0.574362            0.999978           0.580725   \n",
      "7            0.610133            0.999978           0.592280   \n",
      "0            0.529877            0.913407           0.474296   \n",
      "1            0.495826            0.919807           0.436976   \n",
      "2            0.491664            0.918327           0.526921   \n",
      "3            0.521132            0.929118           0.535756   \n",
      "4            0.346534            0.896983           0.493151   \n",
      "5            0.518611            0.925493           0.514109   \n",
      "6            0.470176            0.928646           0.515855   \n",
      "7            0.435470            0.929999           0.527282   \n",
      "0            0.551075            0.999978           0.558273   \n",
      "1            0.492013            0.999978           0.553150   \n",
      "2            0.538011            0.999978           0.576530   \n",
      "3            0.525228            0.999978           0.567881   \n",
      "4            0.459749            0.999978           0.535967   \n",
      "5            0.497923            0.999978           0.539135   \n",
      "6            0.499860            0.999978           0.603550   \n",
      "7            0.470177            0.999978           0.577105   \n",
      "0            0.641078            0.922661           0.549063   \n",
      "1            0.696969            0.929801           0.558220   \n",
      "2            0.693874            0.929307           0.626593   \n",
      "3            0.715424            0.934945           0.579221   \n",
      "4            0.582810            0.903686           0.594502   \n",
      "5            0.635584            0.933998           0.660207   \n",
      "6            0.655826            0.923715           0.571048   \n",
      "7            0.662526            0.932603           0.615139   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.877617           0.445372            0.897734      0.000139   \n",
      "1             0.912061           0.423071            0.917066      0.000326   \n",
      "2             0.923810           0.433343            0.921837      0.000400   \n",
      "3             0.923717           0.464570            0.916511      0.000613   \n",
      "4             0.905834           0.413808            0.895927      0.001724   \n",
      "5             0.912121           0.441685            0.919130      0.001826   \n",
      "6             0.920353           0.445343            0.918235      0.007670   \n",
      "7             0.924390           0.407669            0.917102      0.005413   \n",
      "0             0.998030           0.424076            0.999974      0.000405   \n",
      "1             0.998030           0.406243            0.999974      0.002746   \n",
      "2             0.998030           0.397930            0.999974      0.001071   \n",
      "3             0.998030           0.420547            0.999974      0.000255   \n",
      "4             0.998030           0.345349            0.999974      0.001128   \n",
      "5             0.998030           0.405106            0.999974      0.004279   \n",
      "6             0.998030           0.407175            0.999974      0.022929   \n",
      "7             0.998030           0.376038            0.999974      0.028923   \n",
      "0             0.869641           0.348710            0.908778      0.000299   \n",
      "1             0.914159           0.325005            0.915357      0.004393   \n",
      "2             0.911402           0.384754            0.917626      0.004156   \n",
      "3             0.922294           0.386176            0.925181      0.015858   \n",
      "4             0.870999           0.346366            0.878579      0.001481   \n",
      "5             0.915648           0.401179            0.904786      0.002898   \n",
      "6             0.917081           0.407480            0.907487      0.010971   \n",
      "7             0.921047           0.356440            0.918367      0.006066   \n",
      "0             0.998030           0.347781            0.999974      0.000520   \n",
      "1             0.998030           0.401990            0.999974      0.005516   \n",
      "2             0.998030           0.373970            0.999974      0.002415   \n",
      "3             0.998030           0.371773            0.999974      0.002624   \n",
      "4             0.998030           0.349457            0.999974      0.001997   \n",
      "5             0.998030           0.383980            0.999974      0.000475   \n",
      "..                 ...                ...                 ...           ...   \n",
      "2             0.998030           0.458402            0.999974      0.012188   \n",
      "3             0.998030           0.452257            0.999974      0.008633   \n",
      "4             0.998030           0.391896            0.999974      0.005510   \n",
      "5             0.998030           0.440368            0.999974      0.008436   \n",
      "6             0.998030           0.405761            0.999974      0.004622   \n",
      "7             0.998030           0.436871            0.999974      0.008887   \n",
      "0             0.874649           0.413195            0.924545      0.000490   \n",
      "1             0.920527           0.369452            0.931648      0.002282   \n",
      "2             0.919070           0.378431            0.930952      0.002355   \n",
      "3             0.921036           0.378503            0.927776      0.007452   \n",
      "4             0.896086           0.312841            0.920732      0.000950   \n",
      "5             0.903653           0.379872            0.926045      0.013425   \n",
      "6             0.920022           0.371715            0.931401      0.034239   \n",
      "7             0.914613           0.349390            0.926017      0.011770   \n",
      "0             0.998030           0.332517            0.999974      0.001776   \n",
      "1             0.998030           0.414854            0.999974      0.003099   \n",
      "2             0.998030           0.415819            0.999974      0.000128   \n",
      "3             0.998030           0.330883            0.999974      0.002054   \n",
      "4             0.998030           0.334918            0.999974      0.003281   \n",
      "5             0.998030           0.396388            0.999974      0.009429   \n",
      "6             0.998030           0.371179            0.999974      0.015930   \n",
      "7             0.998030           0.352804            0.999974      0.025848   \n",
      "0             0.937908           0.525471            0.932116      0.001447   \n",
      "1             0.924635           0.502585            0.949243      0.003171   \n",
      "2             0.941446           0.526619            0.952537      0.006429   \n",
      "3             0.947193           0.556294            0.946716      0.006242   \n",
      "4             0.928826           0.514336            0.939085      0.005195   \n",
      "5             0.920911           0.530077            0.948331      0.012959   \n",
      "6             0.933144           0.537507            0.951558      0.012898   \n",
      "7             0.945497           0.577623            0.944681      0.019597   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000128        0.042355         0.009943  \n",
      "1         0.000056        0.050119         0.002860  \n",
      "2         0.000246        0.054229         0.005106  \n",
      "3         0.000061        0.034750         0.003149  \n",
      "4         0.000112        0.059322         0.009361  \n",
      "5         0.000085        0.057065         0.002905  \n",
      "6         0.004956        0.058616         0.004101  \n",
      "7         0.000275        0.072911         0.003901  \n",
      "0         0.000361        0.028219         0.000917  \n",
      "1         0.000495        0.056804         0.000917  \n",
      "2         0.001730        0.058674         0.000917  \n",
      "3         0.000464        0.044731         0.000917  \n",
      "4         0.000103        0.068394         0.000917  \n",
      "5         0.000121        0.061167         0.000917  \n",
      "6         0.001815        0.065161         0.000917  \n",
      "7         0.003829        0.075440         0.000917  \n",
      "0         0.000216        0.064206         0.016451  \n",
      "1         0.001236        0.072806         0.006032  \n",
      "2         0.002018        0.066442         0.005654  \n",
      "3         0.001032        0.045671         0.008310  \n",
      "4         0.000067        0.068304         0.003965  \n",
      "5         0.000056        0.037777         0.008769  \n",
      "6         0.000500        0.048145         0.005433  \n",
      "7         0.000540        0.064097         0.006825  \n",
      "0         0.000010        0.076391         0.000917  \n",
      "1         0.000275        0.053725         0.000917  \n",
      "2         0.000319        0.052769         0.000917  \n",
      "3         0.000374        0.068188         0.000917  \n",
      "4         0.000168        0.053285         0.000917  \n",
      "5         0.000100        0.053995         0.000917  \n",
      "..             ...             ...              ...  \n",
      "2         0.005118        0.076120         0.000917  \n",
      "3         0.000766        0.082721         0.000917  \n",
      "4         0.001011        0.093499         0.000917  \n",
      "5         0.000826        0.080198         0.000917  \n",
      "6         0.001109        0.080940         0.000917  \n",
      "7         0.001584        0.077765         0.000917  \n",
      "0         0.000421        0.047691         0.021385  \n",
      "1         0.001913        0.051672         0.005420  \n",
      "2         0.001147        0.063251         0.005785  \n",
      "3         0.001678        0.070853         0.003536  \n",
      "4         0.000251        0.078168         0.011413  \n",
      "5         0.000608        0.064316         0.010428  \n",
      "6         0.001851        0.060047         0.004847  \n",
      "7         0.001139        0.072507         0.006520  \n",
      "0         0.000272        0.104664         0.000917  \n",
      "1         0.000308        0.056485         0.000917  \n",
      "2         0.001063        0.068408         0.000917  \n",
      "3         0.000370        0.103009         0.000917  \n",
      "4         0.000542        0.082731         0.000917  \n",
      "5         0.001277        0.059890         0.000917  \n",
      "6         0.001539        0.094879         0.000917  \n",
      "7         0.006585        0.091440         0.000917  \n",
      "0         0.000494        0.049958         0.006284  \n",
      "1         0.000462        0.081862         0.010595  \n",
      "2         0.003365        0.068751         0.009487  \n",
      "3         0.001802        0.070357         0.005665  \n",
      "4         0.000098        0.035313         0.014871  \n",
      "5         0.000620        0.056365         0.011198  \n",
      "6         0.001610        0.049865         0.011562  \n",
      "7         0.000795        0.034777         0.005895  \n",
      "\n",
      "[88 rows x 19 columns]\n",
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.027211         0.006327         0.563069          0.999327   \n",
      "1       0.068220         0.012536         0.593994          0.999327   \n",
      "2       0.103084         0.021112         0.610592          0.999327   \n",
      "3       0.139993         0.027920         0.619020          0.999327   \n",
      "4       0.084314         0.005619         0.598731          0.999327   \n",
      "5       0.210423         0.014739         0.577511          0.999327   \n",
      "6       0.335544         0.019676         0.621732          0.999327   \n",
      "7       0.459420         0.029228         0.636866          0.999327   \n",
      "\n",
      "  method_ids param_criterion param_n_estimators  \\\n",
      "0  [1, 2, 2]             mse                 10   \n",
      "1  [1, 2, 2]             mse                 25   \n",
      "2  [1, 2, 2]             mse                 40   \n",
      "3  [1, 2, 2]             mse                 55   \n",
      "4  [1, 2, 2]             mae                 10   \n",
      "5  [1, 2, 2]             mae                 25   \n",
      "6  [1, 2, 2]             mae                 40   \n",
      "7  [1, 2, 2]             mae                 55   \n",
      "\n",
      "                                        params  rank_test_score  \\\n",
      "0  {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1  {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2  {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3  {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4  {u'n_estimators': 10, u'criterion': u'mae'}                5   \n",
      "5  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6  {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7  {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.629988            0.999978           0.576435   \n",
      "1           0.674517            0.999978           0.600672   \n",
      "2           0.675135            0.999978           0.610547   \n",
      "3           0.668569            0.999978           0.638537   \n",
      "4           0.639206            0.999978           0.601776   \n",
      "5           0.671600            0.999978           0.525742   \n",
      "6           0.667524            0.999978           0.648800   \n",
      "7           0.677133            0.999978           0.666931   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.99803           0.482063            0.999974      0.001330   \n",
      "1             0.99803           0.505927            0.999974      0.001923   \n",
      "2             0.99803           0.545401            0.999974      0.003110   \n",
      "3             0.99803           0.549420            0.999974      0.004264   \n",
      "4             0.99803           0.554777            0.999974      0.003891   \n",
      "5             0.99803           0.534180            0.999974      0.006413   \n",
      "6             0.99803           0.548378            0.999974      0.010716   \n",
      "7             0.99803           0.566100            0.999974      0.016674   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.001287        0.061174         0.000917  \n",
      "1        0.000309        0.069048         0.000917  \n",
      "2        0.000726        0.053010         0.000917  \n",
      "3        0.001138        0.050593         0.000917  \n",
      "4        0.000318        0.034565         0.000917  \n",
      "5        0.000752        0.066976         0.000917  \n",
      "6        0.000828        0.052292         0.000917  \n",
      "7        0.000592        0.050079         0.000917  \n",
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.024136         0.005008         0.473376          0.883712   \n",
      "1        0.060178         0.011970         0.492589          0.913149   \n",
      "2        0.095356         0.018556         0.501884          0.919258   \n",
      "3        0.131009         0.025559         0.495889          0.920909   \n",
      "4        0.050747         0.005121         0.485578          0.894911   \n",
      "5        0.135085         0.011601         0.484008          0.915978   \n",
      "6        0.215881         0.022047         0.491211          0.916460   \n",
      "7        0.287532         0.025424         0.499552          0.918961   \n",
      "0        0.021495         0.004955         0.455315          0.999327   \n",
      "1        0.055847         0.012153         0.482821          0.999327   \n",
      "2        0.085707         0.020287         0.480219          0.999327   \n",
      "3        0.116703         0.025506         0.482323          0.999327   \n",
      "4        0.051623         0.004975         0.441957          0.999327   \n",
      "5        0.130315         0.011985         0.475367          0.999327   \n",
      "6        0.228170         0.020735         0.485410          0.999327   \n",
      "7        0.326909         0.028547         0.480426          0.999327   \n",
      "0        0.024429         0.005034         0.438331          0.886438   \n",
      "1        0.068368         0.014011         0.417784          0.910506   \n",
      "2        0.120861         0.026287         0.452943          0.910942   \n",
      "3        0.146770         0.026211         0.435130          0.917921   \n",
      "4        0.053327         0.005148         0.424631          0.873036   \n",
      "5        0.132050         0.012251         0.447810          0.904868   \n",
      "6        0.217647         0.023733         0.464478          0.909622   \n",
      "7        0.292883         0.026061         0.443942          0.914943   \n",
      "0        0.022064         0.005022         0.429469          0.999327   \n",
      "1        0.057824         0.011764         0.477087          0.999327   \n",
      "2        0.089325         0.019156         0.447721          0.999327   \n",
      "3        0.121582         0.025687         0.465677          0.999327   \n",
      "4        0.050461         0.005172         0.417820          0.999327   \n",
      "5        0.129415         0.011766         0.455314          0.999327   \n",
      "..            ...              ...              ...               ...   \n",
      "2        0.119693         0.022323         0.465765          0.922783   \n",
      "3        0.159249         0.027426         0.478616          0.925977   \n",
      "4        0.091102         0.005276         0.384041          0.904600   \n",
      "5        0.237513         0.013088         0.471034          0.918397   \n",
      "6        0.383138         0.022711         0.452645          0.926690   \n",
      "7        0.513650         0.028162         0.437374          0.923543   \n",
      "0        0.027020         0.005336         0.480873          0.999327   \n",
      "1        0.068788         0.012659         0.486692          0.999327   \n",
      "2        0.107790         0.023480         0.510219          0.999327   \n",
      "3        0.145789         0.027460         0.474844          0.999327   \n",
      "4        0.093866         0.006053         0.443603          0.999327   \n",
      "5        0.241093         0.014588         0.477887          0.999327   \n",
      "6        0.384652         0.022765         0.491559          0.999327   \n",
      "7        0.524458         0.037809         0.466708          0.999327   \n",
      "0        0.027670         0.005471         0.572118          0.930895   \n",
      "1        0.087699         0.014203         0.586321          0.934560   \n",
      "2        0.123745         0.021479         0.615974          0.941097   \n",
      "3        0.156221         0.028420         0.617331          0.942951   \n",
      "4        0.076248         0.005222         0.563950          0.923866   \n",
      "5        0.199907         0.014017         0.608719          0.934413   \n",
      "6        0.300280         0.020285         0.588369          0.936139   \n",
      "7        0.439856         0.027308         0.618587          0.940927   \n",
      "0        0.027211         0.006327         0.563069          0.999327   \n",
      "1        0.068220         0.012536         0.593994          0.999327   \n",
      "2        0.103084         0.021112         0.610592          0.999327   \n",
      "3        0.139993         0.027920         0.619020          0.999327   \n",
      "4        0.084314         0.005619         0.598731          0.999327   \n",
      "5        0.210423         0.014739         0.577511          0.999327   \n",
      "6        0.335544         0.019676         0.621732          0.999327   \n",
      "7        0.459420         0.029228         0.636866          0.999327   \n",
      "\n",
      "   method_ids param_criterion param_n_estimators  \\\n",
      "0   [0, 0, 1]             mse                 10   \n",
      "1   [0, 0, 1]             mse                 25   \n",
      "2   [0, 0, 1]             mse                 40   \n",
      "3   [0, 0, 1]             mse                 55   \n",
      "4   [0, 0, 1]             mae                 10   \n",
      "5   [0, 0, 1]             mae                 25   \n",
      "6   [0, 0, 1]             mae                 40   \n",
      "7   [0, 0, 1]             mae                 55   \n",
      "0   [0, 0, 2]             mse                 10   \n",
      "1   [0, 0, 2]             mse                 25   \n",
      "2   [0, 0, 2]             mse                 40   \n",
      "3   [0, 0, 2]             mse                 55   \n",
      "4   [0, 0, 2]             mae                 10   \n",
      "5   [0, 0, 2]             mae                 25   \n",
      "6   [0, 0, 2]             mae                 40   \n",
      "7   [0, 0, 2]             mae                 55   \n",
      "0   [0, 1, 1]             mse                 10   \n",
      "1   [0, 1, 1]             mse                 25   \n",
      "2   [0, 1, 1]             mse                 40   \n",
      "3   [0, 1, 1]             mse                 55   \n",
      "4   [0, 1, 1]             mae                 10   \n",
      "5   [0, 1, 1]             mae                 25   \n",
      "6   [0, 1, 1]             mae                 40   \n",
      "7   [0, 1, 1]             mae                 55   \n",
      "0   [0, 1, 2]             mse                 10   \n",
      "1   [0, 1, 2]             mse                 25   \n",
      "2   [0, 1, 2]             mse                 40   \n",
      "3   [0, 1, 2]             mse                 55   \n",
      "4   [0, 1, 2]             mae                 10   \n",
      "5   [0, 1, 2]             mae                 25   \n",
      "..        ...             ...                ...   \n",
      "2   [1, 1, 1]             mse                 40   \n",
      "3   [1, 1, 1]             mse                 55   \n",
      "4   [1, 1, 1]             mae                 10   \n",
      "5   [1, 1, 1]             mae                 25   \n",
      "6   [1, 1, 1]             mae                 40   \n",
      "7   [1, 1, 1]             mae                 55   \n",
      "0   [1, 1, 2]             mse                 10   \n",
      "1   [1, 1, 2]             mse                 25   \n",
      "2   [1, 1, 2]             mse                 40   \n",
      "3   [1, 1, 2]             mse                 55   \n",
      "4   [1, 1, 2]             mae                 10   \n",
      "5   [1, 1, 2]             mae                 25   \n",
      "6   [1, 1, 2]             mae                 40   \n",
      "7   [1, 1, 2]             mae                 55   \n",
      "0   [1, 2, 1]             mse                 10   \n",
      "1   [1, 2, 1]             mse                 25   \n",
      "2   [1, 2, 1]             mse                 40   \n",
      "3   [1, 2, 1]             mse                 55   \n",
      "4   [1, 2, 1]             mae                 10   \n",
      "5   [1, 2, 1]             mae                 25   \n",
      "6   [1, 2, 1]             mae                 40   \n",
      "7   [1, 2, 1]             mae                 55   \n",
      "0   [1, 2, 2]             mse                 10   \n",
      "1   [1, 2, 2]             mse                 25   \n",
      "2   [1, 2, 2]             mse                 40   \n",
      "3   [1, 2, 2]             mse                 55   \n",
      "4   [1, 2, 2]             mae                 10   \n",
      "5   [1, 2, 2]             mae                 25   \n",
      "6   [1, 2, 2]             mae                 40   \n",
      "7   [1, 2, 2]             mae                 55   \n",
      "\n",
      "                                         params  rank_test_score  \\\n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                4   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                6   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                2   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                2   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                6   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                5   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                8   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                2   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                7   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                4   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                1   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "..                                          ...              ...   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                1   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                3   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                6   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                4   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                3   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                1   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                6   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                5   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                7   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                7   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                3   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                4   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                5   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "0   {u'n_estimators': 10, u'criterion': u'mse'}                8   \n",
      "1   {u'n_estimators': 25, u'criterion': u'mse'}                6   \n",
      "2   {u'n_estimators': 40, u'criterion': u'mse'}                4   \n",
      "3   {u'n_estimators': 55, u'criterion': u'mse'}                3   \n",
      "4   {u'n_estimators': 10, u'criterion': u'mae'}                5   \n",
      "5   {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
      "6   {u'n_estimators': 40, u'criterion': u'mae'}                2   \n",
      "7   {u'n_estimators': 55, u'criterion': u'mae'}                1   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.532909            0.875786           0.441208   \n",
      "1            0.539835            0.910320           0.514354   \n",
      "2            0.565894            0.912127           0.505728   \n",
      "3            0.544117            0.922500           0.478462   \n",
      "4            0.558931            0.882973           0.483207   \n",
      "5            0.564253            0.916684           0.445223   \n",
      "6            0.573519            0.910791           0.453887   \n",
      "7            0.585932            0.915393           0.504125   \n",
      "0            0.492315            0.999978           0.449155   \n",
      "1            0.542346            0.999978           0.499233   \n",
      "2            0.531688            0.999978           0.510485   \n",
      "3            0.525395            0.999978           0.500564   \n",
      "4            0.497328            0.999978           0.482597   \n",
      "5            0.553961            0.999978           0.466189   \n",
      "6            0.566515            0.999978           0.481667   \n",
      "7            0.552411            0.999978           0.512055   \n",
      "0            0.469139            0.880897           0.496814   \n",
      "1            0.502791            0.902003           0.424643   \n",
      "2            0.542659            0.903799           0.430453   \n",
      "3            0.495867            0.906287           0.422693   \n",
      "4            0.512529            0.869530           0.414054   \n",
      "5            0.493631            0.894170           0.448127   \n",
      "6            0.525079            0.904297           0.460221   \n",
      "7            0.508563            0.905416           0.466128   \n",
      "0            0.531158            0.999978           0.408375   \n",
      "1            0.503439            0.999978           0.525550   \n",
      "2            0.495257            0.999978           0.473424   \n",
      "3            0.532163            0.999978           0.492380   \n",
      "4            0.479440            0.999978           0.423900   \n",
      "5            0.514665            0.999978           0.466658   \n",
      "..                ...                 ...                ...   \n",
      "2            0.491664            0.918327           0.526921   \n",
      "3            0.521132            0.929118           0.535756   \n",
      "4            0.346534            0.896983           0.493151   \n",
      "5            0.518611            0.925493           0.514109   \n",
      "6            0.470176            0.928646           0.515855   \n",
      "7            0.435470            0.929999           0.527282   \n",
      "0            0.551075            0.999978           0.558273   \n",
      "1            0.492013            0.999978           0.553150   \n",
      "2            0.538011            0.999978           0.576530   \n",
      "3            0.525228            0.999978           0.567881   \n",
      "4            0.459749            0.999978           0.535967   \n",
      "5            0.497923            0.999978           0.539135   \n",
      "6            0.499860            0.999978           0.603550   \n",
      "7            0.470177            0.999978           0.577105   \n",
      "0            0.641078            0.922661           0.549063   \n",
      "1            0.696969            0.929801           0.558220   \n",
      "2            0.693874            0.929307           0.626593   \n",
      "3            0.715424            0.934945           0.579221   \n",
      "4            0.582810            0.903686           0.594502   \n",
      "5            0.635584            0.933998           0.660207   \n",
      "6            0.655826            0.923715           0.571048   \n",
      "7            0.662526            0.932603           0.615139   \n",
      "0            0.629988            0.999978           0.576435   \n",
      "1            0.674517            0.999978           0.600672   \n",
      "2            0.675135            0.999978           0.610547   \n",
      "3            0.668569            0.999978           0.638537   \n",
      "4            0.639206            0.999978           0.601776   \n",
      "5            0.671600            0.999978           0.525742   \n",
      "6            0.667524            0.999978           0.648800   \n",
      "7            0.677133            0.999978           0.666931   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.877617           0.445372            0.897734      0.000139   \n",
      "1             0.912061           0.423071            0.917066      0.000326   \n",
      "2             0.923810           0.433343            0.921837      0.000400   \n",
      "3             0.923717           0.464570            0.916511      0.000613   \n",
      "4             0.905834           0.413808            0.895927      0.001724   \n",
      "5             0.912121           0.441685            0.919130      0.001826   \n",
      "6             0.920353           0.445343            0.918235      0.007670   \n",
      "7             0.924390           0.407669            0.917102      0.005413   \n",
      "0             0.998030           0.424076            0.999974      0.000405   \n",
      "1             0.998030           0.406243            0.999974      0.002746   \n",
      "2             0.998030           0.397930            0.999974      0.001071   \n",
      "3             0.998030           0.420547            0.999974      0.000255   \n",
      "4             0.998030           0.345349            0.999974      0.001128   \n",
      "5             0.998030           0.405106            0.999974      0.004279   \n",
      "6             0.998030           0.407175            0.999974      0.022929   \n",
      "7             0.998030           0.376038            0.999974      0.028923   \n",
      "0             0.869641           0.348710            0.908778      0.000299   \n",
      "1             0.914159           0.325005            0.915357      0.004393   \n",
      "2             0.911402           0.384754            0.917626      0.004156   \n",
      "3             0.922294           0.386176            0.925181      0.015858   \n",
      "4             0.870999           0.346366            0.878579      0.001481   \n",
      "5             0.915648           0.401179            0.904786      0.002898   \n",
      "6             0.917081           0.407480            0.907487      0.010971   \n",
      "7             0.921047           0.356440            0.918367      0.006066   \n",
      "0             0.998030           0.347781            0.999974      0.000520   \n",
      "1             0.998030           0.401990            0.999974      0.005516   \n",
      "2             0.998030           0.373970            0.999974      0.002415   \n",
      "3             0.998030           0.371773            0.999974      0.002624   \n",
      "4             0.998030           0.349457            0.999974      0.001997   \n",
      "5             0.998030           0.383980            0.999974      0.000475   \n",
      "..                 ...                ...                 ...           ...   \n",
      "2             0.919070           0.378431            0.930952      0.002355   \n",
      "3             0.921036           0.378503            0.927776      0.007452   \n",
      "4             0.896086           0.312841            0.920732      0.000950   \n",
      "5             0.903653           0.379872            0.926045      0.013425   \n",
      "6             0.920022           0.371715            0.931401      0.034239   \n",
      "7             0.914613           0.349390            0.926017      0.011770   \n",
      "0             0.998030           0.332517            0.999974      0.001776   \n",
      "1             0.998030           0.414854            0.999974      0.003099   \n",
      "2             0.998030           0.415819            0.999974      0.000128   \n",
      "3             0.998030           0.330883            0.999974      0.002054   \n",
      "4             0.998030           0.334918            0.999974      0.003281   \n",
      "5             0.998030           0.396388            0.999974      0.009429   \n",
      "6             0.998030           0.371179            0.999974      0.015930   \n",
      "7             0.998030           0.352804            0.999974      0.025848   \n",
      "0             0.937908           0.525471            0.932116      0.001447   \n",
      "1             0.924635           0.502585            0.949243      0.003171   \n",
      "2             0.941446           0.526619            0.952537      0.006429   \n",
      "3             0.947193           0.556294            0.946716      0.006242   \n",
      "4             0.928826           0.514336            0.939085      0.005195   \n",
      "5             0.920911           0.530077            0.948331      0.012959   \n",
      "6             0.933144           0.537507            0.951558      0.012898   \n",
      "7             0.945497           0.577623            0.944681      0.019597   \n",
      "0             0.998030           0.482063            0.999974      0.001330   \n",
      "1             0.998030           0.505927            0.999974      0.001923   \n",
      "2             0.998030           0.545401            0.999974      0.003110   \n",
      "3             0.998030           0.549420            0.999974      0.004264   \n",
      "4             0.998030           0.554777            0.999974      0.003891   \n",
      "5             0.998030           0.534180            0.999974      0.006413   \n",
      "6             0.998030           0.548378            0.999974      0.010716   \n",
      "7             0.998030           0.566100            0.999974      0.016674   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000128        0.042355         0.009943  \n",
      "1         0.000056        0.050119         0.002860  \n",
      "2         0.000246        0.054229         0.005106  \n",
      "3         0.000061        0.034750         0.003149  \n",
      "4         0.000112        0.059322         0.009361  \n",
      "5         0.000085        0.057065         0.002905  \n",
      "6         0.004956        0.058616         0.004101  \n",
      "7         0.000275        0.072911         0.003901  \n",
      "0         0.000361        0.028219         0.000917  \n",
      "1         0.000495        0.056804         0.000917  \n",
      "2         0.001730        0.058674         0.000917  \n",
      "3         0.000464        0.044731         0.000917  \n",
      "4         0.000103        0.068394         0.000917  \n",
      "5         0.000121        0.061167         0.000917  \n",
      "6         0.001815        0.065161         0.000917  \n",
      "7         0.003829        0.075440         0.000917  \n",
      "0         0.000216        0.064206         0.016451  \n",
      "1         0.001236        0.072806         0.006032  \n",
      "2         0.002018        0.066442         0.005654  \n",
      "3         0.001032        0.045671         0.008310  \n",
      "4         0.000067        0.068304         0.003965  \n",
      "5         0.000056        0.037777         0.008769  \n",
      "6         0.000500        0.048145         0.005433  \n",
      "7         0.000540        0.064097         0.006825  \n",
      "0         0.000010        0.076391         0.000917  \n",
      "1         0.000275        0.053725         0.000917  \n",
      "2         0.000319        0.052769         0.000917  \n",
      "3         0.000374        0.068188         0.000917  \n",
      "4         0.000168        0.053285         0.000917  \n",
      "5         0.000100        0.053995         0.000917  \n",
      "..             ...             ...              ...  \n",
      "2         0.001147        0.063251         0.005785  \n",
      "3         0.001678        0.070853         0.003536  \n",
      "4         0.000251        0.078168         0.011413  \n",
      "5         0.000608        0.064316         0.010428  \n",
      "6         0.001851        0.060047         0.004847  \n",
      "7         0.001139        0.072507         0.006520  \n",
      "0         0.000272        0.104664         0.000917  \n",
      "1         0.000308        0.056485         0.000917  \n",
      "2         0.001063        0.068408         0.000917  \n",
      "3         0.000370        0.103009         0.000917  \n",
      "4         0.000542        0.082731         0.000917  \n",
      "5         0.001277        0.059890         0.000917  \n",
      "6         0.001539        0.094879         0.000917  \n",
      "7         0.006585        0.091440         0.000917  \n",
      "0         0.000494        0.049958         0.006284  \n",
      "1         0.000462        0.081862         0.010595  \n",
      "2         0.003365        0.068751         0.009487  \n",
      "3         0.001802        0.070357         0.005665  \n",
      "4         0.000098        0.035313         0.014871  \n",
      "5         0.000620        0.056365         0.011198  \n",
      "6         0.001610        0.049865         0.011562  \n",
      "7         0.000795        0.034777         0.005895  \n",
      "0         0.001287        0.061174         0.000917  \n",
      "1         0.000309        0.069048         0.000917  \n",
      "2         0.000726        0.053010         0.000917  \n",
      "3         0.001138        0.050593         0.000917  \n",
      "4         0.000318        0.034565         0.000917  \n",
      "5         0.000752        0.066976         0.000917  \n",
      "6         0.000828        0.052292         0.000917  \n",
      "7         0.000592        0.050079         0.000917  \n",
      "\n",
      "[96 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "eval_set = rg.auto_grid(X,y,labels, ks=[10,20], opts=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "currind = 0\n",
    "to_drop = []\n",
    "for i in range(0, len(evaluation_results)-1):\n",
    "    if abs(evaluation_results.eval_set_score[currind] - evaluation_results.eval_set_score[i+1]) < 0.01 \\\n",
    "        and abs(evaluation_results.dev_set_score[i] - evaluation_results.dev_set_score[i+1]) < 0.01:\n",
    "        to_drop.append(i+1)\n",
    "    else:\n",
    "        currind = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in to_drop:\n",
    "    evaluation_results.drop(i, inplace=True)\n",
    "    \n",
    "evaluation_results.sort_values(by='rank_test_score', inplace=True)\n",
    "evaluation_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i in range(0, len(evaluation_results)-1):\n",
    "    if str(evaluation_results.method_ids[i])==str(evaluation_results.method_ids[i+1]):\n",
    "        to_drop.append(i+1)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for i in to_drop:\n",
    "    evaluation_results.drop(i, inplace=True)\n",
    "\n",
    "evaluation_results.sort_values(by='rank_test_score', inplace=True)\n",
    "evaluation_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#array = np.array(evaluation_results['eval_set_score'])\n",
    "#temp = array.argsort()[::-1]\n",
    "#ranks = np.empty(len(array), int)\n",
    "#ranks[temp] = np.arange(len(array))\n",
    "#evaluation_results['rank_test_score'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains an evaluation and analysis set\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Trying to write to wrong type of file, or analysis set already saved! Check the file...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-4f22333fe248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./results.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-23a30a858144>\u001b[0m in \u001b[0;36msave_analysis\u001b[0;34m(analysis_results, filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying to write to wrong type of file, or analysis set already saved! Check the file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mfile_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Trying to write to wrong type of file, or analysis set already saved! Check the file..."
     ]
    }
   ],
   "source": [
    "save_analysis(evaluation_results, './results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>method_ids</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.459420</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.636866</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677133</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.666931</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.335544</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.621732</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.548378</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139993</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.619020</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.668569</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.638537</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.549420</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.050593</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.439856</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.618587</td>\n",
       "      <td>0.940927</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.662526</td>\n",
       "      <td>0.932603</td>\n",
       "      <td>0.615139</td>\n",
       "      <td>0.945497</td>\n",
       "      <td>0.577623</td>\n",
       "      <td>0.944681</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>0.005895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156221</td>\n",
       "      <td>0.028420</td>\n",
       "      <td>0.617331</td>\n",
       "      <td>0.942951</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.715424</td>\n",
       "      <td>0.934945</td>\n",
       "      <td>0.579221</td>\n",
       "      <td>0.947193</td>\n",
       "      <td>0.556294</td>\n",
       "      <td>0.946716</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>0.005665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.123745</td>\n",
       "      <td>0.021479</td>\n",
       "      <td>0.615974</td>\n",
       "      <td>0.941097</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.929307</td>\n",
       "      <td>0.626593</td>\n",
       "      <td>0.941446</td>\n",
       "      <td>0.526619</td>\n",
       "      <td>0.952537</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.068751</td>\n",
       "      <td>0.009487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.103084</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.610592</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.675135</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.610547</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.545401</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.053010</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.199907</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.608719</td>\n",
       "      <td>0.934413</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.635584</td>\n",
       "      <td>0.933998</td>\n",
       "      <td>0.660207</td>\n",
       "      <td>0.920911</td>\n",
       "      <td>0.530077</td>\n",
       "      <td>0.948331</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.011198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.084314</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.598731</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.639206</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.601776</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.034565</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.068220</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.593994</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.674517</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.600672</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.505927</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.069048</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.300280</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.588369</td>\n",
       "      <td>0.936139</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.655826</td>\n",
       "      <td>0.923715</td>\n",
       "      <td>0.571048</td>\n",
       "      <td>0.933144</td>\n",
       "      <td>0.537507</td>\n",
       "      <td>0.951558</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.049865</td>\n",
       "      <td>0.011562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.087699</td>\n",
       "      <td>0.014203</td>\n",
       "      <td>0.586321</td>\n",
       "      <td>0.934560</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.696969</td>\n",
       "      <td>0.929801</td>\n",
       "      <td>0.558220</td>\n",
       "      <td>0.924635</td>\n",
       "      <td>0.502585</td>\n",
       "      <td>0.949243</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.081862</td>\n",
       "      <td>0.010595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.210423</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.577511</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.525742</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.066976</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.572118</td>\n",
       "      <td>0.930895</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.641078</td>\n",
       "      <td>0.922661</td>\n",
       "      <td>0.549063</td>\n",
       "      <td>0.937908</td>\n",
       "      <td>0.525471</td>\n",
       "      <td>0.932116</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.152059</td>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.567674</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>14</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.606921</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.452257</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.082721</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.108297</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.566013</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.626742</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.612241</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.458402</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.076120</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.076248</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.923866</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.582810</td>\n",
       "      <td>0.903686</td>\n",
       "      <td>0.594502</td>\n",
       "      <td>0.928826</td>\n",
       "      <td>0.514336</td>\n",
       "      <td>0.939085</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.035313</td>\n",
       "      <td>0.014871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.563069</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.629988</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.576435</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.482063</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.234337</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>18</td>\n",
       "      <td>0.599834</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.619800</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.440368</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.080198</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.492291</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.546656</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>19</td>\n",
       "      <td>0.610133</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.592280</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.436871</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.077765</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.507108</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>0.535624</td>\n",
       "      <td>0.929226</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>20</td>\n",
       "      <td>0.562966</td>\n",
       "      <td>0.918211</td>\n",
       "      <td>0.582872</td>\n",
       "      <td>0.933235</td>\n",
       "      <td>0.460740</td>\n",
       "      <td>0.936233</td>\n",
       "      <td>0.016345</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.053432</td>\n",
       "      <td>0.007885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.074109</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.532244</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>21</td>\n",
       "      <td>0.613994</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.606001</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.375858</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.110334</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.529766</td>\n",
       "      <td>0.914276</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>22</td>\n",
       "      <td>0.593655</td>\n",
       "      <td>0.899050</td>\n",
       "      <td>0.564145</td>\n",
       "      <td>0.916170</td>\n",
       "      <td>0.430812</td>\n",
       "      <td>0.927607</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.070818</td>\n",
       "      <td>0.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.529725</td>\n",
       "      <td>0.928579</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>23</td>\n",
       "      <td>0.585921</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.571995</td>\n",
       "      <td>0.917596</td>\n",
       "      <td>0.430655</td>\n",
       "      <td>0.935709</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.070097</td>\n",
       "      <td>0.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.150285</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.529085</td>\n",
       "      <td>0.929993</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>24</td>\n",
       "      <td>0.569633</td>\n",
       "      <td>0.923452</td>\n",
       "      <td>0.572766</td>\n",
       "      <td>0.928583</td>\n",
       "      <td>0.444420</td>\n",
       "      <td>0.937943</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.059721</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.087587</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.524329</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>25</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.584735</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.391896</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.093499</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.203138</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.522322</td>\n",
       "      <td>0.924236</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>26</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.929253</td>\n",
       "      <td>0.575438</td>\n",
       "      <td>0.918809</td>\n",
       "      <td>0.468585</td>\n",
       "      <td>0.924647</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.004273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.364388</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>27</td>\n",
       "      <td>0.574362</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.580725</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.405761</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.067621</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.517010</td>\n",
       "      <td>0.919884</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>28</td>\n",
       "      <td>0.576332</td>\n",
       "      <td>0.914199</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>0.916065</td>\n",
       "      <td>0.399362</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.082970</td>\n",
       "      <td>0.006763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.340299</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.514097</td>\n",
       "      <td>0.925083</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>29</td>\n",
       "      <td>0.567707</td>\n",
       "      <td>0.919558</td>\n",
       "      <td>0.544228</td>\n",
       "      <td>0.925269</td>\n",
       "      <td>0.429778</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.034664</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.060231</td>\n",
       "      <td>0.004437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.129415</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>66</td>\n",
       "      <td>0.514665</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.466658</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.383980</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.053995</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.135677</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.453036</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>67</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.382795</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.051656</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.120861</td>\n",
       "      <td>0.026287</td>\n",
       "      <td>0.452943</td>\n",
       "      <td>0.910942</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>68</td>\n",
       "      <td>0.542659</td>\n",
       "      <td>0.903799</td>\n",
       "      <td>0.430453</td>\n",
       "      <td>0.911402</td>\n",
       "      <td>0.384754</td>\n",
       "      <td>0.917626</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.066442</td>\n",
       "      <td>0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.057207</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.452940</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>69</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.463751</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.382624</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.053334</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.383138</td>\n",
       "      <td>0.022711</td>\n",
       "      <td>0.452645</td>\n",
       "      <td>0.926690</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>70</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.928646</td>\n",
       "      <td>0.515855</td>\n",
       "      <td>0.920022</td>\n",
       "      <td>0.371715</td>\n",
       "      <td>0.931401</td>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.060047</td>\n",
       "      <td>0.004847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.061383</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.447905</td>\n",
       "      <td>0.912889</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>71</td>\n",
       "      <td>0.506235</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.419286</td>\n",
       "      <td>0.912013</td>\n",
       "      <td>0.417566</td>\n",
       "      <td>0.915883</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.132050</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.447810</td>\n",
       "      <td>0.904868</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>72</td>\n",
       "      <td>0.493631</td>\n",
       "      <td>0.894170</td>\n",
       "      <td>0.448127</td>\n",
       "      <td>0.915648</td>\n",
       "      <td>0.401179</td>\n",
       "      <td>0.904786</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.037777</td>\n",
       "      <td>0.008769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.019156</td>\n",
       "      <td>0.447721</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>73</td>\n",
       "      <td>0.495257</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.473424</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.373970</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.052769</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.447631</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>74</td>\n",
       "      <td>0.499696</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.443762</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.398875</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.041286</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.204490</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.445757</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>75</td>\n",
       "      <td>0.511391</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.470341</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.354833</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.066278</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.292883</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.443942</td>\n",
       "      <td>0.914943</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>76</td>\n",
       "      <td>0.508563</td>\n",
       "      <td>0.905416</td>\n",
       "      <td>0.466128</td>\n",
       "      <td>0.921047</td>\n",
       "      <td>0.356440</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.064097</td>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.093866</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.443603</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[1, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>77</td>\n",
       "      <td>0.459749</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.535967</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.334918</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.082731</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.051623</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.441957</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 0, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>78</td>\n",
       "      <td>0.497328</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.482597</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.345349</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.280706</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>0.440078</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>79</td>\n",
       "      <td>0.503981</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.439359</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.376207</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.052212</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.024429</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.438331</td>\n",
       "      <td>0.886438</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>80</td>\n",
       "      <td>0.469139</td>\n",
       "      <td>0.880897</td>\n",
       "      <td>0.496814</td>\n",
       "      <td>0.869641</td>\n",
       "      <td>0.348710</td>\n",
       "      <td>0.908778</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.064206</td>\n",
       "      <td>0.016451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.513650</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>0.437374</td>\n",
       "      <td>0.923543</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mae'}</td>\n",
       "      <td>81</td>\n",
       "      <td>0.435470</td>\n",
       "      <td>0.929999</td>\n",
       "      <td>0.527282</td>\n",
       "      <td>0.914613</td>\n",
       "      <td>0.349390</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.006520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.146770</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.435130</td>\n",
       "      <td>0.917921</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>82</td>\n",
       "      <td>0.495867</td>\n",
       "      <td>0.906287</td>\n",
       "      <td>0.422693</td>\n",
       "      <td>0.922294</td>\n",
       "      <td>0.386176</td>\n",
       "      <td>0.925181</td>\n",
       "      <td>0.015858</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.226937</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.434604</td>\n",
       "      <td>0.919032</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mae'}</td>\n",
       "      <td>83</td>\n",
       "      <td>0.533535</td>\n",
       "      <td>0.910753</td>\n",
       "      <td>0.432182</td>\n",
       "      <td>0.924144</td>\n",
       "      <td>0.337031</td>\n",
       "      <td>0.922201</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.080311</td>\n",
       "      <td>0.005908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.434305</td>\n",
       "      <td>0.923994</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>84</td>\n",
       "      <td>0.495826</td>\n",
       "      <td>0.919807</td>\n",
       "      <td>0.436976</td>\n",
       "      <td>0.920527</td>\n",
       "      <td>0.369452</td>\n",
       "      <td>0.931648</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.051672</td>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.429469</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>85</td>\n",
       "      <td>0.531158</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.408375</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.347781</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.076391</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.053327</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.424631</td>\n",
       "      <td>0.873036</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>86</td>\n",
       "      <td>0.512529</td>\n",
       "      <td>0.869530</td>\n",
       "      <td>0.414054</td>\n",
       "      <td>0.870999</td>\n",
       "      <td>0.346366</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.068304</td>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.128777</td>\n",
       "      <td>0.026892</td>\n",
       "      <td>0.423102</td>\n",
       "      <td>0.918386</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 55, u'criterion': u'mse'}</td>\n",
       "      <td>87</td>\n",
       "      <td>0.499550</td>\n",
       "      <td>0.915338</td>\n",
       "      <td>0.405926</td>\n",
       "      <td>0.923868</td>\n",
       "      <td>0.363007</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.057092</td>\n",
       "      <td>0.003885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.121377</td>\n",
       "      <td>0.012151</td>\n",
       "      <td>0.422526</td>\n",
       "      <td>0.904570</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mae'}</td>\n",
       "      <td>88</td>\n",
       "      <td>0.493540</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.427600</td>\n",
       "      <td>0.916280</td>\n",
       "      <td>0.345674</td>\n",
       "      <td>0.904813</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.060525</td>\n",
       "      <td>0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.049568</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.421511</td>\n",
       "      <td>0.883591</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>89</td>\n",
       "      <td>0.530776</td>\n",
       "      <td>0.859296</td>\n",
       "      <td>0.420564</td>\n",
       "      <td>0.893825</td>\n",
       "      <td>0.312019</td>\n",
       "      <td>0.897651</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.089388</td>\n",
       "      <td>0.017250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.050461</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.417820</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>90</td>\n",
       "      <td>0.479440</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.349457</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.014011</td>\n",
       "      <td>0.417784</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 25, u'criterion': u'mse'}</td>\n",
       "      <td>91</td>\n",
       "      <td>0.502791</td>\n",
       "      <td>0.902003</td>\n",
       "      <td>0.424643</td>\n",
       "      <td>0.914159</td>\n",
       "      <td>0.325005</td>\n",
       "      <td>0.915357</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.072806</td>\n",
       "      <td>0.006032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.093766</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.414147</td>\n",
       "      <td>0.920426</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 40, u'criterion': u'mse'}</td>\n",
       "      <td>92</td>\n",
       "      <td>0.490336</td>\n",
       "      <td>0.915519</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.926442</td>\n",
       "      <td>0.394687</td>\n",
       "      <td>0.919317</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.056342</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.397968</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>93</td>\n",
       "      <td>0.448027</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.405060</td>\n",
       "      <td>0.998030</td>\n",
       "      <td>0.340278</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.044310</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.384041</td>\n",
       "      <td>0.904600</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mae'}</td>\n",
       "      <td>94</td>\n",
       "      <td>0.346534</td>\n",
       "      <td>0.896983</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.896086</td>\n",
       "      <td>0.312841</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.078168</td>\n",
       "      <td>0.011413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.377227</td>\n",
       "      <td>0.894722</td>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>{u'n_estimators': 10, u'criterion': u'mse'}</td>\n",
       "      <td>95</td>\n",
       "      <td>0.394553</td>\n",
       "      <td>0.908679</td>\n",
       "      <td>0.427265</td>\n",
       "      <td>0.880529</td>\n",
       "      <td>0.309677</td>\n",
       "      <td>0.894957</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.049477</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.459420         0.029228         0.636866          0.999327   \n",
       "1        0.335544         0.019676         0.621732          0.999327   \n",
       "2        0.139993         0.027920         0.619020          0.999327   \n",
       "3        0.439856         0.027308         0.618587          0.940927   \n",
       "4        0.156221         0.028420         0.617331          0.942951   \n",
       "5        0.123745         0.021479         0.615974          0.941097   \n",
       "6        0.103084         0.021112         0.610592          0.999327   \n",
       "7        0.199907         0.014017         0.608719          0.934413   \n",
       "8        0.084314         0.005619         0.598731          0.999327   \n",
       "9        0.068220         0.012536         0.593994          0.999327   \n",
       "10       0.300280         0.020285         0.588369          0.936139   \n",
       "11       0.087699         0.014203         0.586321          0.934560   \n",
       "12       0.210423         0.014739         0.577511          0.999327   \n",
       "13       0.027670         0.005471         0.572118          0.930895   \n",
       "14       0.152059         0.029719         0.567674          0.999327   \n",
       "15       0.108297         0.023410         0.566013          0.999327   \n",
       "16       0.076248         0.005222         0.563950          0.923866   \n",
       "17       0.027211         0.006327         0.563069          0.999327   \n",
       "18       0.234337         0.013297         0.553500          0.999327   \n",
       "19       0.492291         0.029228         0.546656          0.999327   \n",
       "20       0.507108         0.029291         0.535624          0.929226   \n",
       "21       0.074109         0.014175         0.532244          0.999327   \n",
       "22       0.026928         0.004926         0.529766          0.914276   \n",
       "23       0.107500         0.018467         0.529725          0.928579   \n",
       "24       0.150285         0.025328         0.529085          0.929993   \n",
       "25       0.087587         0.006201         0.524329          0.999327   \n",
       "26       0.203138         0.012009         0.522322          0.924236   \n",
       "27       0.364388         0.020911         0.520476          0.999327   \n",
       "28       0.067621         0.012016         0.517010          0.919884   \n",
       "29       0.340299         0.020804         0.514097          0.925083   \n",
       "..            ...              ...              ...               ...   \n",
       "66       0.129415         0.011766         0.455314          0.999327   \n",
       "67       0.135677         0.012172         0.453036          0.999327   \n",
       "68       0.120861         0.026287         0.452943          0.910942   \n",
       "69       0.057207         0.011799         0.452940          0.999327   \n",
       "70       0.383138         0.022711         0.452645          0.926690   \n",
       "71       0.061383         0.011770         0.447905          0.912889   \n",
       "72       0.132050         0.012251         0.447810          0.904868   \n",
       "73       0.089325         0.019156         0.447721          0.999327   \n",
       "74       0.056939         0.005046         0.447631          0.999327   \n",
       "75       0.204490         0.018932         0.445757          0.999327   \n",
       "76       0.292883         0.026061         0.443942          0.914943   \n",
       "77       0.093866         0.006053         0.443603          0.999327   \n",
       "78       0.051623         0.004975         0.441957          0.999327   \n",
       "79       0.280706         0.025735         0.440078          0.999327   \n",
       "80       0.024429         0.005034         0.438331          0.886438   \n",
       "81       0.513650         0.028162         0.437374          0.923543   \n",
       "82       0.146770         0.026211         0.435130          0.917921   \n",
       "83       0.226937         0.019638         0.434604          0.919032   \n",
       "84       0.079181         0.014082         0.434305          0.923994   \n",
       "85       0.022064         0.005022         0.429469          0.999327   \n",
       "86       0.053327         0.005148         0.424631          0.873036   \n",
       "87       0.128777         0.026892         0.423102          0.918386   \n",
       "88       0.121377         0.012151         0.422526          0.904570   \n",
       "89       0.049568         0.005000         0.421511          0.883591   \n",
       "90       0.050461         0.005172         0.417820          0.999327   \n",
       "91       0.068368         0.014011         0.417784          0.910506   \n",
       "92       0.093766         0.018978         0.414147          0.920426   \n",
       "93       0.021641         0.005110         0.397968          0.999327   \n",
       "94       0.091102         0.005276         0.384041          0.904600   \n",
       "95       0.023749         0.004902         0.377227          0.894722   \n",
       "\n",
       "   method_ids                                       params  rank_test_score  \\\n",
       "0   [1, 2, 2]  {u'n_estimators': 55, u'criterion': u'mae'}                0   \n",
       "1   [1, 2, 2]  {u'n_estimators': 40, u'criterion': u'mae'}                1   \n",
       "2   [1, 2, 2]  {u'n_estimators': 55, u'criterion': u'mse'}                2   \n",
       "3   [1, 2, 1]  {u'n_estimators': 55, u'criterion': u'mae'}                3   \n",
       "4   [1, 2, 1]  {u'n_estimators': 55, u'criterion': u'mse'}                4   \n",
       "5   [1, 2, 1]  {u'n_estimators': 40, u'criterion': u'mse'}                5   \n",
       "6   [1, 2, 2]  {u'n_estimators': 40, u'criterion': u'mse'}                6   \n",
       "7   [1, 2, 1]  {u'n_estimators': 25, u'criterion': u'mae'}                7   \n",
       "8   [1, 2, 2]  {u'n_estimators': 10, u'criterion': u'mae'}                8   \n",
       "9   [1, 2, 2]  {u'n_estimators': 25, u'criterion': u'mse'}                9   \n",
       "10  [1, 2, 1]  {u'n_estimators': 40, u'criterion': u'mae'}               10   \n",
       "11  [1, 2, 1]  {u'n_estimators': 25, u'criterion': u'mse'}               11   \n",
       "12  [1, 2, 2]  {u'n_estimators': 25, u'criterion': u'mae'}               12   \n",
       "13  [1, 2, 1]  {u'n_estimators': 10, u'criterion': u'mse'}               13   \n",
       "14  [1, 0, 2]  {u'n_estimators': 55, u'criterion': u'mse'}               14   \n",
       "15  [1, 0, 2]  {u'n_estimators': 40, u'criterion': u'mse'}               15   \n",
       "16  [1, 2, 1]  {u'n_estimators': 10, u'criterion': u'mae'}               16   \n",
       "17  [1, 2, 2]  {u'n_estimators': 10, u'criterion': u'mse'}               17   \n",
       "18  [1, 0, 2]  {u'n_estimators': 25, u'criterion': u'mae'}               18   \n",
       "19  [1, 0, 2]  {u'n_estimators': 55, u'criterion': u'mae'}               19   \n",
       "20  [1, 0, 1]  {u'n_estimators': 55, u'criterion': u'mae'}               20   \n",
       "21  [1, 0, 2]  {u'n_estimators': 25, u'criterion': u'mse'}               21   \n",
       "22  [1, 0, 1]  {u'n_estimators': 10, u'criterion': u'mse'}               22   \n",
       "23  [1, 0, 1]  {u'n_estimators': 40, u'criterion': u'mse'}               23   \n",
       "24  [1, 0, 1]  {u'n_estimators': 55, u'criterion': u'mse'}               24   \n",
       "25  [1, 0, 2]  {u'n_estimators': 10, u'criterion': u'mae'}               25   \n",
       "26  [1, 0, 1]  {u'n_estimators': 25, u'criterion': u'mae'}               26   \n",
       "27  [1, 0, 2]  {u'n_estimators': 40, u'criterion': u'mae'}               27   \n",
       "28  [1, 0, 1]  {u'n_estimators': 25, u'criterion': u'mse'}               28   \n",
       "29  [1, 0, 1]  {u'n_estimators': 40, u'criterion': u'mae'}               29   \n",
       "..        ...                                          ...              ...   \n",
       "66  [0, 1, 2]  {u'n_estimators': 25, u'criterion': u'mae'}               66   \n",
       "67  [0, 2, 2]  {u'n_estimators': 25, u'criterion': u'mae'}               67   \n",
       "68  [0, 1, 1]  {u'n_estimators': 40, u'criterion': u'mse'}               68   \n",
       "69  [0, 2, 2]  {u'n_estimators': 25, u'criterion': u'mse'}               69   \n",
       "70  [1, 1, 1]  {u'n_estimators': 40, u'criterion': u'mae'}               70   \n",
       "71  [0, 2, 1]  {u'n_estimators': 25, u'criterion': u'mse'}               71   \n",
       "72  [0, 1, 1]  {u'n_estimators': 25, u'criterion': u'mae'}               72   \n",
       "73  [0, 1, 2]  {u'n_estimators': 40, u'criterion': u'mse'}               73   \n",
       "74  [0, 2, 2]  {u'n_estimators': 10, u'criterion': u'mae'}               74   \n",
       "75  [0, 1, 2]  {u'n_estimators': 40, u'criterion': u'mae'}               75   \n",
       "76  [0, 1, 1]  {u'n_estimators': 55, u'criterion': u'mae'}               76   \n",
       "77  [1, 1, 2]  {u'n_estimators': 10, u'criterion': u'mae'}               77   \n",
       "78  [0, 0, 2]  {u'n_estimators': 10, u'criterion': u'mae'}               78   \n",
       "79  [0, 1, 2]  {u'n_estimators': 55, u'criterion': u'mae'}               79   \n",
       "80  [0, 1, 1]  {u'n_estimators': 10, u'criterion': u'mse'}               80   \n",
       "81  [1, 1, 1]  {u'n_estimators': 55, u'criterion': u'mae'}               81   \n",
       "82  [0, 1, 1]  {u'n_estimators': 55, u'criterion': u'mse'}               82   \n",
       "83  [0, 2, 1]  {u'n_estimators': 40, u'criterion': u'mae'}               83   \n",
       "84  [1, 1, 1]  {u'n_estimators': 25, u'criterion': u'mse'}               84   \n",
       "85  [0, 1, 2]  {u'n_estimators': 10, u'criterion': u'mse'}               85   \n",
       "86  [0, 1, 1]  {u'n_estimators': 10, u'criterion': u'mae'}               86   \n",
       "87  [0, 2, 1]  {u'n_estimators': 55, u'criterion': u'mse'}               87   \n",
       "88  [0, 2, 1]  {u'n_estimators': 25, u'criterion': u'mae'}               88   \n",
       "89  [0, 2, 1]  {u'n_estimators': 10, u'criterion': u'mae'}               89   \n",
       "90  [0, 1, 2]  {u'n_estimators': 10, u'criterion': u'mae'}               90   \n",
       "91  [0, 1, 1]  {u'n_estimators': 25, u'criterion': u'mse'}               91   \n",
       "92  [0, 2, 1]  {u'n_estimators': 40, u'criterion': u'mse'}               92   \n",
       "93  [0, 2, 2]  {u'n_estimators': 10, u'criterion': u'mse'}               93   \n",
       "94  [1, 1, 1]  {u'n_estimators': 10, u'criterion': u'mae'}               94   \n",
       "95  [0, 2, 1]  {u'n_estimators': 10, u'criterion': u'mse'}               95   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.677133            0.999978           0.666931   \n",
       "1            0.667524            0.999978           0.648800   \n",
       "2            0.668569            0.999978           0.638537   \n",
       "3            0.662526            0.932603           0.615139   \n",
       "4            0.715424            0.934945           0.579221   \n",
       "5            0.693874            0.929307           0.626593   \n",
       "6            0.675135            0.999978           0.610547   \n",
       "7            0.635584            0.933998           0.660207   \n",
       "8            0.639206            0.999978           0.601776   \n",
       "9            0.674517            0.999978           0.600672   \n",
       "10           0.655826            0.923715           0.571048   \n",
       "11           0.696969            0.929801           0.558220   \n",
       "12           0.671600            0.999978           0.525742   \n",
       "13           0.641078            0.922661           0.549063   \n",
       "14           0.643035            0.999978           0.606921   \n",
       "15           0.626742            0.999978           0.612241   \n",
       "16           0.582810            0.903686           0.594502   \n",
       "17           0.629988            0.999978           0.576435   \n",
       "18           0.599834            0.999978           0.619800   \n",
       "19           0.610133            0.999978           0.592280   \n",
       "20           0.562966            0.918211           0.582872   \n",
       "21           0.613994            0.999978           0.606001   \n",
       "22           0.593655            0.899050           0.564145   \n",
       "23           0.585921            0.932432           0.571995   \n",
       "24           0.569633            0.923452           0.572766   \n",
       "25           0.595589            0.999978           0.584735   \n",
       "26           0.522936            0.929253           0.575438   \n",
       "27           0.574362            0.999978           0.580725   \n",
       "28           0.576332            0.914199           0.574699   \n",
       "29           0.567707            0.919558           0.544228   \n",
       "..                ...                 ...                ...   \n",
       "66           0.514665            0.999978           0.466658   \n",
       "67           0.505800            0.999978           0.469945   \n",
       "68           0.542659            0.903799           0.430453   \n",
       "69           0.511811            0.999978           0.463751   \n",
       "70           0.470176            0.928646           0.515855   \n",
       "71           0.506235            0.910769           0.419286   \n",
       "72           0.493631            0.894170           0.448127   \n",
       "73           0.495257            0.999978           0.473424   \n",
       "74           0.499696            0.999978           0.443762   \n",
       "75           0.511391            0.999978           0.470341   \n",
       "76           0.508563            0.905416           0.466128   \n",
       "77           0.459749            0.999978           0.535967   \n",
       "78           0.497328            0.999978           0.482597   \n",
       "79           0.503981            0.999978           0.439359   \n",
       "80           0.469139            0.880897           0.496814   \n",
       "81           0.435470            0.929999           0.527282   \n",
       "82           0.495867            0.906287           0.422693   \n",
       "83           0.533535            0.910753           0.432182   \n",
       "84           0.495826            0.919807           0.436976   \n",
       "85           0.531158            0.999978           0.408375   \n",
       "86           0.512529            0.869530           0.414054   \n",
       "87           0.499550            0.915338           0.405926   \n",
       "88           0.493540            0.892617           0.427600   \n",
       "89           0.530776            0.859296           0.420564   \n",
       "90           0.479440            0.999978           0.423900   \n",
       "91           0.502791            0.902003           0.424643   \n",
       "92           0.490336            0.915519           0.356600   \n",
       "93           0.448027            0.999978           0.405060   \n",
       "94           0.346534            0.896983           0.493151   \n",
       "95           0.394553            0.908679           0.427265   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0             0.998030           0.566100            0.999974      0.016674   \n",
       "1             0.998030           0.548378            0.999974      0.010716   \n",
       "2             0.998030           0.549420            0.999974      0.004264   \n",
       "3             0.945497           0.577623            0.944681      0.019597   \n",
       "4             0.947193           0.556294            0.946716      0.006242   \n",
       "5             0.941446           0.526619            0.952537      0.006429   \n",
       "6             0.998030           0.545401            0.999974      0.003110   \n",
       "7             0.920911           0.530077            0.948331      0.012959   \n",
       "8             0.998030           0.554777            0.999974      0.003891   \n",
       "9             0.998030           0.505927            0.999974      0.001923   \n",
       "10            0.933144           0.537507            0.951558      0.012898   \n",
       "11            0.924635           0.502585            0.949243      0.003171   \n",
       "12            0.998030           0.534180            0.999974      0.006413   \n",
       "13            0.937908           0.525471            0.932116      0.001447   \n",
       "14            0.998030           0.452257            0.999974      0.008633   \n",
       "15            0.998030           0.458402            0.999974      0.012188   \n",
       "16            0.928826           0.514336            0.939085      0.005195   \n",
       "17            0.998030           0.482063            0.999974      0.001330   \n",
       "18            0.998030           0.440368            0.999974      0.008436   \n",
       "19            0.998030           0.436871            0.999974      0.008887   \n",
       "20            0.933235           0.460740            0.936233      0.016345   \n",
       "21            0.998030           0.375858            0.999974      0.015076   \n",
       "22            0.916170           0.430812            0.927607      0.000247   \n",
       "23            0.917596           0.430655            0.935709      0.000166   \n",
       "24            0.928583           0.444420            0.937943      0.003182   \n",
       "25            0.998030           0.391896            0.999974      0.005510   \n",
       "26            0.918809           0.468585            0.924647      0.008198   \n",
       "27            0.998030           0.405761            0.999974      0.004622   \n",
       "28            0.916065           0.399362            0.929387      0.000219   \n",
       "29            0.925269           0.429778            0.930421      0.034664   \n",
       "..                 ...                ...                 ...           ...   \n",
       "66            0.998030           0.383980            0.999974      0.000475   \n",
       "67            0.998030           0.382795            0.999974      0.004922   \n",
       "68            0.911402           0.384754            0.917626      0.004156   \n",
       "69            0.998030           0.382624            0.999974      0.004856   \n",
       "70            0.920022           0.371715            0.931401      0.034239   \n",
       "71            0.912013           0.417566            0.915883      0.003928   \n",
       "72            0.915648           0.401179            0.904786      0.002898   \n",
       "73            0.998030           0.373970            0.999974      0.002415   \n",
       "74            0.998030           0.398875            0.999974      0.001311   \n",
       "75            0.998030           0.354833            0.999974      0.004821   \n",
       "76            0.921047           0.356440            0.918367      0.006066   \n",
       "77            0.998030           0.334918            0.999974      0.003281   \n",
       "78            0.998030           0.345349            0.999974      0.001128   \n",
       "79            0.998030           0.376207            0.999974      0.005013   \n",
       "80            0.869641           0.348710            0.908778      0.000299   \n",
       "81            0.914613           0.349390            0.926017      0.011770   \n",
       "82            0.922294           0.386176            0.925181      0.015858   \n",
       "83            0.924144           0.337031            0.922201      0.030296   \n",
       "84            0.920527           0.369452            0.931648      0.002282   \n",
       "85            0.998030           0.347781            0.999974      0.000520   \n",
       "86            0.870999           0.346366            0.878579      0.001481   \n",
       "87            0.923868           0.363007            0.915952      0.000726   \n",
       "88            0.916280           0.345674            0.904813      0.002863   \n",
       "89            0.893825           0.312019            0.897651      0.001317   \n",
       "90            0.998030           0.349457            0.999974      0.001997   \n",
       "91            0.914159           0.325005            0.915357      0.004393   \n",
       "92            0.926442           0.394687            0.919317      0.000166   \n",
       "93            0.998030           0.340278            0.999974      0.000178   \n",
       "94            0.896086           0.312841            0.920732      0.000950   \n",
       "95            0.880529           0.309677            0.894957      0.000176   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.000592        0.050079         0.000917  \n",
       "1         0.000828        0.052292         0.000917  \n",
       "2         0.001138        0.050593         0.000917  \n",
       "3         0.000795        0.034777         0.005895  \n",
       "4         0.001802        0.070357         0.005665  \n",
       "5         0.003365        0.068751         0.009487  \n",
       "6         0.000726        0.053010         0.000917  \n",
       "7         0.000620        0.056365         0.011198  \n",
       "8         0.000318        0.034565         0.000917  \n",
       "9         0.000309        0.069048         0.000917  \n",
       "10        0.001610        0.049865         0.011562  \n",
       "11        0.000462        0.081862         0.010595  \n",
       "12        0.000752        0.066976         0.000917  \n",
       "13        0.000494        0.049958         0.006284  \n",
       "14        0.000766        0.082721         0.000917  \n",
       "15        0.005118        0.076120         0.000917  \n",
       "16        0.000098        0.035313         0.014871  \n",
       "17        0.001287        0.061174         0.000917  \n",
       "18        0.000826        0.080198         0.000917  \n",
       "19        0.001584        0.077765         0.000917  \n",
       "20        0.001807        0.053432         0.007885  \n",
       "21        0.000813        0.110334         0.000917  \n",
       "22        0.000115        0.070818         0.011735  \n",
       "23        0.000161        0.070097         0.007880  \n",
       "24        0.000340        0.059721         0.005999  \n",
       "25        0.001011        0.093499         0.000917  \n",
       "26        0.000034        0.043547         0.004273  \n",
       "27        0.001109        0.080940         0.000917  \n",
       "28        0.000420        0.082970         0.006763  \n",
       "29        0.001539        0.060231         0.004437  \n",
       "..             ...             ...              ...  \n",
       "66        0.000100        0.053995         0.000917  \n",
       "67        0.000161        0.051656         0.000917  \n",
       "68        0.002018        0.066442         0.005654  \n",
       "69        0.000110        0.053334         0.000917  \n",
       "70        0.001851        0.060047         0.004847  \n",
       "71        0.000171        0.041473         0.002178  \n",
       "72        0.000056        0.037777         0.008769  \n",
       "73        0.000319        0.052769         0.000917  \n",
       "74        0.000078        0.041286         0.000917  \n",
       "75        0.000459        0.066278         0.000917  \n",
       "76        0.000540        0.064097         0.006825  \n",
       "77        0.000542        0.082731         0.000917  \n",
       "78        0.000103        0.068394         0.000917  \n",
       "79        0.000165        0.052212         0.000917  \n",
       "80        0.000216        0.064206         0.016451  \n",
       "81        0.001139        0.072507         0.006520  \n",
       "82        0.001032        0.045671         0.008310  \n",
       "83        0.001403        0.080311         0.005908  \n",
       "84        0.001913        0.051672         0.005420  \n",
       "85        0.000010        0.076391         0.000917  \n",
       "86        0.000067        0.068304         0.003965  \n",
       "87        0.001883        0.057092         0.003885  \n",
       "88        0.000346        0.060525         0.009662  \n",
       "89        0.000152        0.089388         0.017250  \n",
       "90        0.000168        0.053285         0.000917  \n",
       "91        0.001236        0.072806         0.006032  \n",
       "92        0.000079        0.056342         0.004528  \n",
       "93        0.000249        0.044310         0.000917  \n",
       "94        0.000251        0.078168         0.011413  \n",
       "95        0.000139        0.049477         0.011494  \n",
       "\n",
       "[96 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains only an evaluation set\n",
      "This file contains an evaluation and analysis set\n",
      "5\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "stuff.load_file('./results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_evs</th>\n",
       "      <th>dev_mae</th>\n",
       "      <th>dev_median_ae</th>\n",
       "      <th>dev_mse</th>\n",
       "      <th>dev_set_score</th>\n",
       "      <th>eval_evs</th>\n",
       "      <th>eval_mae</th>\n",
       "      <th>eval_median_ae</th>\n",
       "      <th>eval_mse</th>\n",
       "      <th>eval_set_score</th>\n",
       "      <th>method_ids</th>\n",
       "      <th>parameters</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739102</td>\n",
       "      <td>0.623838</td>\n",
       "      <td>0.501034</td>\n",
       "      <td>0.639926</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.694692</td>\n",
       "      <td>0.616625</td>\n",
       "      <td>0.441952</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.787241</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744669</td>\n",
       "      <td>0.617112</td>\n",
       "      <td>0.483138</td>\n",
       "      <td>0.626944</td>\n",
       "      <td>0.823081</td>\n",
       "      <td>0.699515</td>\n",
       "      <td>0.612576</td>\n",
       "      <td>0.466975</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.786968</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733978</td>\n",
       "      <td>0.636807</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.669066</td>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.615025</td>\n",
       "      <td>0.434259</td>\n",
       "      <td>0.721846</td>\n",
       "      <td>0.786966</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745762</td>\n",
       "      <td>0.616421</td>\n",
       "      <td>0.480062</td>\n",
       "      <td>0.625489</td>\n",
       "      <td>0.823491</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.612471</td>\n",
       "      <td>0.465889</td>\n",
       "      <td>0.721890</td>\n",
       "      <td>0.786953</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.733186</td>\n",
       "      <td>0.637282</td>\n",
       "      <td>0.511426</td>\n",
       "      <td>0.669930</td>\n",
       "      <td>0.810950</td>\n",
       "      <td>0.710194</td>\n",
       "      <td>0.615207</td>\n",
       "      <td>0.435337</td>\n",
       "      <td>0.721912</td>\n",
       "      <td>0.786947</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.614667</td>\n",
       "      <td>0.475049</td>\n",
       "      <td>0.621882</td>\n",
       "      <td>0.824509</td>\n",
       "      <td>0.701933</td>\n",
       "      <td>0.612238</td>\n",
       "      <td>0.459401</td>\n",
       "      <td>0.721978</td>\n",
       "      <td>0.786927</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.732047</td>\n",
       "      <td>0.637962</td>\n",
       "      <td>0.511549</td>\n",
       "      <td>0.671181</td>\n",
       "      <td>0.810597</td>\n",
       "      <td>0.709410</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.436924</td>\n",
       "      <td>0.722020</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694322</td>\n",
       "      <td>0.657794</td>\n",
       "      <td>0.518539</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>0.684489</td>\n",
       "      <td>0.627613</td>\n",
       "      <td>0.460684</td>\n",
       "      <td>0.736574</td>\n",
       "      <td>0.782620</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.752357</td>\n",
       "      <td>0.632101</td>\n",
       "      <td>0.494662</td>\n",
       "      <td>0.648956</td>\n",
       "      <td>0.816869</td>\n",
       "      <td>0.711772</td>\n",
       "      <td>0.618592</td>\n",
       "      <td>0.453992</td>\n",
       "      <td>0.738298</td>\n",
       "      <td>0.782111</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.732740</td>\n",
       "      <td>0.638443</td>\n",
       "      <td>0.486457</td>\n",
       "      <td>0.673809</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.706970</td>\n",
       "      <td>0.624094</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.738805</td>\n",
       "      <td>0.781961</td>\n",
       "      <td>[4, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.712333</td>\n",
       "      <td>0.643176</td>\n",
       "      <td>0.498564</td>\n",
       "      <td>0.684339</td>\n",
       "      <td>0.806884</td>\n",
       "      <td>0.673801</td>\n",
       "      <td>0.628156</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.741350</td>\n",
       "      <td>0.781210</td>\n",
       "      <td>[6, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.760021</td>\n",
       "      <td>0.618858</td>\n",
       "      <td>0.497022</td>\n",
       "      <td>0.623746</td>\n",
       "      <td>0.823983</td>\n",
       "      <td>0.708178</td>\n",
       "      <td>0.621593</td>\n",
       "      <td>0.435541</td>\n",
       "      <td>0.746938</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715423</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.518645</td>\n",
       "      <td>0.667201</td>\n",
       "      <td>0.811720</td>\n",
       "      <td>0.668582</td>\n",
       "      <td>0.625715</td>\n",
       "      <td>0.495734</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.779459</td>\n",
       "      <td>[8, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.761455</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>0.493286</td>\n",
       "      <td>0.622160</td>\n",
       "      <td>0.824431</td>\n",
       "      <td>0.709157</td>\n",
       "      <td>0.621469</td>\n",
       "      <td>0.437635</td>\n",
       "      <td>0.747285</td>\n",
       "      <td>0.779459</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.715333</td>\n",
       "      <td>0.645763</td>\n",
       "      <td>0.518736</td>\n",
       "      <td>0.667319</td>\n",
       "      <td>0.811687</td>\n",
       "      <td>0.668516</td>\n",
       "      <td>0.625743</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>0.747314</td>\n",
       "      <td>0.779450</td>\n",
       "      <td>[8, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.761590</td>\n",
       "      <td>0.617789</td>\n",
       "      <td>0.492898</td>\n",
       "      <td>0.622011</td>\n",
       "      <td>0.824473</td>\n",
       "      <td>0.709249</td>\n",
       "      <td>0.621457</td>\n",
       "      <td>0.437951</td>\n",
       "      <td>0.747320</td>\n",
       "      <td>0.779448</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.612044</td>\n",
       "      <td>0.464145</td>\n",
       "      <td>0.613458</td>\n",
       "      <td>0.826886</td>\n",
       "      <td>0.688871</td>\n",
       "      <td>0.623567</td>\n",
       "      <td>0.465434</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>0.779080</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.727966</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.655139</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>0.670222</td>\n",
       "      <td>0.630329</td>\n",
       "      <td>0.460665</td>\n",
       "      <td>0.748615</td>\n",
       "      <td>0.779066</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753141</td>\n",
       "      <td>0.612524</td>\n",
       "      <td>0.463647</td>\n",
       "      <td>0.614427</td>\n",
       "      <td>0.826613</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.623663</td>\n",
       "      <td>0.467851</td>\n",
       "      <td>0.748642</td>\n",
       "      <td>0.779058</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.727571</td>\n",
       "      <td>0.635538</td>\n",
       "      <td>0.502972</td>\n",
       "      <td>0.655631</td>\n",
       "      <td>0.814985</td>\n",
       "      <td>0.669901</td>\n",
       "      <td>0.630404</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.748741</td>\n",
       "      <td>0.779029</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>0.466295</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.685186</td>\n",
       "      <td>0.624397</td>\n",
       "      <td>0.481655</td>\n",
       "      <td>0.749268</td>\n",
       "      <td>0.778873</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.709217</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.456101</td>\n",
       "      <td>0.717894</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>0.706953</td>\n",
       "      <td>0.641784</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.775590</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 1.0, u'n_alp...</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.621763</td>\n",
       "      <td>0.505157</td>\n",
       "      <td>0.636988</td>\n",
       "      <td>0.820246</td>\n",
       "      <td>0.685149</td>\n",
       "      <td>0.634194</td>\n",
       "      <td>0.470239</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>0.775441</td>\n",
       "      <td>[6, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.714051</td>\n",
       "      <td>0.645477</td>\n",
       "      <td>0.454366</td>\n",
       "      <td>0.711626</td>\n",
       "      <td>0.799184</td>\n",
       "      <td>0.707913</td>\n",
       "      <td>0.640131</td>\n",
       "      <td>0.460990</td>\n",
       "      <td>0.760953</td>\n",
       "      <td>0.775425</td>\n",
       "      <td>[4, 2, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.707464</td>\n",
       "      <td>0.653229</td>\n",
       "      <td>0.528076</td>\n",
       "      <td>0.680128</td>\n",
       "      <td>0.808072</td>\n",
       "      <td>0.663530</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.458075</td>\n",
       "      <td>0.761125</td>\n",
       "      <td>0.775374</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.707902</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.456368</td>\n",
       "      <td>0.719311</td>\n",
       "      <td>0.797015</td>\n",
       "      <td>0.706007</td>\n",
       "      <td>0.642356</td>\n",
       "      <td>0.468621</td>\n",
       "      <td>0.761136</td>\n",
       "      <td>0.775371</td>\n",
       "      <td>[3, 2, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 260, u'fit_i...</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.707269</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.528153</td>\n",
       "      <td>0.680364</td>\n",
       "      <td>0.808006</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>0.635913</td>\n",
       "      <td>0.457949</td>\n",
       "      <td>0.761176</td>\n",
       "      <td>0.775359</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.707560</td>\n",
       "      <td>0.649931</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.719676</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.705765</td>\n",
       "      <td>0.642497</td>\n",
       "      <td>0.468358</td>\n",
       "      <td>0.761319</td>\n",
       "      <td>0.775317</td>\n",
       "      <td>[3, 2, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 310, u'fit_i...</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.706498</td>\n",
       "      <td>0.653795</td>\n",
       "      <td>0.528483</td>\n",
       "      <td>0.681305</td>\n",
       "      <td>0.807740</td>\n",
       "      <td>0.662874</td>\n",
       "      <td>0.636078</td>\n",
       "      <td>0.458020</td>\n",
       "      <td>0.761378</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.707318</td>\n",
       "      <td>0.650090</td>\n",
       "      <td>0.456602</td>\n",
       "      <td>0.719927</td>\n",
       "      <td>0.796841</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.642587</td>\n",
       "      <td>0.468873</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>0.775285</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 1.0, u'n_alp...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.550590</td>\n",
       "      <td>0.712954</td>\n",
       "      <td>0.562368</td>\n",
       "      <td>0.912872</td>\n",
       "      <td>0.742393</td>\n",
       "      <td>0.580783</td>\n",
       "      <td>0.675239</td>\n",
       "      <td>0.505763</td>\n",
       "      <td>0.837002</td>\n",
       "      <td>0.752981</td>\n",
       "      <td>[5, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.603733</td>\n",
       "      <td>0.720595</td>\n",
       "      <td>0.565269</td>\n",
       "      <td>0.848397</td>\n",
       "      <td>0.760588</td>\n",
       "      <td>0.622767</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0.570301</td>\n",
       "      <td>0.841065</td>\n",
       "      <td>0.751782</td>\n",
       "      <td>[2, 2, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.492557</td>\n",
       "      <td>0.564538</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.726606</td>\n",
       "      <td>0.658499</td>\n",
       "      <td>0.512103</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.751017</td>\n",
       "      <td>[6, 2, 9]</td>\n",
       "      <td>{u'normalize': False, u'positive': False, u'cr...</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.770162</td>\n",
       "      <td>0.626217</td>\n",
       "      <td>0.535170</td>\n",
       "      <td>0.645725</td>\n",
       "      <td>0.817781</td>\n",
       "      <td>0.716766</td>\n",
       "      <td>0.666046</td>\n",
       "      <td>0.481189</td>\n",
       "      <td>0.845424</td>\n",
       "      <td>0.750495</td>\n",
       "      <td>[3, 2, 10]</td>\n",
       "      <td>{u'normalize': True, u'alpha': 0, u'l1_ratio':...</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.533353</td>\n",
       "      <td>0.731591</td>\n",
       "      <td>0.612059</td>\n",
       "      <td>0.921334</td>\n",
       "      <td>0.740005</td>\n",
       "      <td>0.546803</td>\n",
       "      <td>0.675835</td>\n",
       "      <td>0.501723</td>\n",
       "      <td>0.849062</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.504935</td>\n",
       "      <td>0.731396</td>\n",
       "      <td>0.610117</td>\n",
       "      <td>0.967370</td>\n",
       "      <td>0.727014</td>\n",
       "      <td>0.594080</td>\n",
       "      <td>0.700044</td>\n",
       "      <td>0.541446</td>\n",
       "      <td>0.850542</td>\n",
       "      <td>0.748985</td>\n",
       "      <td>[8, 1, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 160, u'fit_i...</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.530106</td>\n",
       "      <td>0.732692</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.924453</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.676669</td>\n",
       "      <td>0.500438</td>\n",
       "      <td>0.850770</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.734525</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>0.724840</td>\n",
       "      <td>0.588283</td>\n",
       "      <td>0.702526</td>\n",
       "      <td>0.544397</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>[8, 1, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 210, u'fit_i...</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.569702</td>\n",
       "      <td>0.722565</td>\n",
       "      <td>0.631466</td>\n",
       "      <td>0.841763</td>\n",
       "      <td>0.762460</td>\n",
       "      <td>0.540087</td>\n",
       "      <td>0.682678</td>\n",
       "      <td>0.485593</td>\n",
       "      <td>0.859571</td>\n",
       "      <td>0.746320</td>\n",
       "      <td>[8, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.451734</td>\n",
       "      <td>0.749088</td>\n",
       "      <td>0.608370</td>\n",
       "      <td>0.987187</td>\n",
       "      <td>0.721422</td>\n",
       "      <td>0.501453</td>\n",
       "      <td>0.684844</td>\n",
       "      <td>0.497613</td>\n",
       "      <td>0.863123</td>\n",
       "      <td>0.745272</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.776571</td>\n",
       "      <td>0.619039</td>\n",
       "      <td>0.513424</td>\n",
       "      <td>0.630290</td>\n",
       "      <td>0.822136</td>\n",
       "      <td>0.707807</td>\n",
       "      <td>0.669490</td>\n",
       "      <td>0.470071</td>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.744724</td>\n",
       "      <td>[4, 2, 10]</td>\n",
       "      <td>{u'normalize': False, u'alpha': 0, u'l1_ratio'...</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.447570</td>\n",
       "      <td>0.750434</td>\n",
       "      <td>0.611115</td>\n",
       "      <td>0.990570</td>\n",
       "      <td>0.720467</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>0.686017</td>\n",
       "      <td>0.499541</td>\n",
       "      <td>0.865731</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.534083</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.596311</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>0.738968</td>\n",
       "      <td>0.532096</td>\n",
       "      <td>0.685192</td>\n",
       "      <td>0.506913</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.743759</td>\n",
       "      <td>[6, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.729616</td>\n",
       "      <td>0.665953</td>\n",
       "      <td>0.524935</td>\n",
       "      <td>0.709743</td>\n",
       "      <td>0.799715</td>\n",
       "      <td>0.668276</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.546733</td>\n",
       "      <td>0.878031</td>\n",
       "      <td>0.740872</td>\n",
       "      <td>[2, 2, 10]</td>\n",
       "      <td>{u'normalize': False, u'alpha': 0, u'l1_ratio'...</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.541978</td>\n",
       "      <td>0.737704</td>\n",
       "      <td>0.652997</td>\n",
       "      <td>0.874577</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.520419</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.512165</td>\n",
       "      <td>0.879264</td>\n",
       "      <td>0.740509</td>\n",
       "      <td>[7, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.422882</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.615778</td>\n",
       "      <td>1.009943</td>\n",
       "      <td>0.715001</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>0.693306</td>\n",
       "      <td>0.509715</td>\n",
       "      <td>0.879486</td>\n",
       "      <td>0.740443</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.735618</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.522273</td>\n",
       "      <td>0.701986</td>\n",
       "      <td>0.801904</td>\n",
       "      <td>0.674743</td>\n",
       "      <td>0.698704</td>\n",
       "      <td>0.555863</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>[2, 2, 3]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': False}</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.421128</td>\n",
       "      <td>0.758463</td>\n",
       "      <td>0.614793</td>\n",
       "      <td>1.011325</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.476152</td>\n",
       "      <td>0.693819</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.880572</td>\n",
       "      <td>0.740123</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.725819</td>\n",
       "      <td>0.671606</td>\n",
       "      <td>0.535260</td>\n",
       "      <td>0.709767</td>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.667863</td>\n",
       "      <td>0.697610</td>\n",
       "      <td>0.525565</td>\n",
       "      <td>0.884596</td>\n",
       "      <td>0.738935</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>{u'normalize': False, u'fit_intercept': False}</td>\n",
       "      <td>1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.746404</td>\n",
       "      <td>0.645662</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.731756</td>\n",
       "      <td>0.511875</td>\n",
       "      <td>0.692870</td>\n",
       "      <td>0.473515</td>\n",
       "      <td>0.885048</td>\n",
       "      <td>0.738801</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.525478</td>\n",
       "      <td>0.743138</td>\n",
       "      <td>0.650591</td>\n",
       "      <td>0.896135</td>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.504712</td>\n",
       "      <td>0.700073</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.895630</td>\n",
       "      <td>0.735679</td>\n",
       "      <td>[6, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.759827</td>\n",
       "      <td>0.592218</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>0.718166</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.700127</td>\n",
       "      <td>0.486327</td>\n",
       "      <td>0.896699</td>\n",
       "      <td>0.735363</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.675823</td>\n",
       "      <td>0.663516</td>\n",
       "      <td>0.552594</td>\n",
       "      <td>0.787680</td>\n",
       "      <td>0.777722</td>\n",
       "      <td>0.653145</td>\n",
       "      <td>0.682258</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.901762</td>\n",
       "      <td>0.733869</td>\n",
       "      <td>[5, 1, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.435712</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.598814</td>\n",
       "      <td>1.006578</td>\n",
       "      <td>0.715950</td>\n",
       "      <td>0.462404</td>\n",
       "      <td>0.702793</td>\n",
       "      <td>0.488876</td>\n",
       "      <td>0.902035</td>\n",
       "      <td>0.733788</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.736167</td>\n",
       "      <td>0.637874</td>\n",
       "      <td>0.495982</td>\n",
       "      <td>0.724036</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>0.695098</td>\n",
       "      <td>0.671311</td>\n",
       "      <td>0.486387</td>\n",
       "      <td>0.903170</td>\n",
       "      <td>0.733453</td>\n",
       "      <td>[5, 1, 9]</td>\n",
       "      <td>{u'normalize': False, u'positive': False, u'cr...</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.468627</td>\n",
       "      <td>0.758251</td>\n",
       "      <td>0.660417</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.722702</td>\n",
       "      <td>0.478973</td>\n",
       "      <td>0.703630</td>\n",
       "      <td>0.489093</td>\n",
       "      <td>0.905926</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.531155</td>\n",
       "      <td>0.737551</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.892246</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.475383</td>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.731758</td>\n",
       "      <td>[7, 0, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.677915</td>\n",
       "      <td>0.677873</td>\n",
       "      <td>0.572106</td>\n",
       "      <td>0.774922</td>\n",
       "      <td>0.781322</td>\n",
       "      <td>0.623996</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.548083</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>0.726411</td>\n",
       "      <td>[6, 1, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.373999</td>\n",
       "      <td>0.779665</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>1.054485</td>\n",
       "      <td>0.702431</td>\n",
       "      <td>0.407944</td>\n",
       "      <td>0.720262</td>\n",
       "      <td>0.516974</td>\n",
       "      <td>0.936280</td>\n",
       "      <td>0.723682</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.552625</td>\n",
       "      <td>0.755980</td>\n",
       "      <td>0.606267</td>\n",
       "      <td>0.962445</td>\n",
       "      <td>0.728404</td>\n",
       "      <td>0.493804</td>\n",
       "      <td>0.761326</td>\n",
       "      <td>0.664197</td>\n",
       "      <td>1.000121</td>\n",
       "      <td>0.704841</td>\n",
       "      <td>[8, 2, 10]</td>\n",
       "      <td>{u'normalize': True, u'alpha': 10, u'l1_ratio'...</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dev_evs   dev_mae  dev_median_ae   dev_mse  dev_set_score  eval_evs  \\\n",
       "0    0.739102  0.623838       0.501034  0.639926       0.819417  0.694692   \n",
       "1    0.744669  0.617112       0.483138  0.626944       0.823081  0.699515   \n",
       "2    0.733978  0.636807       0.511334  0.669066       0.811194  0.710737   \n",
       "3    0.745762  0.616421       0.480062  0.625489       0.823491  0.700215   \n",
       "4    0.733186  0.637282       0.511426  0.669930       0.810950  0.710194   \n",
       "5    0.748417  0.614667       0.475049  0.621882       0.824509  0.701933   \n",
       "6    0.732047  0.637962       0.511549  0.671181       0.810597  0.709410   \n",
       "7    0.694322  0.657794       0.518539  0.714293       0.798431  0.684489   \n",
       "8    0.752357  0.632101       0.494662  0.648956       0.816869  0.711772   \n",
       "9    0.732740  0.638443       0.486457  0.673809       0.809855  0.706970   \n",
       "10   0.712333  0.643176       0.498564  0.684339       0.806884  0.673801   \n",
       "11   0.760021  0.618858       0.497022  0.623746       0.823983  0.708178   \n",
       "12   0.715423  0.645702       0.518645  0.667201       0.811720  0.668582   \n",
       "13   0.761455  0.617882       0.493286  0.622160       0.824431  0.709157   \n",
       "14   0.715333  0.645763       0.518736  0.667319       0.811687  0.668516   \n",
       "15   0.761590  0.617789       0.492898  0.622011       0.824473  0.709249   \n",
       "16   0.753805  0.612044       0.464145  0.613458       0.826886  0.688871   \n",
       "17   0.727966  0.635300       0.502775  0.655139       0.815124  0.670222   \n",
       "18   0.753141  0.612524       0.463647  0.614427       0.826613  0.688424   \n",
       "19   0.727571  0.635538       0.502972  0.655631       0.814985  0.669901   \n",
       "20   0.748437  0.615994       0.466295  0.621203       0.824700  0.685186   \n",
       "21   0.709217  0.648809       0.456101  0.717894       0.797415  0.706953   \n",
       "22   0.749687  0.621763       0.505157  0.636988       0.820246  0.685149   \n",
       "23   0.714051  0.645477       0.454366  0.711626       0.799184  0.707913   \n",
       "24   0.707464  0.653229       0.528076  0.680128       0.808072  0.663530   \n",
       "25   0.707902  0.649701       0.456368  0.719311       0.797015  0.706007   \n",
       "26   0.707269  0.653343       0.528153  0.680364       0.808006  0.663397   \n",
       "27   0.707560  0.649931       0.456474  0.719676       0.796912  0.705765   \n",
       "28   0.706498  0.653795       0.528483  0.681305       0.807740  0.662874   \n",
       "29   0.707318  0.650090       0.456602  0.719927       0.796841  0.705601   \n",
       "..        ...       ...            ...       ...            ...       ...   \n",
       "135  0.550590  0.712954       0.562368  0.912872       0.742393  0.580783   \n",
       "136  0.603733  0.720595       0.565269  0.848397       0.760588  0.622767   \n",
       "137  0.806119  0.583333       0.492557  0.564538       0.840691  0.726606   \n",
       "138  0.770162  0.626217       0.535170  0.645725       0.817781  0.716766   \n",
       "139  0.533353  0.731591       0.612059  0.921334       0.740005  0.546803   \n",
       "140  0.504935  0.731396       0.610117  0.967370       0.727014  0.594080   \n",
       "141  0.530106  0.732692       0.611526  0.924453       0.739125  0.544051   \n",
       "142  0.497141  0.734525       0.602428  0.975076       0.724840  0.588283   \n",
       "143  0.569702  0.722565       0.631466  0.841763       0.762460  0.540087   \n",
       "144  0.451734  0.749088       0.608370  0.987187       0.721422  0.501453   \n",
       "145  0.776571  0.619039       0.513424  0.630290       0.822136  0.707807   \n",
       "146  0.447570  0.750434       0.611115  0.990570       0.720467  0.497802   \n",
       "147  0.534083  0.734079       0.596311  0.925011       0.738968  0.532096   \n",
       "148  0.729616  0.665953       0.524935  0.709743       0.799715  0.668276   \n",
       "149  0.541978  0.737704       0.652997  0.874577       0.753200  0.520419   \n",
       "150  0.422882  0.757920       0.615778  1.009943       0.715001  0.477688   \n",
       "151  0.735618  0.665637       0.522273  0.701986       0.801904  0.674743   \n",
       "152  0.421128  0.758463       0.614793  1.011325       0.714611  0.476152   \n",
       "153  0.725819  0.671606       0.535260  0.709767       0.799708  0.667863   \n",
       "154  0.506101  0.746404       0.645662  0.950568       0.731756  0.511875   \n",
       "155  0.525478  0.743138       0.650591  0.896135       0.747117  0.504712   \n",
       "156  0.445400  0.759827       0.592218  0.998727       0.718166  0.470838   \n",
       "157  0.675823  0.663516       0.552594  0.787680       0.777722  0.653145   \n",
       "158  0.435712  0.762590       0.598814  1.006578       0.715950  0.462404   \n",
       "159  0.736167  0.637874       0.495982  0.724036       0.795682  0.695098   \n",
       "160  0.468627  0.758251       0.660417  0.982653       0.722702  0.478973   \n",
       "161  0.531155  0.737551       0.583274  0.892246       0.748214  0.475383   \n",
       "162  0.677915  0.677873       0.572106  0.774922       0.781322  0.623996   \n",
       "163  0.373999  0.779665       0.602904  1.054485       0.702431  0.407944   \n",
       "164  0.552625  0.755980       0.606267  0.962445       0.728404  0.493804   \n",
       "\n",
       "     eval_mae  eval_median_ae  eval_mse  eval_set_score  method_ids  \\\n",
       "0    0.616625        0.441952  0.720915        0.787241  [7, 0, 11]   \n",
       "1    0.612576        0.466975  0.721839        0.786968  [8, 0, 11]   \n",
       "2    0.615025        0.434259  0.721846        0.786966  [5, 2, 11]   \n",
       "3    0.612471        0.465889  0.721890        0.786953  [8, 0, 11]   \n",
       "4    0.615207        0.435337  0.721912        0.786947  [5, 2, 11]   \n",
       "5    0.612238        0.459401  0.721978        0.786927  [8, 0, 11]   \n",
       "6    0.615465        0.436924  0.722020        0.786915  [5, 2, 11]   \n",
       "7    0.627613        0.460684  0.736574        0.782620  [3, 2, 11]   \n",
       "8    0.618592        0.453992  0.738298        0.782111  [5, 2, 11]   \n",
       "9    0.624094        0.438201  0.738805        0.781961  [4, 2, 11]   \n",
       "10   0.628156        0.458054  0.741350        0.781210  [6, 0, 11]   \n",
       "11   0.621593        0.435541  0.746938        0.779561  [6, 2, 11]   \n",
       "12   0.625715        0.495734  0.747283        0.779459  [8, 2, 11]   \n",
       "13   0.621469        0.437635  0.747285        0.779459  [6, 2, 11]   \n",
       "14   0.625743        0.495719  0.747314        0.779450  [8, 2, 11]   \n",
       "15   0.621457        0.437951  0.747320        0.779448  [6, 2, 11]   \n",
       "16   0.623567        0.465434  0.748569        0.779080  [8, 0, 11]   \n",
       "17   0.630329        0.460665  0.748615        0.779066  [7, 0, 11]   \n",
       "18   0.623663        0.467851  0.748642        0.779058  [8, 0, 11]   \n",
       "19   0.630404        0.461174  0.748741        0.779029  [7, 0, 11]   \n",
       "20   0.624397        0.481655  0.749268        0.778873  [8, 0, 11]   \n",
       "21   0.641784        0.466925  0.760394        0.775590  [3, 2, 11]   \n",
       "22   0.634194        0.470239  0.760898        0.775441  [6, 0, 11]   \n",
       "23   0.640131        0.460990  0.760953        0.775425   [4, 2, 9]   \n",
       "24   0.635869        0.458075  0.761125        0.775374  [7, 2, 11]   \n",
       "25   0.642356        0.468621  0.761136        0.775371   [3, 2, 7]   \n",
       "26   0.635913        0.457949  0.761176        0.775359  [7, 2, 11]   \n",
       "27   0.642497        0.468358  0.761319        0.775317   [3, 2, 7]   \n",
       "28   0.636078        0.458020  0.761378        0.775300  [7, 2, 11]   \n",
       "29   0.642587        0.468873  0.761425        0.775285  [3, 2, 11]   \n",
       "..        ...             ...       ...             ...         ...   \n",
       "135  0.675239        0.505763  0.837002        0.752981  [5, 1, 11]   \n",
       "136  0.708632        0.570301  0.841065        0.751782   [2, 2, 9]   \n",
       "137  0.658499        0.512103  0.843655        0.751017   [6, 2, 9]   \n",
       "138  0.666046        0.481189  0.845424        0.750495  [3, 2, 10]   \n",
       "139  0.675835        0.501723  0.849062        0.749422  [8, 1, 11]   \n",
       "140  0.700044        0.541446  0.850542        0.748985   [8, 1, 7]   \n",
       "141  0.676669        0.500438  0.850770        0.748918  [8, 1, 11]   \n",
       "142  0.702526        0.544397  0.855595        0.747494   [8, 1, 7]   \n",
       "143  0.682678        0.485593  0.859571        0.746320   [8, 2, 4]   \n",
       "144  0.684844        0.497613  0.863123        0.745272  [8, 1, 11]   \n",
       "145  0.669490        0.470071  0.864982        0.744724  [4, 2, 10]   \n",
       "146  0.686017        0.499541  0.865731        0.744503  [8, 1, 11]   \n",
       "147  0.685192        0.506913  0.868250        0.743759  [6, 1, 11]   \n",
       "148  0.697973        0.546733  0.878031        0.740872  [2, 2, 10]   \n",
       "149  0.692700        0.512165  0.879264        0.740509   [7, 2, 4]   \n",
       "150  0.693306        0.509715  0.879486        0.740443  [7, 1, 11]   \n",
       "151  0.698704        0.555863  0.880352        0.740187   [2, 2, 3]   \n",
       "152  0.693819        0.510340  0.880572        0.740123  [7, 1, 11]   \n",
       "153  0.697610        0.525565  0.884596        0.738935   [2, 2, 4]   \n",
       "154  0.692870        0.473515  0.885048        0.738801  [7, 1, 11]   \n",
       "155  0.700073        0.535032  0.895630        0.735679   [6, 2, 4]   \n",
       "156  0.700127        0.486327  0.896699        0.735363  [7, 1, 11]   \n",
       "157  0.682258        0.539400  0.901762        0.733869   [5, 1, 9]   \n",
       "158  0.702793        0.488876  0.902035        0.733788  [7, 1, 11]   \n",
       "159  0.671311        0.486387  0.903170        0.733453   [5, 1, 9]   \n",
       "160  0.703630        0.489093  0.905926        0.732640  [7, 1, 11]   \n",
       "161  0.707195        0.543245  0.908914        0.731758   [7, 0, 4]   \n",
       "162  0.720576        0.548083  0.927032        0.726411   [6, 1, 9]   \n",
       "163  0.720262        0.516974  0.936280        0.723682  [7, 1, 11]   \n",
       "164  0.761326        0.664197  1.000121        0.704841  [8, 2, 10]   \n",
       "\n",
       "                                            parameters  rank_test_score  \n",
       "0    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...                0  \n",
       "1    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               13  \n",
       "2    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               14  \n",
       "3    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               18  \n",
       "4    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               19  \n",
       "5    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               21  \n",
       "6    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               29  \n",
       "7    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               76  \n",
       "8    {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...               77  \n",
       "9    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               96  \n",
       "10   {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...              136  \n",
       "11   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              155  \n",
       "12   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              158  \n",
       "13   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              159  \n",
       "14   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              161  \n",
       "15   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              162  \n",
       "16   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              172  \n",
       "17   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              177  \n",
       "18   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              179  \n",
       "19   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              184  \n",
       "20   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              187  \n",
       "21   {u'normalize': True, u'l1_ratio': 1.0, u'n_alp...              392  \n",
       "22   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              396  \n",
       "23   {u'normalize': True, u'positive': False, u'cri...              406  \n",
       "24   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              409  \n",
       "25   {u'normalize': True, u'n_alphas': 260, u'fit_i...              410  \n",
       "26   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              412  \n",
       "27   {u'normalize': True, u'n_alphas': 310, u'fit_i...              414  \n",
       "28   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              416  \n",
       "29   {u'normalize': True, u'l1_ratio': 1.0, u'n_alp...              417  \n",
       "..                                                 ...              ...  \n",
       "135  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1247  \n",
       "136  {u'normalize': True, u'positive': False, u'cri...             1262  \n",
       "137  {u'normalize': False, u'positive': False, u'cr...             1263  \n",
       "138  {u'normalize': True, u'alpha': 0, u'l1_ratio':...             1264  \n",
       "139  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1276  \n",
       "140  {u'normalize': True, u'n_alphas': 160, u'fit_i...             1280  \n",
       "141  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1284  \n",
       "142  {u'normalize': True, u'n_alphas': 210, u'fit_i...             1306  \n",
       "143       {u'normalize': True, u'fit_intercept': True}             1339  \n",
       "144  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1340  \n",
       "145  {u'normalize': False, u'alpha': 0, u'l1_ratio'...             1345  \n",
       "146  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1357  \n",
       "147  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1362  \n",
       "148  {u'normalize': False, u'alpha': 0, u'l1_ratio'...             1372  \n",
       "149       {u'normalize': True, u'fit_intercept': True}             1384  \n",
       "150  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1385  \n",
       "151      {u'normalize': True, u'fit_intercept': False}             1387  \n",
       "152  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1389  \n",
       "153     {u'normalize': False, u'fit_intercept': False}             1395  \n",
       "154  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1397  \n",
       "155       {u'normalize': True, u'fit_intercept': True}             1410  \n",
       "156  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1411  \n",
       "157  {u'normalize': True, u'positive': False, u'cri...             1419  \n",
       "158  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1421  \n",
       "159  {u'normalize': False, u'positive': False, u'cr...             1422  \n",
       "160  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1423  \n",
       "161       {u'normalize': True, u'fit_intercept': True}             1424  \n",
       "162  {u'normalize': True, u'positive': False, u'cri...             1426  \n",
       "163  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1428  \n",
       "164  {u'normalize': True, u'alpha': 10, u'l1_ratio'...             1430  \n",
       "\n",
       "[165 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff.analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f8fe4d4d2f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
